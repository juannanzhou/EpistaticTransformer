{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a6edcf-5d70-424b-ba72-2655d7e555f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from functools import partial\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import GPUtil\n",
    "from scipy.stats import pearsonr\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "sys.path.append('../model')\n",
    "from utils import amino_acid_to_number, tokenize, Tee\n",
    "from functions import get_A2N_list, tokenize, make_train_val_test_lists_rand, prepare_data\n",
    "from models import make_predictions, ProtDataset, Transformer_MHA, Transformer_2k\n",
    "from models import LinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6bc310-da0b-43f8-95a0-cd1ac05c82be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[KeOps] Warning : There were warnings or errors compiling formula :\n",
      "<stdin>:1:10: fatal error: cuda.h: No such file or directory\n",
      "compilation terminated.\n",
      "\n",
      "[KeOps] Warning : \n",
      "    The location of Cuda header files cuda.h and nvrtc.h could not be detected on your system.\n",
      "    You must determine their location and then define the environment variable CUDA_PATH,\n",
      "    either before launching Python or using os.environ before importing keops. For example\n",
      "    if these files are in /vol/cuda/10.2.89-cudnn7.6.4.38/include you can do :\n",
      "      import os\n",
      "      os.environ['CUDA_PATH'] = '/vol/cuda/10.2.89-cudnn7.6.4.38'\n",
      "    \n",
      "[KeOps] Compiling cuda jit compiler engine ... \n",
      "[KeOps] Warning : There were warnings or errors compiling formula :\n",
      "/home/juannanzhou/.local/lib/python3.10/site-packages/keopscore/binders/nvrtc/nvrtc_jit.cpp:5:10: fatal error: nvrtc.h: No such file or directory\n",
      " #include <nvrtc.h>\n",
      "          ^~~~~~~~~\n",
      "compilation terminated.\n",
      "\n",
      "OK\n",
      "[pyKeOps] Compiling nvrtc binder for python ... \n",
      "[KeOps] Warning : There were warnings or errors compiling formula :\n",
      "In file included from /home/juannanzhou/.local/lib/python3.10/site-packages/pykeops/common/keops_io/pykeops_nvrtc.cpp:4:\n",
      "/home/juannanzhou/.local/lib/python3.10/site-packages/keopscore/binders/nvrtc/keops_nvrtc.cpp:6:10: fatal error: nvrtc.h: No such file or directory\n",
      " #include <nvrtc.h>\n",
      "          ^~~~~~~~~\n",
      "compilation terminated.\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import kernels\n",
    "importlib.reload(kernels)\n",
    "from kernels import hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1cef9b9-a548-4009-b0d1-c05b2ed957cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence length = 34;  AA_size = 2\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "# device = \"cpu\"\n",
    "\n",
    "data_name = \"Faure2023_1_lenient\"\n",
    "# prepare data\n",
    "in_path = \"../Data/Data_prepared/\" + data_name + \".csv\"\n",
    "datafile = pd.read_csv(in_path, index_col=None)\n",
    "phenotypes, seqs, seqs1h = prepare_data(datafile)\n",
    "_, L, AA_size = seqs1h.shape\n",
    "print(f\"sequence length = {L}; \", f\"AA_size = {AA_size}\")\n",
    "\n",
    "num_train = int(100)\n",
    "num_test = min(10000, len(datafile) - num_train)\n",
    "train_list, val_list, test_list, __ = make_train_val_test_lists_rand(datafile, num_train, num_test)    \n",
    "\n",
    "x = seqs1h[train_list].float().flatten(1).to(device)\n",
    "\n",
    "y = torch.tensor(datafile.DMS_score[train_list].to_numpy()).float().to(device)\n",
    "\n",
    "D = L - hd(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18e5fe9-9210-48dc-bafc-d192e960a87a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def binom(n, k):\n",
    "    \"\"\"Compute binomial coefficient using the log-gamma function for stability.\"\"\"\n",
    "    # Ensure n and k are tensors\n",
    "    n = torch.as_tensor(n, dtype=torch.float)\n",
    "    k = torch.as_tensor(k, dtype=torch.float)\n",
    "    return torch.exp(torch.lgamma(n + 1) - torch.lgamma(k + 1) - torch.lgamma(n - k + 1))\n",
    "\n",
    "def w(k, d, alpha, l):\n",
    "    total_sum = torch.zeros_like(d, dtype=torch.float)  # Initialize the sum as a tensor of zeros with the same shape as d\n",
    "    alpha = torch.as_tensor(alpha, dtype=torch.float)  # Ensure alpha is a tensor\n",
    "    l = torch.as_tensor(l, dtype=torch.float)  # Ensure l is a tensor\n",
    "    \n",
    "    for q in range(0, k + 1):\n",
    "        q_tensor = torch.full_like(d, q, dtype=torch.float)  # Convert q to a tensor of the same shape as d\n",
    "        # Compute the term for each q where q <= d\n",
    "        term = ((-1) ** q_tensor) * ((alpha - 1) ** (k - q_tensor)) * binom(d, q_tensor) * binom(l - d, k - q_tensor)\n",
    "        # Accumulate the sum\n",
    "        total_sum += term\n",
    "    return total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a9794e2-eab9-48eb-b5fb-069c505971b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 7\n",
    "\n",
    "b = -1\n",
    "lda = torch.exp(torch.tensor(b*k))\n",
    "\n",
    "K = lda*w(k, D, AA_size, L)\n",
    "\n",
    "plt.scatter(D[:, 1].cpu().numpy() , K[:, 1].cpu().numpy() )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b51056-5f7c-4025-ae6e-fcfdd99c942e",
   "metadata": {},
   "source": [
    "### Define new kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80608044-7e4d-4da5-82dc-749ffab495c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c09a5d-4a37-4c24-bccc-00bb4dcf63e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = gpytorch.kernels.Kernel()\n",
    "D_ = (k.covar_dist(x, x)**2).round()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12f10d3-b88a-4946-bfcd-4c887f3aa10e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import positivity constraint\n",
    "from gpytorch.constraints import Positive\n",
    "\n",
    "class EpKernel(gpytorch.kernels.Kernel):\n",
    "    # the sinc kernel is stationary\n",
    "    is_stationary = True\n",
    "\n",
    "    # We will register the parameter when initializing the kernel\n",
    "    def __init__(self, lda_prior=None, lda_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # register the raw parameter\n",
    "        # self.register_parameter(\n",
    "        #     name='raw_lda', parameter=torch.nn.Parameter(2*torch.arange(1, 8+1).float())\n",
    "        # )\n",
    "        self.register_parameter(\n",
    "            name='raw_lda', parameter=torch.nn.Parameter(torch.ones(*self.batch_shape, 8, 1))\n",
    "        )\n",
    "        \n",
    "        # set the parameter constraint to be positive, when nothing is specified\n",
    "        if lda_constraint is None:\n",
    "            lda_constraint = Positive()\n",
    "\n",
    "        # register the constraint\n",
    "        self.register_constraint(\"raw_lda\", lda_constraint)\n",
    "\n",
    "        # set the parameter prior, see\n",
    "        # https://docs.gpytorch.ai/en/latest/module.html#gpytorch.Module.register_prior\n",
    "        if lda_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"lda_prior\",\n",
    "                lda_prior,\n",
    "                lambda m: m.lda,\n",
    "                lambda m, v : m._set_lda(v),\n",
    "            )\n",
    "\n",
    "    # now set up the 'actual' paramter\n",
    "    @property\n",
    "    def lda(self):\n",
    "        # when accessing the parameter, apply the constraint transform\n",
    "        return -1*self.raw_lda_constraint.transform(self.raw_lda)\n",
    "\n",
    "    @lda.setter\n",
    "    def lda(self, value):\n",
    "        return self._set_lda(value)\n",
    "\n",
    "    def _set_lda(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lda)\n",
    "        # when setting the paramater, transform the actual value to a raw one by applying the inverse transform\n",
    "        self.initialize(raw_lda=self.raw_lda_constraint.inverse_transform(value))\n",
    "\n",
    "    # this is the kernel function\n",
    "    def forward(self, x1, x2, **params):\n",
    "        D = (self.covar_dist(x1, x2)**2).round()/2\n",
    "        wkd = torch.stack([w(k, D, AA_size, L) for k in range(1, 8+1)])\n",
    "        K = (wkd * torch.exp(self.lda).view(8, 1, 1)).sum(0)\n",
    "        return K\n",
    "    \n",
    "# Use the simplest form of GP model, exact inference\n",
    "class EpModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = EpKernel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2445aacb-da06-4a6f-a838-7d164efe15af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = EpKernel().to(device)\n",
    "\n",
    "# wkd = torch.stack([w(k, D_, AA_size, L) for k in range(1, 8+1)]).cpu()\n",
    "\n",
    "# K = (wkd * torch.exp(k.lda).view(8, 1, 1)).sum(0)\n",
    "\n",
    "# plt.scatter(D_[:, 1].cpu().numpy() , K[:, 1].detach().cpu().numpy() )\n",
    "# plt.show()\n",
    "\n",
    "K = k.forward(x, x)\n",
    "\n",
    "plt.scatter(D_[:, 1].cpu().numpy() , K[:, 1].detach().cpu().numpy() )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14a85efe-f4e9-46e1-bf0a-5dfbc6b43c80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.4831e+02],\n",
       "        [-6.4411e+03],\n",
       "        [-6.4364e+04],\n",
       "        [-4.9145e+05],\n",
       "        [-2.8989e+06],\n",
       "        [-1.3887e+07],\n",
       "        [-5.5282e+07],\n",
       "        [-1.8573e+08]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = y.unsqueeze(0).matmul(K).matmul(y)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "k.raw_lda.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a513f4a0-fe2a-4beb-9b1c-be67290e5335",
   "metadata": {},
   "source": [
    "#### Try on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e0be12c-0ae4-4416-9930-d14e2a66c3d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = EpModel(x, y, likelihood).to(device)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df3e381c-316d-4e89-824c-0c0fcff9a8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EpModel(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (mean_module): ConstantMean()\n",
       "  (covar_module): EpKernel(\n",
       "    (raw_lda_constraint): Positive()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc37811b-bf6c-4b83-bf4d-6556fbbc9cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.4831e+02],\n",
      "        [-6.4411e+03],\n",
      "        [-6.4364e+04],\n",
      "        [-4.9145e+05],\n",
      "        [-2.8989e+06],\n",
      "        [-1.3887e+07],\n",
      "        [-5.5282e+07],\n",
      "        [-1.8573e+08]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "K = model.covar_module(x, x).evaluate()\n",
    "\n",
    "loss = y.unsqueeze(0).matmul(K).matmul(y)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(model.covar_module.raw_lda.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3a5b5dd-f622-48c0-a551-2a3924eb6187",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6570e+03],\n",
      "        [-1.1193e+04],\n",
      "        [-1.1165e+05],\n",
      "        [-8.5272e+05],\n",
      "        [-5.0540e+06],\n",
      "        [-2.4152e+07],\n",
      "        [-9.6160e+07],\n",
      "        [-3.2335e+08]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "loss = model.covar_module(x, x).sum()\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(model.covar_module.raw_lda.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b21baaf0-e73c-4923-aa4d-7ab3d80183e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.covar_module = EpKernel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa1f3d72-7f5f-4a88-8cf0-39120a4ca1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7afd8c62-6627-4ccb-8408-b57b42642a41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.4831e+02],\n",
       "        [-6.4411e+03],\n",
       "        [-6.4364e+04],\n",
       "        [-4.9145e+05],\n",
       "        [-2.8989e+06],\n",
       "        [-1.3887e+07],\n",
       "        [-5.5282e+07],\n",
       "        [-1.8573e+08]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = model.covar_module\n",
    "\n",
    "K = k.forward(x, x)\n",
    "\n",
    "loss = y.unsqueeze(0).matmul(K).matmul(y)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "k.raw_lda.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53413404-83dd-43ff-8965-3ff2c929fbd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6966e+03],\n",
       "        [-1.2882e+04],\n",
       "        [-1.2873e+05],\n",
       "        [-9.8290e+05],\n",
       "        [-5.7978e+06],\n",
       "        [-2.7773e+07],\n",
       "        [-1.1056e+08],\n",
       "        [-3.7147e+08]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = model.covar_module(x, x)\n",
    "\n",
    "loss = y.unsqueeze(0).matmul(K).matmul(y)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "k.raw_lda.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92691e8-db87-4205-b0b7-60b5eec4c534",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f9b212d-f17b-4972-8aaa-b6d3e59a55a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_iter = 10\n",
    "\n",
    "import os\n",
    "def train(model, likelihood, training_iter=training_iter):\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        print(f\"performing iteration {i}\")\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        print(f\"loss = {loss.item()}\")\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1124a2bd-d84e-416e-a69b-f638ea01000b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = EpModel(x, y, likelihood).to(device)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "output = model(x)\n",
    "# Calc loss and backprop gradients\n",
    "loss = -mll(output, y)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cab33af-5fc4-40b6-9456-3e57028bf29e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: likelihood.noise_covar.raw_noise, Gradient: tensor([3.6903e-08], device='cuda:0')\n",
      "Parameter name: mean_module.raw_constant, Gradient: 7.698514536969014e-08\n",
      "Parameter name: covar_module.raw_lda, Gradient: tensor([[-4.9018e-07],\n",
      "        [-8.0989e-06],\n",
      "        [-8.6488e-05],\n",
      "        [-6.7092e-04],\n",
      "        [-4.0287e-03],\n",
      "        [-1.9484e-02],\n",
      "        [-7.7976e-02],\n",
      "        [-2.6327e-01]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter name: {name}, Gradient: {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c91d13a5-d941-4210-9df6-d20cf3c38ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3133],\n",
       "        [-1.3133],\n",
       "        [-1.3133],\n",
       "        [-1.3133],\n",
       "        [-1.3133],\n",
       "        [-1.3133],\n",
       "        [-1.3133],\n",
       "        [-1.3133]], device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EpModel(x, y, likelihood).to(device)\n",
    "model.covar_module.lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "733edeed-d890-496c-b5d7-02ec50d0f64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = .1\n",
    "training_iter = 1000\n",
    "train_x, train_y = x, y\n",
    "# initialize the new model\n",
    "model = EpModel(train_x, train_y, likelihood).to(device)\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8683727-66fa-4a44-8979-6b5192de43a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing iteration 0\n",
      "loss = 3.438227653503418\n",
      "performing iteration 1\n",
      "loss = 3.388589859008789\n",
      "performing iteration 2\n",
      "loss = 3.3389384746551514\n",
      "performing iteration 3\n",
      "loss = 3.2893576622009277\n",
      "performing iteration 4\n",
      "loss = 3.239825487136841\n",
      "performing iteration 5\n",
      "loss = 3.190324544906616\n",
      "performing iteration 6\n",
      "loss = 3.1408820152282715\n",
      "performing iteration 7\n",
      "loss = 3.091517925262451\n",
      "performing iteration 8\n",
      "loss = 3.0422208309173584\n",
      "performing iteration 9\n",
      "loss = 2.9929897785186768\n"
     ]
    }
   ],
   "source": [
    "# set to training mode and train\n",
    "model.train()\n",
    "likelihood.train()\n",
    "train(model, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "746f5243-e73e-4227-b219-8574f702d5eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: likelihood.noise_covar.raw_noise, Gradient: None\n",
      "Parameter name: mean_module.raw_constant, Gradient: 7.63205960652158e-08\n",
      "Parameter name: covar_module.raw_lda, Gradient: tensor([[-4.9141e-07],\n",
      "        [-8.1185e-06],\n",
      "        [-8.6697e-05],\n",
      "        [-6.7254e-04],\n",
      "        [-4.0384e-03],\n",
      "        [-1.9531e-02],\n",
      "        [-7.8164e-02],\n",
      "        [-2.6391e-01]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter name: {name}, Gradient: {param.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee52af-9e67-4e01-ab48-9e6c09c3553c",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f9eb1b0-a0f5-433c-8f8c-5ca896cfc5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90f38794-977b-4c94-ad42-45842c0c9c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 50\n",
    "\n",
    "# Training data is 100 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, 100)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)\n",
    "\n",
    "# Wrap training, prediction and plotting from the ExactGP-Tutorial into a function,\n",
    "# so that we do not have to repeat the code later on\n",
    "def train(model, likelihood, training_iter=training_iter):\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def predict(model, likelihood, test_x = torch.linspace(0, 1, 51)):\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    # Make predictions by feeding model through likelihood\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        # Test points are regularly spaced along [0,1]\n",
    "        return likelihood(model(test_x))\n",
    "\n",
    "def plot(observed_pred, test_x=torch.linspace(0, 1, 51)):\n",
    "    with torch.no_grad():\n",
    "        # Initialize plot\n",
    "        f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "        # Get upper and lower confidence bounds\n",
    "        lower, upper = observed_pred.confidence_region()\n",
    "        # Plot training data as black stars\n",
    "        ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "        # Plot predictive means as blue line\n",
    "        ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
    "        # Shade between the lower and upper confidence bounds\n",
    "        ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "        ax.set_ylim([-3, 3])\n",
    "        ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b318ddc4-2e92-48c3-aeb6-630b560f86ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import positivity constraint\n",
    "from gpytorch.constraints import Positive\n",
    "\n",
    "class SincKernel(gpytorch.kernels.Kernel):\n",
    "    # the sinc kernel is stationary\n",
    "    is_stationary = True\n",
    "\n",
    "    # We will register the parameter when initializing the kernel\n",
    "    def __init__(self, length_prior=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # register the raw parameter\n",
    "        self.register_parameter(\n",
    "            name='raw_length', parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # set the parameter constraint to be positive, when nothing is specified\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "\n",
    "        # register the constraint\n",
    "        self.register_constraint(\"raw_length\", length_constraint)\n",
    "\n",
    "        # set the parameter prior, see\n",
    "        # https://docs.gpytorch.ai/en/latest/module.html#gpytorch.Module.register_prior\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"length_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.length,\n",
    "                lambda m, v : m._set_length(v),\n",
    "            )\n",
    "\n",
    "    # now set up the 'actual' paramter\n",
    "    @property\n",
    "    def length(self):\n",
    "        # when accessing the parameter, apply the constraint transform\n",
    "        return self.raw_length_constraint.transform(self.raw_length)\n",
    "\n",
    "    @length.setter\n",
    "    def length(self, value):\n",
    "        return self._set_length(value)\n",
    "\n",
    "    def _set_length(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_length)\n",
    "        # when setting the paramater, transform the actual value to a raw one by applying the inverse transform\n",
    "        self.initialize(raw_length=self.raw_length_constraint.inverse_transform(value))\n",
    "\n",
    "    # this is the kernel function\n",
    "    def forward(self, x1, x2, **params):\n",
    "        # apply lengthscale\n",
    "        x1_ = x1.div(self.length)\n",
    "        x2_ = x2.div(self.length)\n",
    "        # calculate the distance between inputs\n",
    "        diff = self.covar_dist(x1_, x2_, **params)\n",
    "        # prevent divide by 0 errors\n",
    "        diff.where(diff == 0, torch.as_tensor(1e-20))\n",
    "        # return sinc(diff) = sin(diff) / diff\n",
    "        return torch.sin(diff).div(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f0514a6-7ee8-4441-bee5-1cb6cdd44796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the simplest form of GP model, exact inference\n",
    "class SincGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = SincKernel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fc210149-2cca-48ed-8afe-3f0ff3c679c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import positivity constraint\n",
    "from gpytorch.constraints import Positive\n",
    "\n",
    "class SincKernel(gpytorch.kernels.Kernel):\n",
    "    # the sinc kernel is stationary\n",
    "    is_stationary = True\n",
    "\n",
    "    # We will register the parameter when initializing the kernel\n",
    "    def __init__(self, length_prior=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # register the raw parameter\n",
    "        self.register_parameter(\n",
    "            name='raw_length', parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 8, 1))\n",
    "        )\n",
    "\n",
    "        # set the parameter constraint to be positive, when nothing is specified\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "\n",
    "        # register the constraint\n",
    "        self.register_constraint(\"raw_length\", length_constraint)\n",
    "\n",
    "        # set the parameter prior, see\n",
    "        # https://docs.gpytorch.ai/en/latest/module.html#gpytorch.Module.register_prior\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"length_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.length,\n",
    "                lambda m, v : m._set_length(v),\n",
    "            )\n",
    "\n",
    "    # now set up the 'actual' paramter\n",
    "    @property\n",
    "    def length(self):\n",
    "        # when accessing the parameter, apply the constraint transform\n",
    "        return self.raw_length_constraint.transform(self.raw_length)\n",
    "\n",
    "    @length.setter\n",
    "    def length(self, value):\n",
    "        return self._set_length(value)\n",
    "\n",
    "    def _set_length(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_length)\n",
    "        # when setting the paramater, transform the actual value to a raw one by applying the inverse transform\n",
    "        self.initialize(raw_length=self.raw_length_constraint.inverse_transform(value))\n",
    "\n",
    "    # this is the kernel function\n",
    "    def forward(self, x1, x2, **params):\n",
    "        # apply lengthscale\n",
    "        x1_ = x1.div(self.length.sum())\n",
    "        x2_ = x2.div(self.length.sum())\n",
    "        # calculate the distance between inputs\n",
    "        diff = self.covar_dist(x1_, x2_, **params)\n",
    "        # prevent divide by 0 errors\n",
    "        diff.where(diff == 0, torch.as_tensor(1e-20))\n",
    "        # return sinc(diff) = sin(diff) / diff\n",
    "        return torch.sin(diff).div(diff)\n",
    "    \n",
    "    def forward(self, x1, x2, **params):\n",
    "        D = (k.covar_dist(x1, x2)**2).round()/2\n",
    "        wkd = torch.stack([w(k, D, AA_size, L) for k in range(1, 8+1)])\n",
    "        K = (wkd * torch.exp(k.lda).view(8, 1, 1)).sum(0)\n",
    "        return K\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b44f5875-bc90-40fe-a4d9-82e645bd30ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def forward(self, x1, x2, **params):\n",
    "#         D = (k.covar_dist(x1, x2)**2).round()/2\n",
    "#         wkd = torch.stack([w(k, D, AA_size, L) for k in range(1, 8+1)])\n",
    "#         K = (wkd * torch.exp(k.lda).view(8, 1, 1)).sum(0)\n",
    "#         return K\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ee64e4c3-23cb-44a3-9072-34b91fe4a952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize the new model\n",
    "model = SincGPModel(x.cpu(), y.cpu(), likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "042825a8-bf4a-4989-b469-47b9045e73e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "69ff8e7c-5b25-44ba-8167-4567fb5d0b19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmll\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py:64\u001b[0m, in \u001b[0;36mExactMarginalLogLikelihood.forward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Get the log prob of the marginal distribution\u001b[39;00m\n\u001b[1;32m     63\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlikelihood(function_dist, \u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 64\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_other_terms(res, params)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Scale by the amount of data we have\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gpytorch/distributions/multivariate_normal.py:192\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    185\u001b[0m         covar \u001b[38;5;241m=\u001b[39m covar\u001b[38;5;241m.\u001b[39mrepeat(\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;241m*\u001b[39m(diff_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m covar_size \u001b[38;5;28;01mfor\u001b[39;00m diff_size, covar_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(diff\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], padded_batch_shape)),\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    189\u001b[0m         )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Get log determininant and first part of quadratic form\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m covar \u001b[38;5;241m=\u001b[39m \u001b[43mcovar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m inv_quad, logdet \u001b[38;5;241m=\u001b[39m covar\u001b[38;5;241m.\u001b[39minv_quad_logdet(inv_quad_rhs\u001b[38;5;241m=\u001b[39mdiff\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), logdet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    195\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m([inv_quad, logdet, diff\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi)])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/linear_operator/operators/added_diag_linear_operator.py:209\u001b[0m, in \u001b[0;36mAddedDiagLinearOperator.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_kernel\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 209\u001b[0m     added_diag_linear_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation())\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m added_diag_linear_op\u001b[38;5;241m.\u001b[39m_linear_op \u001b[38;5;241m+\u001b[39m added_diag_linear_op\u001b[38;5;241m.\u001b[39m_diag_tensor\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/linear_operator/operators/_linear_operator.py:2064\u001b[0m, in \u001b[0;36mLinearOperator.representation_tree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepresentation_tree\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LinearOperatorRepresentationTree:\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;124;03m    Returns a\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m    :obj:`linear_operator.operators.LinearOperatorRepresentationTree` tree\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2062\u001b[0m \u001b[38;5;124;03m    including all subobjects. This is used internally.\u001b[39;00m\n\u001b[1;32m   2063\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLinearOperatorRepresentationTree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/linear_operator/operators/linear_operator_representation_tree.py:15\u001b[0m, in \u001b[0;36mLinearOperatorRepresentationTree.__init__\u001b[0;34m(self, linear_op)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(linear_op\u001b[38;5;241m.\u001b[39m_args, linear_op\u001b[38;5;241m.\u001b[39m_differentiable_kwargs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepresentation\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(arg\u001b[38;5;241m.\u001b[39mrepresentation):  \u001b[38;5;66;03m# Is it a lazy tensor?\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m         representation_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mslice\u001b[39m(counter, counter \u001b[38;5;241m+\u001b[39m representation_size, \u001b[38;5;28;01mNone\u001b[39;00m), arg\u001b[38;5;241m.\u001b[39mrepresentation_tree()))\n\u001b[1;32m     17\u001b[0m         counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m representation_size\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:397\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.representation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrepresentation()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# Otherwise, we'll evaluate the kernel (or at least its LinearOperator representation) and use its\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# representation\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrepresentation()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:25\u001b[0m, in \u001b[0;36mrecall_grad_state.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_grad_enabled):\n\u001b[0;32m---> 25\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:355\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m     temp_active_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m temp_active_dims\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gpytorch/kernels/kernel.py:530\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    527\u001b[0m     res \u001b[38;5;241m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     res \u001b[38;5;241m=\u001b[39m to_linear_operator(\n\u001b[0;32m--> 530\u001b[0m         \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m     )\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "Cell \u001b[0;32mIn[112], line 65\u001b[0m, in \u001b[0;36mSincKernel.forward\u001b[0;34m(self, x1, x2, **params)\u001b[0m\n\u001b[1;32m     63\u001b[0m D \u001b[38;5;241m=\u001b[39m (k\u001b[38;5;241m.\u001b[39mcovar_dist(x1, x2)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mround()\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     64\u001b[0m wkd \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([w(k, D, AA_size, L) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m---> 65\u001b[0m K \u001b[38;5;241m=\u001b[39m (\u001b[43mwkd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlda\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "loss = mll(output, y.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "22b49cc6-7cb4-4da7-880f-6e8e75925ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7a00b355-6590-400c-93fc-872187467963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: likelihood.noise_covar.raw_noise, Gradient: None\n",
      "Parameter name: mean_module.raw_constant, Gradient: -0.0005533979274332523\n",
      "Parameter name: covar_module.raw_length, Gradient: tensor([[-0.0450],\n",
      "        [-0.0450],\n",
      "        [-0.0450],\n",
      "        [-0.0450],\n",
      "        [-0.0450],\n",
      "        [-0.0450],\n",
      "        [-0.0450],\n",
      "        [-0.0450]])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter name: {name}, Gradient: {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded4e40-c037-4bb1-ad0f-5e6f9217761d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a838041-51b1-4fe9-9022-5c7d04da2605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8712994a-a00d-4996-ad80-099e64da01d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10799e72-80be-4b81-a2f8-a7f12f5e0dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # set to training mode and train\n",
    "# model.train()\n",
    "# likelihood.train()\n",
    "# train(model, likelihood)\n",
    "\n",
    "# # Get into evaluation (predictive posterior) mode and predict\n",
    "# model.eval()\n",
    "# likelihood.eval()\n",
    "# observed_pred = predict(model, likelihood)\n",
    "# # plot results\n",
    "# plot(observed_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd347d-a8f0-406e-802c-19fc9961a0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
