{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "623e5d77-b740-4b8c-9d7f-c1e46605270e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 | 73% |  7% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% | 17% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% |  2% |\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "import random as rd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import GPUtil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append('../model')\n",
    "from utils import amino_acid_to_number, tokenize\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "def sgpu():\n",
    "    GPUtil.showUtilization()\n",
    "\n",
    "sgpu()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import GPUtil\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c3ec108-d434-4d64-9703-4b1bb0b31c11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "L, AA_size = 12, 2\n",
    "elements = [-1, 1]\n",
    "seqs = torch.tensor(list(product(elements, repeat=L)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e88b464d-1d0f-4535-b1b8-6a4400f0daa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seqs_ = torch.tensor(list(product([0, 1], repeat=L)))\n",
    "\n",
    "from torch.nn.functional import one_hot\n",
    "seqs1h = one_hot(seqs_)\n",
    "seqs1hf = seqs1h.view(-1, L*(AA_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c2e4a7-560c-45c5-b00b-be4ef439e90c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "order = 3\n",
    "\n",
    "def get_design_mat(order, n):\n",
    "    design_mat = []\n",
    "    for _ in range(n):\n",
    "        positions = rd.sample(range(L), order)\n",
    "        design_vec = torch.prod(seqs[:, positions], 1)\n",
    "        design_mat.append(design_vec)\n",
    "    design_mat = torch.stack(design_mat).T.float()\n",
    "    \n",
    "    return design_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f8ad109-2026-4789-aa08-89bc23985f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_pheno_epi(seqs, n_terms, stds):\n",
    "    designs = {}\n",
    "    coeffs = {}\n",
    "    phenos = {}\n",
    "    for order in n_terms.keys():\n",
    "        designs[order] = get_design_mat(order, n_terms[order])\n",
    "        coeffs[order] = torch.normal(0., stds[order], (n_terms[order], ))\n",
    "        phenos[order] = torch.matmul(designs[order], coeffs[order])\n",
    "    return designs, torch.sum(torch.stack(list(phenos.values())), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "305ed4d4-7a95-4adb-a8cb-214d40cf2aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_pheno_add(seqs, std):\n",
    "    X = seqs.float()\n",
    "    coeffs = torch.normal(0., std, (L, ))\n",
    "    return torch.matmul(X, coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6883e13f-d81d-4ef6-9e0b-204a0d5be364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_terms = {1:1000, 2: 100}\n",
    "# stds = {1: 1, 2: 1}\n",
    "\n",
    "n_terms = {2: 1000}\n",
    "stds = {2: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0058dd4-ae80-4d15-b070-121e4fe05ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 1])\n"
     ]
    }
   ],
   "source": [
    "designs, phenos_epi = simulate_pheno_epi(seqs, n_terms, stds)\n",
    "phenos_add = simulate_pheno_add(seqs, 1)\n",
    "phenotypes = phenos_epi + phenos_add\n",
    "phenotypes = phenotypes.unsqueeze(1)\n",
    "print(phenotypes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92d2a60e-6bad-404e-ae7b-e6a5f9cb9f69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(phenotypes.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72769519-810e-4d32-aace-4eea19104d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "class ProtDataset(data.Dataset):\n",
    "    def __init__(self, feats, labels, train=True):    \n",
    "        self.train = train\n",
    "        self.feats = feats\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.feats)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        X = self.feats[idx]\n",
    "        y = self.labels[idx]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "381269a8-909f-42e5-8ebc-4b5327b1a935",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3276\n",
      "3276\n",
      "820\n"
     ]
    }
   ],
   "source": [
    "# random sampling\n",
    "\n",
    "num_train = int(len(seqs)*.8)\n",
    "print(num_train)\n",
    "\n",
    "sub_list = np.random.choice(range(len(seqs)), num_train, replace=False)\n",
    "comp_list = list(set(range(len(seqs))).difference(sub_list))\n",
    "\n",
    "train_list = sub_list\n",
    "test_list = comp_list\n",
    "\n",
    "print(len(train_list))\n",
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6204c110-c6dc-4855-88d8-7491942f789f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3ee6a62-719a-4592-b1e4-1beaadf218f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3276, 24])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = seqs1hf.float().to(device)\n",
    "y = phenotypes.to(device)\n",
    "\n",
    "X_train, y_train = X[train_list], y[train_list]\n",
    "X_test, y_test = X[test_list], y[test_list]\n",
    "\n",
    "train_dataset = ProtDataset(X_train, y_train)\n",
    "train_loader = data.DataLoader(train_dataset,\n",
    "                               batch_size=1000,\n",
    "                               shuffle=True,\n",
    "                               drop_last=False)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b1bcdcf-ba3d-4522-846f-298e3f7292b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc = nn.Linear((AA_size)*L, 1)\n",
    "        self.sigmoid_norm = nn.BatchNorm1d(1, affine=False)                \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.sigmoid_scale = nn.Linear(1, 1)        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        # x = self.sigmoid_norm(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.sigmoid_scale(x)        \n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bbb69491-4554-476a-8c6b-632305c8731b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "model = LinearModel().cuda()\n",
    "output = model(x)\n",
    "\n",
    "plt.hist(output.detach().cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4364ea9a-9c1e-4d29-9733-cf85ce0884e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1184.0597839355469\n",
      "0.016811194188641267\n",
      "Epoch 11/100, Loss: 1213.5825500488281\n",
      "0.018065593057029008\n",
      "Epoch 21/100, Loss: 1196.3292846679688\n",
      "0.019840711352799866\n",
      "Epoch 31/100, Loss: 1199.4667053222656\n",
      "0.02155124164791301\n",
      "Epoch 41/100, Loss: 1184.7074584960938\n",
      "0.023467849964445\n",
      "Epoch 51/100, Loss: 1210.73193359375\n",
      "0.026301079333151203\n",
      "Epoch 61/100, Loss: 1171.6458435058594\n",
      "0.028936044472756522\n",
      "Epoch 71/100, Loss: 1187.3014221191406\n",
      "0.032183151885189075\n",
      "Epoch 81/100, Loss: 1191.5299682617188\n",
      "0.03611611838701464\n",
      "Epoch 91/100, Loss: 1181.5906677246094\n",
      "0.038492969245037645\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_inputs, batch_targets in train_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "        model.eval()\n",
    "        pred, true = model(X_test.flatten(1)).flatten().detach().cpu().numpy(), y_test.flatten().detach().cpu().numpy()\n",
    "        print(pearsonr(pred, true)[0]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1b002-9644-48e0-8077-c65f5c39c588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64c9a845-c640-45bb-94cf-4b75fc340dd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### torch Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8a1f8e1b-927c-447b-a74c-882437f8cb95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seqs_ex = seqs_ + AA_size*torch.tensor(range(L))\n",
    "\n",
    "X = seqs_ex.to(device)\n",
    "y = phenotypes.to(device)\n",
    "\n",
    "X_train, y_train = X[train_list], y[train_list]\n",
    "X_test, y_test = X[test_list], y[test_list]\n",
    "\n",
    "train_dataset = ProtDataset(X_train, y_train)\n",
    "train_loader = data.DataLoader(train_dataset,\n",
    "                               batch_size=1000,\n",
    "                               shuffle=True,\n",
    "                               drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "59bb852c-2af6-4ce6-a4bf-bc6062192deb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, dropout):\n",
    "        super(MultiHeadAttentionLayer, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(hidden_dim, num_heads, dropout)\n",
    "        # self.multihead_attn = MultiheadAttention(hidden_dim, hidden_dim, num_heads)        \n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.multihead_attn(x, x, x)\n",
    "        x = x + attn_output\n",
    "        # x = self.layer_norm(x + attn_output)\n",
    "        return x\n",
    "\n",
    "class CustomTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, dropout):\n",
    "        super(CustomTransformer, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        \n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            MultiHeadAttentionLayer(hidden_dim, num_heads, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        # self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.fc = nn.Linear(hidden_dim*L, 1)        \n",
    "        self.sigmoid_norm = nn.BatchNorm1d(1, affine=False)        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.phi_scaling = nn.Linear(1, 1)\n",
    "        self.sigmoid_scaling = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)  # seq_len x batch x hidden_dim\n",
    "        \n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        # x = torch.mean(x, dim=0)  # batch x hidden_dim\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = x.flatten(1)\n",
    "        # print(x.shape)\n",
    "        x = self.fc(x)  # batch x 1 (scalar)\n",
    "        x = self.sigmoid_norm(x)\n",
    "#         mean = torch.mean(x)\n",
    "#         std = torch.std(x)\n",
    "#         x = (x - mean) / std\n",
    "        \n",
    "        # x = self.phi_scaling(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.sigmoid_scaling(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "sequence_length = L\n",
    "input_dim = AA_size*L\n",
    "output_dim = 1\n",
    "hidden_dim = 2\n",
    "num_layers = 1\n",
    "num_heads = 1\n",
    "dropout = 0.3\n",
    "\n",
    "model = CustomTransformer(input_dim, hidden_dim, num_layers, num_heads, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0a3d1750-63c9-41ff-aa21-083a0d2b6653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "19378444-bb75-4a3a-8e05-c440bca9f8b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Loss: 1042.288101196289\n",
      "0.0032697029787237125\n",
      "Epoch 2/500, Loss: 1045.736083984375\n",
      "0.003939732804431683\n",
      "Epoch 3/500, Loss: 1038.0727081298828\n",
      "0.004715807346494847\n",
      "Epoch 4/500, Loss: 1039.7447967529297\n",
      "0.005500916438590647\n",
      "Epoch 5/500, Loss: 1056.541519165039\n",
      "0.006279383909729607\n",
      "Epoch 6/500, Loss: 1061.551498413086\n",
      "0.007065134318645049\n",
      "Epoch 7/500, Loss: 1049.4418029785156\n",
      "0.007819407929303388\n",
      "Epoch 8/500, Loss: 1076.4252624511719\n",
      "0.008600537005688884\n",
      "Epoch 9/500, Loss: 1040.5981903076172\n",
      "0.009340518363953462\n",
      "Epoch 10/500, Loss: 1039.7640686035156\n",
      "0.010047432491822118\n",
      "Epoch 11/500, Loss: 1066.8445434570312\n",
      "0.01072675795053937\n",
      "Epoch 12/500, Loss: 1049.4662628173828\n",
      "0.011386806901791039\n",
      "Epoch 13/500, Loss: 1036.5716094970703\n",
      "0.012097679293440326\n",
      "Epoch 14/500, Loss: 1053.3685150146484\n",
      "0.012748762851072008\n",
      "Epoch 15/500, Loss: 1034.0354614257812\n",
      "0.013380331710198047\n",
      "Epoch 16/500, Loss: 1042.5638732910156\n",
      "0.014050487067976215\n",
      "Epoch 17/500, Loss: 1046.3031005859375\n",
      "0.014706363431245293\n",
      "Epoch 18/500, Loss: 1035.1810913085938\n",
      "0.015274510878976199\n",
      "Epoch 19/500, Loss: 1031.7207946777344\n",
      "0.01583064515616677\n",
      "Epoch 20/500, Loss: 1030.735366821289\n",
      "0.016382137625759838\n",
      "Epoch 21/500, Loss: 1021.0679931640625\n",
      "0.016861162515137466\n",
      "Epoch 22/500, Loss: 1039.9137725830078\n",
      "0.01732239810709459\n",
      "Epoch 23/500, Loss: 1014.2299499511719\n",
      "0.01783805622336877\n",
      "Epoch 24/500, Loss: 1021.0470123291016\n",
      "0.018228585244156457\n",
      "Epoch 25/500, Loss: 1047.6962280273438\n",
      "0.018581713130976975\n",
      "Epoch 26/500, Loss: 1039.2076721191406\n",
      "0.018931609009894018\n",
      "Epoch 27/500, Loss: 1048.225357055664\n",
      "0.019302325138346815\n",
      "Epoch 28/500, Loss: 1032.2920684814453\n",
      "0.01965616277721634\n",
      "Epoch 29/500, Loss: 1036.0911102294922\n",
      "0.019960212980710785\n",
      "Epoch 30/500, Loss: 1054.2359313964844\n",
      "0.02029137596235321\n",
      "Epoch 31/500, Loss: 1032.4221954345703\n",
      "0.020564434818368598\n",
      "Epoch 32/500, Loss: 1046.0408782958984\n",
      "0.020807381924393877\n",
      "Epoch 33/500, Loss: 1037.9822235107422\n",
      "0.021027379774044945\n",
      "Epoch 34/500, Loss: 1015.1212615966797\n",
      "0.021313585206799653\n",
      "Epoch 35/500, Loss: 1022.1141967773438\n",
      "0.021657653931356415\n",
      "Epoch 36/500, Loss: 1035.8379669189453\n",
      "0.022044716519611176\n",
      "Epoch 37/500, Loss: 1034.5719604492188\n",
      "0.02247808552336521\n",
      "Epoch 38/500, Loss: 1034.93701171875\n",
      "0.022986889635678513\n",
      "Epoch 39/500, Loss: 1032.8054809570312\n",
      "0.023401008286030485\n",
      "Epoch 40/500, Loss: 1028.9938201904297\n",
      "0.023720105342424625\n",
      "Epoch 41/500, Loss: 1037.1080169677734\n",
      "0.024075431085460102\n",
      "Epoch 42/500, Loss: 1030.4043884277344\n",
      "0.024463848398843503\n",
      "Epoch 43/500, Loss: 1025.9351043701172\n",
      "0.02501024753849878\n",
      "Epoch 44/500, Loss: 1048.8061828613281\n",
      "0.025676605583691704\n",
      "Epoch 45/500, Loss: 1028.6097717285156\n",
      "0.026405795383650753\n",
      "Epoch 46/500, Loss: 1030.816162109375\n",
      "0.027248217908948994\n",
      "Epoch 47/500, Loss: 1042.716812133789\n",
      "0.028125026962576665\n",
      "Epoch 48/500, Loss: 1013.9745941162109\n",
      "0.02902708027013998\n",
      "Epoch 49/500, Loss: 1023.9187316894531\n",
      "0.030093802666162444\n",
      "Epoch 50/500, Loss: 1016.664306640625\n",
      "0.0312672390069269\n",
      "Epoch 51/500, Loss: 1045.4428100585938\n",
      "0.032702472368101414\n",
      "Epoch 52/500, Loss: 1031.5219268798828\n",
      "0.03420560554157419\n",
      "Epoch 53/500, Loss: 1049.5961151123047\n",
      "0.03594710905099272\n",
      "Epoch 54/500, Loss: 1028.6776275634766\n",
      "0.03800022047044736\n",
      "Epoch 55/500, Loss: 1019.3367614746094\n",
      "0.040191928714151254\n",
      "Epoch 56/500, Loss: 1006.3586730957031\n",
      "0.04279007436311358\n",
      "Epoch 57/500, Loss: 1020.4223327636719\n",
      "0.046139994338309925\n",
      "Epoch 58/500, Loss: 1054.2263488769531\n",
      "0.05027388900393516\n",
      "Epoch 59/500, Loss: 1020.0553741455078\n",
      "0.054157645130501496\n",
      "Epoch 60/500, Loss: 1040.5617980957031\n",
      "0.057995003676720655\n",
      "Epoch 61/500, Loss: 1027.3398895263672\n",
      "0.062223151798119\n",
      "Epoch 62/500, Loss: 1042.045639038086\n",
      "0.06754836343016002\n",
      "Epoch 63/500, Loss: 1045.2955780029297\n",
      "0.07374695050847639\n",
      "Epoch 64/500, Loss: 1037.082260131836\n",
      "0.07944384883242377\n",
      "Epoch 65/500, Loss: 1061.5250244140625\n",
      "0.08476025336004815\n",
      "Epoch 66/500, Loss: 1059.6842498779297\n",
      "0.09112231426381869\n",
      "Epoch 67/500, Loss: 1045.6866149902344\n",
      "0.09717793330812417\n",
      "Epoch 68/500, Loss: 1026.0127868652344\n",
      "0.10325577816412654\n",
      "Epoch 69/500, Loss: 1031.8311767578125\n",
      "0.1089494362861731\n",
      "Epoch 70/500, Loss: 1033.8695373535156\n",
      "0.11463230766469623\n",
      "Epoch 71/500, Loss: 1043.0055694580078\n",
      "0.12002445825912332\n",
      "Epoch 72/500, Loss: 1030.8446960449219\n",
      "0.12567776215792528\n",
      "Epoch 73/500, Loss: 1040.492172241211\n",
      "0.13012048840306967\n",
      "Epoch 74/500, Loss: 1037.199447631836\n",
      "0.13420998142403207\n",
      "Epoch 75/500, Loss: 1012.8267517089844\n",
      "0.13742538618480107\n",
      "Epoch 76/500, Loss: 1038.1382446289062\n",
      "0.1408799913396071\n",
      "Epoch 77/500, Loss: 1030.1455383300781\n",
      "0.14514620328864666\n",
      "Epoch 78/500, Loss: 1027.0552062988281\n",
      "0.14910355699486333\n",
      "Epoch 79/500, Loss: 1036.5199279785156\n",
      "0.1518226174035576\n",
      "Epoch 80/500, Loss: 1027.8558654785156\n",
      "0.15603231872300105\n",
      "Epoch 81/500, Loss: 1049.87841796875\n",
      "0.16108437739662237\n",
      "Epoch 82/500, Loss: 1050.4845275878906\n",
      "0.16605201340269315\n",
      "Epoch 83/500, Loss: 1036.1798553466797\n",
      "0.16804976400005298\n",
      "Epoch 84/500, Loss: 1045.8474731445312\n",
      "0.16929316669170005\n",
      "Epoch 85/500, Loss: 1028.1844940185547\n",
      "0.17148397782784267\n",
      "Epoch 86/500, Loss: 1022.4137725830078\n",
      "0.173421317576987\n",
      "Epoch 87/500, Loss: 1046.234130859375\n",
      "0.17424939746659882\n",
      "Epoch 88/500, Loss: 1022.1871948242188\n",
      "0.17675120117608287\n",
      "Epoch 89/500, Loss: 1033.9487762451172\n",
      "0.17993606044350108\n",
      "Epoch 90/500, Loss: 1032.3027038574219\n",
      "0.18334868430154805\n",
      "Epoch 91/500, Loss: 1046.5430603027344\n",
      "0.1854935014783562\n",
      "Epoch 92/500, Loss: 1053.2990417480469\n",
      "0.18812041791007458\n",
      "Epoch 93/500, Loss: 1037.693603515625\n",
      "0.19156702945344387\n",
      "Epoch 94/500, Loss: 1029.6407165527344\n",
      "0.19438205220025218\n",
      "Epoch 95/500, Loss: 1045.7330322265625\n",
      "0.1962651952552679\n",
      "Epoch 96/500, Loss: 1061.0601196289062\n",
      "0.19939080515983662\n",
      "Epoch 97/500, Loss: 1013.5618133544922\n",
      "0.20041978044491235\n",
      "Epoch 98/500, Loss: 1047.958724975586\n",
      "0.20208918537623038\n",
      "Epoch 99/500, Loss: 1031.8584442138672\n",
      "0.20167600982098158\n",
      "Epoch 100/500, Loss: 1005.1072692871094\n",
      "0.2026271216468868\n",
      "Epoch 101/500, Loss: 1040.8523406982422\n",
      "0.20340888873643606\n",
      "Epoch 102/500, Loss: 1006.9930877685547\n",
      "0.20664048172682775\n",
      "Epoch 103/500, Loss: 1048.4218444824219\n",
      "0.21028550029473472\n",
      "Epoch 104/500, Loss: 1040.998306274414\n",
      "0.2139581828543133\n",
      "Epoch 105/500, Loss: 1001.6581268310547\n",
      "0.2163982983615689\n",
      "Epoch 106/500, Loss: 1023.9646148681641\n",
      "0.2197877595121512\n",
      "Epoch 107/500, Loss: 1047.0694732666016\n",
      "0.22102117695195\n",
      "Epoch 108/500, Loss: 1072.133041381836\n",
      "0.22186146883836705\n",
      "Epoch 109/500, Loss: 1054.073013305664\n",
      "0.2241901194986218\n",
      "Epoch 110/500, Loss: 1060.4789428710938\n",
      "0.22589170197776529\n",
      "Epoch 111/500, Loss: 1038.1575012207031\n",
      "0.22734985293143847\n",
      "Epoch 112/500, Loss: 1034.2108612060547\n",
      "0.22865785724266213\n",
      "Epoch 113/500, Loss: 1045.9252624511719\n",
      "0.2309068333107786\n",
      "Epoch 114/500, Loss: 1040.9385223388672\n",
      "0.2333699205954954\n",
      "Epoch 115/500, Loss: 1013.2225036621094\n",
      "0.2343063891594163\n",
      "Epoch 116/500, Loss: 1042.3827514648438\n",
      "0.23297875763802522\n",
      "Epoch 117/500, Loss: 1036.7217102050781\n",
      "0.23086084413860816\n",
      "Epoch 118/500, Loss: 1027.9206085205078\n",
      "0.23140968379700627\n",
      "Epoch 119/500, Loss: 1023.5357666015625\n",
      "0.23133856156719065\n",
      "Epoch 120/500, Loss: 1044.3775482177734\n",
      "0.23133533149859217\n",
      "Epoch 121/500, Loss: 1037.4324035644531\n",
      "0.2315464367539485\n",
      "Epoch 122/500, Loss: 1043.962631225586\n",
      "0.23380942431880175\n",
      "Epoch 123/500, Loss: 1034.6488952636719\n",
      "0.23679205040513795\n",
      "Epoch 124/500, Loss: 1039.1395874023438\n",
      "0.23940879388902508\n",
      "Epoch 125/500, Loss: 1025.6141052246094\n",
      "0.24092695062457992\n",
      "Epoch 126/500, Loss: 1036.743637084961\n",
      "0.2440909028122933\n",
      "Epoch 127/500, Loss: 1030.3399810791016\n",
      "0.2479051976574612\n",
      "Epoch 128/500, Loss: 1047.6919860839844\n",
      "0.25088135498156194\n",
      "Epoch 129/500, Loss: 1041.8545227050781\n",
      "0.25068446473790157\n",
      "Epoch 130/500, Loss: 1038.7182312011719\n",
      "0.24905136921839852\n",
      "Epoch 131/500, Loss: 1017.9589385986328\n",
      "0.24794481484503358\n",
      "Epoch 132/500, Loss: 1028.9232482910156\n",
      "0.2486816863057522\n",
      "Epoch 133/500, Loss: 1026.8336486816406\n",
      "0.25151859468427606\n",
      "Epoch 134/500, Loss: 1055.5990447998047\n",
      "0.25437654648405195\n",
      "Epoch 135/500, Loss: 1037.6607666015625\n",
      "0.2581696460123923\n",
      "Epoch 136/500, Loss: 1054.6500854492188\n",
      "0.26049777023131543\n",
      "Epoch 137/500, Loss: 1052.9529418945312\n",
      "0.26312288490472807\n",
      "Epoch 138/500, Loss: 1033.920394897461\n",
      "0.2654384074836699\n",
      "Epoch 139/500, Loss: 1034.8688049316406\n",
      "0.2689713378409984\n",
      "Epoch 140/500, Loss: 1032.8223419189453\n",
      "0.27357549462152586\n",
      "Epoch 141/500, Loss: 1038.9182739257812\n",
      "0.27650004126098526\n",
      "Epoch 142/500, Loss: 1079.5721282958984\n",
      "0.2789523984305228\n",
      "Epoch 143/500, Loss: 1034.6783752441406\n",
      "0.27976282106968037\n",
      "Epoch 144/500, Loss: 1049.1085357666016\n",
      "0.2800941145977391\n",
      "Epoch 145/500, Loss: 1004.5371704101562\n",
      "0.2787149877490594\n",
      "Epoch 146/500, Loss: 1037.558822631836\n",
      "0.2774925451562517\n",
      "Epoch 147/500, Loss: 1044.5983428955078\n",
      "0.2785171745384929\n",
      "Epoch 148/500, Loss: 1051.0362091064453\n",
      "0.2828063775061458\n",
      "Epoch 149/500, Loss: 1029.0530853271484\n",
      "0.28711604051949235\n",
      "Epoch 150/500, Loss: 1039.0997772216797\n",
      "0.2917080268311376\n",
      "Epoch 151/500, Loss: 1016.1202392578125\n",
      "0.2962172378686599\n",
      "Epoch 152/500, Loss: 1031.2225036621094\n",
      "0.30025712103934216\n",
      "Epoch 153/500, Loss: 1043.6743469238281\n",
      "0.302938264955172\n",
      "Epoch 154/500, Loss: 1031.3970031738281\n",
      "0.3051047551787115\n",
      "Epoch 155/500, Loss: 1048.1124114990234\n",
      "0.30775036406477946\n",
      "Epoch 156/500, Loss: 1006.7007293701172\n",
      "0.3126947575405145\n",
      "Epoch 157/500, Loss: 1036.7084197998047\n",
      "0.3162755991002323\n",
      "Epoch 158/500, Loss: 1050.317611694336\n",
      "0.31864836299250926\n",
      "Epoch 159/500, Loss: 1024.6651000976562\n",
      "0.3201460692108012\n",
      "Epoch 160/500, Loss: 1027.083999633789\n",
      "0.32114683113038306\n",
      "Epoch 161/500, Loss: 1028.4778594970703\n",
      "0.32359129371856166\n",
      "Epoch 162/500, Loss: 1060.7838134765625\n",
      "0.3259356339401814\n",
      "Epoch 163/500, Loss: 1036.4088897705078\n",
      "0.3272146549372625\n",
      "Epoch 164/500, Loss: 1020.1954956054688\n",
      "0.32866801253875366\n",
      "Epoch 165/500, Loss: 1034.632308959961\n",
      "0.3296028422881788\n",
      "Epoch 166/500, Loss: 1032.1331329345703\n",
      "0.3299155555340187\n",
      "Epoch 167/500, Loss: 1048.7445068359375\n",
      "0.33062567046485\n",
      "Epoch 168/500, Loss: 1015.5282135009766\n",
      "0.3320966158136941\n",
      "Epoch 169/500, Loss: 1023.7196807861328\n",
      "0.33288692387577257\n",
      "Epoch 170/500, Loss: 1022.2613372802734\n",
      "0.33470893998966655\n",
      "Epoch 171/500, Loss: 1039.1924133300781\n",
      "0.33626437375610196\n",
      "Epoch 172/500, Loss: 1033.2966766357422\n",
      "0.3376338184615534\n",
      "Epoch 173/500, Loss: 1041.770263671875\n",
      "0.33913475058803483\n",
      "Epoch 174/500, Loss: 1028.312744140625\n",
      "0.3403759658064447\n",
      "Epoch 175/500, Loss: 1040.7245330810547\n",
      "0.3409457779232787\n",
      "Epoch 176/500, Loss: 1038.2061920166016\n",
      "0.3424283544530908\n",
      "Epoch 177/500, Loss: 1043.4203186035156\n",
      "0.3462248908678526\n",
      "Epoch 178/500, Loss: 1053.3607940673828\n",
      "0.3480291968497253\n",
      "Epoch 179/500, Loss: 1043.5066680908203\n",
      "0.34746669127030644\n",
      "Epoch 180/500, Loss: 1021.5178833007812\n",
      "0.34762849064350615\n",
      "Epoch 181/500, Loss: 1033.9229583740234\n",
      "0.3492227176842621\n",
      "Epoch 182/500, Loss: 1039.2975311279297\n",
      "0.34999872653352654\n",
      "Epoch 183/500, Loss: 1042.4231414794922\n",
      "0.35055326674417664\n",
      "Epoch 184/500, Loss: 1012.8700866699219\n",
      "0.3514561700749543\n",
      "Epoch 185/500, Loss: 1031.353500366211\n",
      "0.3515267394486133\n",
      "Epoch 186/500, Loss: 1040.582763671875\n",
      "0.3523939089152208\n",
      "Epoch 187/500, Loss: 1040.0743408203125\n",
      "0.35168846279258914\n",
      "Epoch 188/500, Loss: 1011.4880981445312\n",
      "0.35090026455051565\n",
      "Epoch 189/500, Loss: 1044.3520812988281\n",
      "0.35084199038681413\n",
      "Epoch 190/500, Loss: 1031.7683563232422\n",
      "0.3525480855568206\n",
      "Epoch 191/500, Loss: 1045.0695190429688\n",
      "0.35326025255794075\n",
      "Epoch 192/500, Loss: 1050.96826171875\n",
      "0.3535546543961168\n",
      "Epoch 193/500, Loss: 1017.2649993896484\n",
      "0.35363652591404554\n",
      "Epoch 194/500, Loss: 1003.2427673339844\n",
      "0.3528053930631505\n",
      "Epoch 195/500, Loss: 1042.6526336669922\n",
      "0.3518225424955738\n",
      "Epoch 196/500, Loss: 1015.2200622558594\n",
      "0.3524838907749479\n",
      "Epoch 197/500, Loss: 1015.0615539550781\n",
      "0.35372960490142025\n",
      "Epoch 198/500, Loss: 1008.8934478759766\n",
      "0.35530678468138077\n",
      "Epoch 199/500, Loss: 1025.835433959961\n",
      "0.3565312867941857\n",
      "Epoch 200/500, Loss: 1000.6864776611328\n",
      "0.35665539956540143\n",
      "Epoch 201/500, Loss: 1027.7191009521484\n",
      "0.35690787012641223\n",
      "Epoch 202/500, Loss: 1043.2439575195312\n",
      "0.3564590751377838\n",
      "Epoch 203/500, Loss: 1034.1859130859375\n",
      "0.35403572673818434\n",
      "Epoch 204/500, Loss: 1053.0882568359375\n",
      "0.35204221091689675\n",
      "Epoch 205/500, Loss: 1022.9286193847656\n",
      "0.3532525774070315\n",
      "Epoch 206/500, Loss: 1032.6042022705078\n",
      "0.35425528692361125\n",
      "Epoch 207/500, Loss: 1038.731948852539\n",
      "0.3549704798989929\n",
      "Epoch 208/500, Loss: 1044.8745574951172\n",
      "0.35564785697994306\n",
      "Epoch 209/500, Loss: 1011.8756713867188\n",
      "0.35534146360428626\n",
      "Epoch 210/500, Loss: 1021.5798645019531\n",
      "0.35386040147747166\n",
      "Epoch 211/500, Loss: 1006.3449249267578\n",
      "0.3533106789573298\n",
      "Epoch 212/500, Loss: 1012.0464782714844\n",
      "0.35248535029766465\n",
      "Epoch 213/500, Loss: 1030.4600219726562\n",
      "0.35239152975749033\n",
      "Epoch 214/500, Loss: 1042.9069519042969\n",
      "0.35274904378450195\n",
      "Epoch 215/500, Loss: 1038.8453063964844\n",
      "0.35280507341408407\n",
      "Epoch 216/500, Loss: 1028.548812866211\n",
      "0.3529771697209896\n",
      "Epoch 217/500, Loss: 1045.7951202392578\n",
      "0.3533884642029183\n",
      "Epoch 218/500, Loss: 1014.0205993652344\n",
      "0.3527767312657041\n",
      "Epoch 219/500, Loss: 1025.1859893798828\n",
      "0.3525456374322698\n",
      "Epoch 220/500, Loss: 1026.8345489501953\n",
      "0.353051162333416\n",
      "Epoch 221/500, Loss: 1010.3268585205078\n",
      "0.353486127754091\n",
      "Epoch 222/500, Loss: 1031.4608306884766\n",
      "0.3549169181535055\n",
      "Epoch 223/500, Loss: 1026.470962524414\n",
      "0.35518261256036243\n",
      "Epoch 224/500, Loss: 1046.960922241211\n",
      "0.35538397115763537\n",
      "Epoch 225/500, Loss: 1018.6094665527344\n",
      "0.35426767682004273\n",
      "Epoch 226/500, Loss: 1078.0079498291016\n",
      "0.3526190912489098\n",
      "Epoch 227/500, Loss: 1043.3866882324219\n",
      "0.35181468008547767\n",
      "Epoch 228/500, Loss: 1040.9194030761719\n",
      "0.35226262331711655\n",
      "Epoch 229/500, Loss: 1048.7459106445312\n",
      "0.35417927216914896\n",
      "Epoch 230/500, Loss: 1034.817626953125\n",
      "0.3563906811205952\n",
      "Epoch 231/500, Loss: 1026.7506256103516\n",
      "0.35681164862165343\n",
      "Epoch 232/500, Loss: 1043.5352783203125\n",
      "0.35733096407758685\n",
      "Epoch 233/500, Loss: 1044.5106811523438\n",
      "0.3575600661275389\n",
      "Epoch 234/500, Loss: 1038.849624633789\n",
      "0.3570289667281177\n",
      "Epoch 235/500, Loss: 1020.3526000976562\n",
      "0.3567364295086334\n",
      "Epoch 236/500, Loss: 1015.8831024169922\n",
      "0.3554848519827658\n",
      "Epoch 237/500, Loss: 1028.9600982666016\n",
      "0.3561856184900848\n",
      "Epoch 238/500, Loss: 1040.9434661865234\n",
      "0.3570120638454361\n",
      "Epoch 239/500, Loss: 1022.5074310302734\n",
      "0.358160523370581\n",
      "Epoch 240/500, Loss: 1023.6951751708984\n",
      "0.35776979200872333\n",
      "Epoch 241/500, Loss: 1050.3348236083984\n",
      "0.3578685657217311\n",
      "Epoch 242/500, Loss: 1037.6997528076172\n",
      "0.3577622159008638\n",
      "Epoch 243/500, Loss: 1015.4819946289062\n",
      "0.35630652397517276\n",
      "Epoch 244/500, Loss: 1011.0221710205078\n",
      "0.35461677300305805\n",
      "Epoch 245/500, Loss: 1016.7317962646484\n",
      "0.35386288808523114\n",
      "Epoch 246/500, Loss: 1016.7642059326172\n",
      "0.3535135473235072\n",
      "Epoch 247/500, Loss: 1045.5022430419922\n",
      "0.3548029309600157\n",
      "Epoch 248/500, Loss: 1025.2579193115234\n",
      "0.35536885854038947\n",
      "Epoch 249/500, Loss: 1031.6051330566406\n",
      "0.35651209039104287\n",
      "Epoch 250/500, Loss: 1027.2420654296875\n",
      "0.35667821901726926\n",
      "Epoch 251/500, Loss: 1013.4129943847656\n",
      "0.3561704826389566\n",
      "Epoch 252/500, Loss: 1018.3044128417969\n",
      "0.354425795163706\n",
      "Epoch 253/500, Loss: 1007.1944122314453\n",
      "0.3533586359201789\n",
      "Epoch 254/500, Loss: 1013.6835174560547\n",
      "0.35371854838791\n",
      "Epoch 255/500, Loss: 1017.6100616455078\n",
      "0.3544861756052731\n",
      "Epoch 256/500, Loss: 1041.3956146240234\n",
      "0.3551945855193439\n",
      "Epoch 257/500, Loss: 1034.9315948486328\n",
      "0.35602817795169833\n",
      "Epoch 258/500, Loss: 1011.5258483886719\n",
      "0.35639376836006476\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     10\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_inputs, batch_targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(batch_inputs)\n",
      "File \u001b[0;32m/apps/pytorch/2.0.1/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/apps/pytorch/2.0.1/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/apps/pytorch/2.0.1/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/apps/pytorch/2.0.1/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/apps/pytorch/2.0.1/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:139\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "learning_rate = 0.001\n",
    "epochs = 500\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_inputs, batch_targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "        model.eval()\n",
    "        pred, true = model(X_test.flatten(1)).flatten().detach().cpu().numpy(), y_test.flatten().detach().cpu().numpy()\n",
    "        print(pearsonr(pred, true)[0]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e1727-98fe-4d3f-80ab-e3a4b33d92bf",
   "metadata": {},
   "source": [
    "### Custom multiheadattention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bce8ff10-1b8d-4a7f-8abc-fde5b0904345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seqs_ex = seqs_ + AA_size*torch.tensor(range(L))\n",
    "\n",
    "X = seqs_ex.to(device)\n",
    "y = phenotypes.to(device)\n",
    "\n",
    "X_train, y_train = X[train_list], y[train_list]\n",
    "X_test, y_test = X[test_list], y[test_list]\n",
    "\n",
    "train_dataset = ProtDataset(X_train, y_train)\n",
    "train_loader = data.DataLoader(train_dataset,\n",
    "                               batch_size=1000,\n",
    "                               shuffle=True,\n",
    "                               drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "050607a8-c6e0-4ed7-964f-1c77b93be7e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Efficient implementation equivalent to the following:\n",
    "def scaled_dot_product_attention(query, key, value, attn_mask=None, dropout_p=0.0, is_causal=False, scale=None) -> torch.Tensor:\n",
    "    # Efficient implementation equivalent to the following:\n",
    "    L, S = query.size(-2), key.size(-2)\n",
    "    scale_factor = 1 / math.sqrt(query.size(-1)) if scale is None else scale\n",
    "    attn_bias = torch.zeros(L, S, dtype=query.dtype)\n",
    "    if is_causal:\n",
    "        assert attn_mask is None\n",
    "        temp_mask = torch.ones(L, S, dtype=torch.bool).tril(diagonal=0)\n",
    "        attn_bias.masked_fill_(temp_mask.logical_not(), float(\"-inf\"))\n",
    "        attn_bias.to(query.dtype)\n",
    "\n",
    "    if attn_mask is not None:\n",
    "        if attn_mask.dtype == torch.bool:\n",
    "            attn_mask.masked_fill_(attn_mask.logical_not(), float(\"-inf\"))\n",
    "        else:\n",
    "            attn_bias += attn_mask\n",
    "    attn_weight = query @ key.transpose(-2, -1) * scale_factor\n",
    "    attn_weight += attn_bias\n",
    "    attn_weight = torch.softmax(attn_weight, dim=-1)\n",
    "    attn_weight = torch.dropout(attn_weight, dropout_p, train=True)\n",
    "    return attn_weight @ value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f7c47ba8-39ee-4491-bf86-4a4c5a0be097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim=512, n_heads=8, dropout=.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_dim: dimension of embeding vector output\n",
    "            n_heads: number of self attention heads\n",
    "        \"\"\"\n",
    "        super(CustomMultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim    #512 dim\n",
    "        self.n_heads = n_heads   #8\n",
    "        self.single_head_dim = int(self.embed_dim / self.n_heads)   #512/8 = 64  . each key,query, value will be of 64d\n",
    "       \n",
    "        #key,query and value matrixes    #64 x 64   \n",
    "        self.query_matrix = nn.Linear(self.single_head_dim , self.single_head_dim ,bias=False)  # single key matrix for all 8 keys #512x512\n",
    "        self.key_matrix = nn.Linear(self.single_head_dim  , self.single_head_dim, bias=False)\n",
    "        self.value_matrix = nn.Linear(self.single_head_dim ,self.single_head_dim , bias=False)\n",
    "        self.out = nn.Linear(self.n_heads*self.single_head_dim ,self.embed_dim) \n",
    "\n",
    "    def forward(self,key,query,value,mask=None):    #batch_size x sequence_length x embedding_dim    # 32 x 10 x 512\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "           key : key vector\n",
    "           query : query vector\n",
    "           value : value vector\n",
    "           mask: mask for decoder\n",
    "        \n",
    "        Returns:\n",
    "           output vector from multihead attention\n",
    "        \"\"\"\n",
    "        batch_size = key.size(0)\n",
    "        seq_length = key.size(1)\n",
    "        \n",
    "        # query dimension can change in decoder during inference. \n",
    "        # so we cant take general seq_length\n",
    "        seq_length_query = query.size(1)\n",
    "        \n",
    "        # 32x10x512\n",
    "        key = key.view(batch_size, seq_length, self.n_heads, self.single_head_dim)  #batch_size x sequence_length x n_heads x single_head_dim = (32x10x8x64)\n",
    "        query = query.view(batch_size, seq_length_query, self.n_heads, self.single_head_dim) #(32x10x8x64)\n",
    "        value = value.view(batch_size, seq_length, self.n_heads, self.single_head_dim) #(32x10x8x64)\n",
    "       \n",
    "        k = self.key_matrix(key)       # (32x10x8x64)\n",
    "        q = self.query_matrix(query)   \n",
    "        v = self.value_matrix(value)\n",
    "\n",
    "        q = q.transpose(1,2)  # (batch_size, n_heads, seq_len, single_head_dim)    # (32 x 8 x 10 x 64)\n",
    "        k = k.transpose(1,2)  # (batch_size, n_heads, seq_len, single_head_dim)\n",
    "        v = v.transpose(1,2)  # (batch_size, n_heads, seq_len, single_head_dim)\n",
    "       \n",
    "        # computes attention\n",
    "        # adjust key for matrix multiplication\n",
    "        k_adjusted = k.transpose(-1,-2)  #(batch_size, n_heads, single_head_dim, seq_ken)  #(32 x 8 x 64 x 10)\n",
    "        product = torch.matmul(q, k_adjusted)  #(32 x 8 x 10 x 64) x (32 x 8 x 64 x 10) = #(32x8x10x10)\n",
    "      \n",
    "        \n",
    "        # fill those positions of product matrix as (-1e20) where mask positions are 0\n",
    "        if mask is not None:\n",
    "             product = product.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        #divising by square root of key dimension\n",
    "        product = product / math.sqrt(self.single_head_dim) # / sqrt(64)\n",
    "\n",
    "        #applying softmax\n",
    "        scores = product\n",
    "        # scores = F.softmax(product, dim=-1)\n",
    "        \n",
    "        print(v.shape)\n",
    " \n",
    "        #mutiply with value matrix\n",
    "        scores = torch.matmul(scores, v)  ##(32x8x 10x 10) x (32 x 8 x 10 x 64) = (32 x 8 x 10 x 64) \n",
    "        \n",
    "        #concatenated output\n",
    "        concat = scores.transpose(1,2).contiguous().view(batch_size, seq_length_query, self.single_head_dim*self.n_heads)  # (32x8x10x64) -> (32x10x8x64)  -> (32,10,512)\n",
    "        \n",
    "        output = self.out(concat) #(32,10,512) -> (32,10,512)\n",
    "       \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "08e85138-9b45-4921-a00d-c0ad20bfe6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attn = CustomMultiHeadAttention(hidden_dim, num_heads, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4b0fd65c-560f-4648-8a47-5531d59cd224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.rand(10, L, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7307fa14-9bb6-44b5-8078-b6a0c3f8058c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, dropout):\n",
    "        super(CustomTransformer, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        \n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            CustomMultiHeadAttention(hidden_dim, num_heads, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc = nn.Linear(hidden_dim*L, 1)        \n",
    "        self.sigmoid_norm = nn.BatchNorm1d(1, affine=False)        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.phi_scaling = nn.Linear(1, 1)\n",
    "        self.sigmoid_scaling = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        # x = x.permute(1, 0, 2)  # seq_len x batch x hidden_dim\n",
    "        \n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x, x, x)\n",
    "            \n",
    "        # x = x.permute(1, 0, 2)\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc(x)  \n",
    "        x = self.sigmoid_norm(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.sigmoid_scaling(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "77a540a5-d2ad-4117-b20e-cc8758f99525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length = L\n",
    "input_dim = AA_size*L\n",
    "output_dim = 1\n",
    "hidden_dim = 128\n",
    "num_layers = 1\n",
    "num_heads = 4\n",
    "dropout = 0.3\n",
    "\n",
    "model = CustomTransformer(input_dim, hidden_dim, num_layers, num_heads, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d9d391ef-b008-4610-8430-934deef7f728",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "Epoch 1/500, Loss: 1025.3250427246094\n",
      "torch.Size([820, 4, 12, 32])\n",
      "0.4946459563032324\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "Epoch 11/500, Loss: 1025.6119079589844\n",
      "torch.Size([820, 4, 12, 32])\n",
      "0.9722833801355173\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "Epoch 21/500, Loss: 1031.201400756836\n",
      "torch.Size([820, 4, 12, 32])\n",
      "0.9716663568880531\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "Epoch 31/500, Loss: 1014.0341491699219\n",
      "torch.Size([820, 4, 12, 32])\n",
      "0.9723929305501404\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "Epoch 41/500, Loss: 997.9407653808594\n",
      "torch.Size([820, 4, 12, 32])\n",
      "0.9697112304491445\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "Epoch 51/500, Loss: 1013.8538055419922\n",
      "torch.Size([820, 4, 12, 32])\n",
      "0.9736425427105742\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "Epoch 61/500, Loss: 988.7095642089844\n",
      "torch.Size([820, 4, 12, 32])\n",
      "0.9689630261729921\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([276, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n",
      "torch.Size([1000, 4, 12, 32])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[218], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_targets)\n\u001b[1;32m     15\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 16\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/apps/pytorch/2.0.1/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/apps/pytorch/2.0.1/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/apps/pytorch/2.0.1/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/apps/pytorch/2.0.1/lib/python3.10/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/apps/pytorch/2.0.1/lib/python3.10/site-packages/torch/optim/adam.py:448\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    445\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_mul_(device_exp_avgs, beta1)\n\u001b[1;32m    446\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(device_exp_avgs, device_grads, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 448\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_addcmul_(device_exp_avg_sqs, device_grads, device_grads, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# TODO: use foreach_pow if/when foreach_pow is added\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "learning_rate = 0.01\n",
    "epochs = 500\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_inputs, batch_targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "        model.eval()\n",
    "        pred, true = model(X_test.flatten(1)).flatten().detach().cpu().numpy(), y_test.flatten().detach().cpu().numpy()\n",
    "        print(pearsonr(pred, true)[0]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dea51d-08df-40d5-b12e-790629ba943b",
   "metadata": {},
   "source": [
    "### Modified attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2ba493aa-47e7-4d46-bcd5-db0b3f58c96e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim=512, n_heads=8, dropout=.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_dim: dimension of embeding vector output\n",
    "            n_heads: number of self attention heads\n",
    "        \"\"\"\n",
    "        super(CustomMultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim    #512 dim\n",
    "        self.n_heads = n_heads   #8\n",
    "        self.single_head_dim = int(self.embed_dim / self.n_heads)   #512/8 = 64  . each key,query, value will be of 64d\n",
    "       \n",
    "        #key,query and value matrixes    #64 x 64   \n",
    "        self.query_matrix = nn.Linear(self.single_head_dim , self.single_head_dim ,bias=False)  # single key matrix for all 8 keys #512x512\n",
    "        self.key_matrix = nn.Linear(self.single_head_dim  , self.single_head_dim, bias=False)\n",
    "        self.value_matrix = nn.Linear(self.single_head_dim ,self.single_head_dim , bias=False)\n",
    "        self.out = nn.Linear(self.n_heads*self.single_head_dim ,self.embed_dim) \n",
    "\n",
    "    def forward(self,key,query,value,V, mask=None):    #batch_size x sequence_length x embedding_dim    # 32 x 10 x 512\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "           key : key vector\n",
    "           query : query vector\n",
    "           value : value vector\n",
    "           mask: mask for decoder\n",
    "        \n",
    "        Returns:\n",
    "           output vector from multihead attention\n",
    "        \"\"\"\n",
    "        batch_size = key.size(0)\n",
    "        seq_length = key.size(1)\n",
    "        \n",
    "        # query dimension can change in decoder during inference. \n",
    "        # so we cant take general seq_length\n",
    "        seq_length_query = query.size(1)\n",
    "        \n",
    "        # 32x10x512\n",
    "        key = key.view(batch_size, seq_length, self.n_heads, self.single_head_dim)  #batch_size x sequence_length x n_heads x single_head_dim = (32x10x8x64)\n",
    "        query = query.view(batch_size, seq_length_query, self.n_heads, self.single_head_dim) #(32x10x8x64)\n",
    "        value = value.view(batch_size, seq_length, self.n_heads, self.single_head_dim) #(32x10x8x64)\n",
    "       \n",
    "        k = self.key_matrix(key)       # (32x10x8x64)\n",
    "        q = self.query_matrix(query)   \n",
    "        v = self.value_matrix(value)\n",
    "\n",
    "        q = q.transpose(1,2)  # (batch_size, n_heads, seq_len, single_head_dim)    # (32 x 8 x 10 x 64)\n",
    "        k = k.transpose(1,2)  # (batch_size, n_heads, seq_len, single_head_dim)\n",
    "        v = v.transpose(1,2)  # (batch_size, n_heads, seq_len, single_head_dim)\n",
    "       \n",
    "        # computes attention\n",
    "        # adjust key for matrix multiplication\n",
    "        k_adjusted = k.transpose(-1,-2)  #(batch_size, n_heads, single_head_dim, seq_ken)  #(32 x 8 x 64 x 10)\n",
    "        product = torch.matmul(q, k_adjusted)  #(32 x 8 x 10 x 64) x (32 x 8 x 64 x 10) = #(32x8x10x10)\n",
    "      \n",
    "        \n",
    "        # fill those positions of product matrix as (-1e20) where mask positions are 0\n",
    "        if mask is not None:\n",
    "             product = product.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        #divising by square root of key dimension\n",
    "        product = product / math.sqrt(self.single_head_dim) # / sqrt(64)\n",
    "\n",
    "        #applying softmax\n",
    "        scores = product\n",
    "        # scores = F.softmax(product, dim=-1)\n",
    "        \n",
    "        V_ = V.view(batch_size, seq_length, self.n_heads, self.single_head_dim).transpose(1,2)\n",
    " \n",
    "        #mutiply with value matrix\n",
    "        scores = torch.matmul(scores, V_)  ##(32x8x 10x 10) x (32 x 8 x 10 x 64) = (32 x 8 x 10 x 64) \n",
    "        \n",
    "        #concatenated output\n",
    "        concat = scores.transpose(1,2).contiguous().view(batch_size, seq_length_query, self.single_head_dim*self.n_heads)  # (32x8x10x64) -> (32x10x8x64)  -> (32,10,512)\n",
    "        \n",
    "        output = self.out(concat) #(32,10,512) -> (32,10,512)\n",
    "       \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "eebdb5b8-219e-49b2-bf38-9eff3a7948f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attn = CustomMultiHeadAttention(hidden_dim, num_heads, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d7befaee-8553-4b14-a84c-6048aed19a13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.rand(10, L, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0f087832-8b2d-44a5-8006-58519a539c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, dropout):\n",
    "        super(CustomTransformer, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        \n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            CustomMultiHeadAttention(hidden_dim, num_heads, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc = nn.Linear(hidden_dim*L, 1)        \n",
    "        self.sigmoid_norm = nn.BatchNorm1d(1, affine=False)        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.phi_scaling = nn.Linear(1, 1)\n",
    "        self.sigmoid_scaling = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        V = x\n",
    "        # x = x.permute(1, 0, 2)  # seq_len x batch x hidden_dim\n",
    "        \n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x, x, x, V)\n",
    "            \n",
    "        # x = x.permute(1, 0, 2)\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc(x)  \n",
    "        x = self.sigmoid_norm(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.sigmoid_scaling(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "886cec6d-b9a3-4062-b2d0-39b007e0913f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length = L\n",
    "input_dim = AA_size*L\n",
    "output_dim = 1\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "num_heads = 4\n",
    "dropout = 0.3\n",
    "\n",
    "model = CustomTransformer(input_dim, hidden_dim, num_layers, num_heads, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1dfb65dc-d66e-4470-802d-84bd4731f5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Loss: 1024.9734497070312\n",
      "0.646021763278786\n",
      "Epoch 11/500, Loss: 1032.565185546875\n",
      "0.963778127504474\n",
      "Epoch 21/500, Loss: 998.0761260986328\n",
      "0.9714212180789416\n",
      "Epoch 31/500, Loss: 975.8685455322266\n",
      "0.9637386104039538\n",
      "Epoch 41/500, Loss: 985.6015167236328\n",
      "0.9616150240699377\n",
      "Epoch 51/500, Loss: 1002.05224609375\n",
      "0.9604381029173191\n",
      "Epoch 61/500, Loss: 994.6170806884766\n",
      "0.9582491267320739\n",
      "Epoch 71/500, Loss: 999.4447326660156\n",
      "0.9523356783602878\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[227], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(batch_inputs)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_targets)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/apps/pytorch/2.0.1/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/apps/pytorch/2.0.1/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "learning_rate = 0.01\n",
    "epochs = 500\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_inputs, batch_targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "        model.eval()\n",
    "        pred, true = model(X_test.flatten(1)).flatten().detach().cpu().numpy(), y_test.flatten().detach().cpu().numpy()\n",
    "        print(pearsonr(pred, true)[0]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a621e-8876-450a-ace8-70825c8920bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
