{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d30ca4fe-8d2d-419e-9be5-4544f101e911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AA_size = seqs1h.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0e01b38-b0b4-4769-a572-28c091d6b32f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seqs_ex = seqs + AA_size*torch.tensor(range(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "662f0c54-c801-4b69-b441-7ed0fae8d56c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 400\n",
    "\n",
    "X = seqs_ex.to(device)\n",
    "y = phenotypes.to(device)\n",
    "\n",
    "X_train, y_train = X[train_list], y[train_list]\n",
    "X_test, y_test = X[test_list], y[test_list]\n",
    "\n",
    "train_dataset = ProtDataset(X_train, y_train)\n",
    "train_loader = data.DataLoader(train_dataset,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True,\n",
    "                               drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f59026a5-8a8b-4fc5-8b7e-3e1c4fc00a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, dropout):\n",
    "        super(MultiHeadAttentionLayer, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(hidden_dim, num_heads, dropout)\n",
    "        # self.multihead_attn = MultiheadAttention(hidden_dim, hidden_dim, num_heads)        \n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.multihead_attn(x, x, x)\n",
    "        x = x + attn_output\n",
    "        # x = self.layer_norm(x + attn_output)\n",
    "        return x\n",
    "\n",
    "class CustomTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, dropout):\n",
    "        super(CustomTransformer, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        \n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            MultiHeadAttentionLayer(hidden_dim, num_heads, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        # self.fc = nn.Linear(hidden_dim*L, 1)        \n",
    "        self.sigmoid_norm = nn.BatchNorm1d(1, affine=False)        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.phi_scaling = nn.Linear(1, 1)\n",
    "        self.sigmoid_scaling = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)  # seq_len x batch x hidden_dim\n",
    "        \n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = torch.mean(x, dim=1)  # batch x hidden_dim\n",
    "\n",
    "        # x = x.flatten(1)\n",
    "        # print(x.shape)\n",
    "        x = self.fc(x)  # batch x 1 (scalar)\n",
    "        x = self.sigmoid_norm(x)\n",
    "#         mean = torch.mean(x)\n",
    "#         std = torch.std(x)\n",
    "#         x = (x - mean) / std\n",
    "        \n",
    "        # x = self.phi_scaling(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.sigmoid_scaling(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "010f2b80-0b61-4469-b6fb-0f7e7bec7dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length = L\n",
    "input_dim = AA_size*L\n",
    "output_dim = 1\n",
    "hidden_dim = 128\n",
    "num_layers = 1\n",
    "num_heads = 4\n",
    "dropout = 0.0\n",
    "\n",
    "model = CustomTransformer(input_dim, hidden_dim, num_layers, num_heads, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f668b71-41a4-4955-8d37-9db8eab41ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec16585-5ea9-4a7b-97f7-41c178842f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "import random as rd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import GPUtil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append('../model')\n",
    "from utils import amino_acid_to_number, tokenize\n",
    "\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "433f8f73-f144-47c8-b1a8-9987c601b683",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% |  0% |\n",
      "|  5 |  0% | 50% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "# site specific tokenization\n",
    "\n",
    "def get_A2N_list(seqs):\n",
    "    seqs_ = list([list(seq) for seq in seqs])\n",
    "    seqs__ = pd.DataFrame(seqs_)\n",
    "    alphabet_by_site = [list(seqs__.iloc[:, i].unique()) for i in range(seqs__.shape[1])]\n",
    "    A2N_list = [dict(zip(alphabet, range(len(alphabet)))) for alphabet in alphabet_by_site]        \n",
    "    return A2N_list\n",
    "\n",
    "def tokenize(seq):\n",
    "    numeric_sequence = [A2N_list[i][seq[i]] for i in range(len(A2N_list))]\n",
    "    return numeric_sequence\n",
    "\n",
    "def sgpu():\n",
    "    GPUtil.showUtilization()\n",
    "\n",
    "sgpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cfb0c8-aabd-4b24-b78f-816332e1922e",
   "metadata": {},
   "source": [
    "#### Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d99237-d8e1-4df5-93b1-73b63a54cc53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_path = \"../Data/Data_prepared/\"\n",
    "file_name = \"Somermeyer2022_allGFP.csv\"\n",
    "datafile = pd.read_csv(in_path + file_name, index_col=None)\n",
    "\n",
    "phenotypes = torch.tensor(list(datafile.DMS_score)).float()\n",
    "phenotypes = phenotypes.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b42789-ab29-4572-98ad-19cc924a75bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_(seq):\n",
    "    return np.sum(np.array([aa == \"-\" for aa in seq]))\n",
    "\n",
    "_counts = [count_(seq) for seq in datafile.mutated_sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "849c3f09-bba0-42a7-a733-0a320e2621e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phenotypes = (phenotypes - phenotypes.min())/(phenotypes.max() - phenotypes.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ee292fa-9963-41b4-9a8a-733f4f4d61e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitness vs. Hamming distance\n",
    "plt.scatter(datafile['hd'], datafile['DMS_score'])\n",
    "plt.show()\n",
    "\n",
    "plt.hist(datafile.DMS_score, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb2406f-1b1e-4756-9be7-8a26118c39fc",
   "metadata": {},
   "source": [
    "#### Generate tokenized sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cb6984f-da76-4bf7-85b2-3ede6bd7c3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A2N_list = get_A2N_list(datafile.mutated_sequence) # Get position-wise alphabet\n",
    "seqs = [tokenize(mutant) for mutant in datafile.mutated_sequence]\n",
    "seqs = torch.tensor(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "737189e6-58a7-437a-9bbb-7eb0d7b46044",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence length = 245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/21219464/ipykernel_1097053/4240040816.py:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  seqs = seqs[:, sites_var].squeeze(1)\n"
     ]
    }
   ],
   "source": [
    "seqs_df = pd.DataFrame(seqs.cpu().numpy())\n",
    "counts = {i: seqs_df[i].value_counts() for i in range(seqs_df.shape[1])}\n",
    "n_aas = [len(counts[i]) for i in range(len(counts))]\n",
    "sites_var = np.where(np.array(n_aas) != 1)\n",
    "\n",
    "plt.plot(n_aas)\n",
    "plt.show()\n",
    "\n",
    "seqs = seqs[:, sites_var].squeeze(1)\n",
    "L = seqs.shape[1]\n",
    "print(f\"sequence length = {L}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b9eac0-dd04-4c2d-a10d-61515cafb2e6",
   "metadata": {},
   "source": [
    "#### Generate one hot sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d12945f5-9736-4994-802b-a76691e0a640",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([93925, 245, 22])\n",
      "torch.Size([93925, 5390])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "seqs1h = one_hot(seqs)\n",
    "print(seqs1h.shape)\n",
    "\n",
    "AA_size = seqs1h.shape[-1]\n",
    "\n",
    "seqs1hf = seqs1h.view(-1, L*(AA_size))\n",
    "print(seqs1hf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f230d0-c593-42f1-a47a-02328ab078a7",
   "metadata": {},
   "source": [
    "#### Define train test scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e173e8-bac8-4386-9fe5-f3bf9737927f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "class ProtDataset(data.Dataset):\n",
    "    def __init__(self, feats, labels, train=True):    \n",
    "        self.train = train\n",
    "        self.feats = feats\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.feats)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        X = self.feats[idx]\n",
    "        y = self.labels[idx]\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36376f2b-c9e5-41d1-9f9e-a2eca7d77d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # mutagenesis sampling\n",
    "\n",
    "# min_d = 2\n",
    "# sub_list = list(np.where(datafile['hd'] <= min_d)[0])\n",
    "# comp_list = list(np.where(datafile['hd'] > min_d)[0])\n",
    "\n",
    "# num_train = 20000\n",
    "# print(num_train)\n",
    "# num_test = 1000\n",
    "\n",
    "# # train_list = np.random.choice(sub_list, len(sub_list), replace=False)\n",
    "# train_list = np.random.choice(sub_list, num_train, replace=False)\n",
    "# test_list = np.random.choice(comp_list, num_test, replace=False)\n",
    "\n",
    "# print(len(train_list))\n",
    "# print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10a87d02-b931-475a-ae30-4d3e40883176",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# random sampling\n",
    "\n",
    "num_train = 10000\n",
    "num_test = 2000\n",
    "\n",
    "sub_list = np.random.choice(range(len(datafile)), num_train, replace=False)\n",
    "comp_list = list(set(range(len(datafile))).difference(sub_list))\n",
    "\n",
    "train_list = sub_list\n",
    "test_list = np.random.choice(comp_list, num_test, replace=False)\n",
    "\n",
    "print(len(train_list))\n",
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4747ccb1-9bf7-4505-9f23-f208d85aa25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# _counts = pd.Series(_counts)\n",
    "# _counts.unique()\n",
    "\n",
    "# num_train = 20000\n",
    "# num_test = 1000\n",
    "\n",
    "# sub_list = np.where((_counts == 11) | (_counts == 24))[0]\n",
    "\n",
    "# comp_list = list(set(range(len(datafile))).difference(sub_list))\n",
    "\n",
    "# train_list = np.random.choice(sub_list, num_train)\n",
    "# test_list = np.random.choice(comp_list, num_test, replace=False)\n",
    "\n",
    "# print(len(train_list))\n",
    "# print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfe95d5c-0821-4dba-a247-84a4ff84d3e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQpUlEQVR4nO3df6yeZX3H8ffHUn8sMljoWSRt9WiEZMim6AlC/GP8GAk60v4hbrDoxDC7MJmKZsvqElT2B3NG2RQja4AI6hCGxlQHMc2sQReKHrBU2yrpGIMyEo4Fi0RlO/rdH+fBHh/O6XOfnuc8p736fiVPev+4el/fXHnO59zn/pmqQpJ05HvechcgSRoOA12SGmGgS1IjDHRJaoSBLkmNOGa5Ol61alWNj48vV/eSdES69957f1RVY3OtW7ZAHx8fZ3Jycrm6l6QjUpL/nm+dh1wkqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRne8UTbICmAQeraoL+ta9ALgZeB2wD/jjqnpoiHX+uq1XL9mmn+PsjaPrS5IWYSF76O8Bds+z7lLgyap6JXAN8JHFFiZJWphOgZ5kDfCHwPXzNFkP3NSbvh04N0kWX54kqauue+j/CPw18Mt51q8GHgGoqmlgP3BCf6MkG5JMJpmcmppaeLWSpHkNDPQkFwCPV9W9i+2sqjZV1URVTYyNzfn0R0nSIeqyh/4GYF2Sh4AvAOck+Vxfm0eBtQBJjgGOY+bkqCRpRAYGelVtrKo1VTUOXAR8vare2tdsM/D23vSFvTY11EolSQd1yC+4SHIVMFlVm4EbgM8m2QM8wUzwS5JGaEGBXlXfAL7Rm75y1vKfA28ZZmGSpIXxTlFJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhpxyDcWLae7HxzdUwW2TT/wa/NXnHfyyPqWpIVwD12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUiC4viX5hkm8nuT/JziQfnqPNJUmmkmzvff5sacqVJM2ny52izwDnVNXTSVYC30pyZ1Vt62t3a1VdPvwSJUldDAz03suen+7Nrux9fAG0JB1mOh1DT7IiyXbgcWBLVd0zR7M3J9mR5PYka+fZzoYkk0kmp6amDr1qSdJzdAr0qvpFVb0GWAOcnuTUviZfAcar6veALcBN82xnU1VNVNXE2NjYIsqWJPVb0FUuVfVjYCtwft/yfVX1TG/2euB1Q6lOktRZl6tcxpIc35t+EXAe8IO+NifOml0H7B5ijZKkDrpc5XIicFOSFcz8Aritqr6a5Cpgsqo2A+9Osg6YBp4ALlmqgiVJc+tylcsO4LQ5ll85a3ojsHG4pUmSFsI7RSWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRXd4p+sIk305yf5KdST48R5sXJLk1yZ4k9yQZX5JqJUnz6rKH/gxwTlW9GngNcH6SM/raXAo8WVWvBK4BPjLUKiVJAw0M9JrxdG92Ze9Tfc3WAzf1pm8Hzk2SoVUpSRqo0zH0JCuSbAceB7ZU1T19TVYDjwBU1TSwHzhhju1sSDKZZHJqampRhUuSfl2nQK+qX1TVa4A1wOlJTj2UzqpqU1VNVNXE2NjYoWxCkjSPBV3lUlU/BrYC5/etehRYC5DkGOA4YN8Q6pMkddTlKpexJMf3pl8EnAf8oK/ZZuDtvekLga9XVf9xdknSEjqmQ5sTgZuSrGDmF8BtVfXVJFcBk1W1GbgB+GySPcATwEVLVrEkaU4DA72qdgCnzbH8ylnTPwfeMtzSJEkL4Z2iktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGdHkF3dokW5PsSrIzyXvmaHNWkv1Jtvc+V861LUnS0unyCrpp4P1VdV+SY4F7k2ypql197b5ZVRcMv0RJUhcD99Cr6rGquq83/RNgN7B6qQuTJC3Mgo6hJxln5v2i98yx+swk9ye5M8mr5vn/G5JMJpmcmppaeLWSpHl1DvQkLwa+CLy3qp7qW30f8LKqejXwSeDLc22jqjZV1URVTYyNjR1iyZKkuXQK9CQrmQnzz1fVl/rXV9VTVfV0b/oOYGWSVUOtVJJ0UF2ucglwA7C7qj4+T5uX9NqR5PTedvcNs1BJ0sF1ucrlDcDbgO8l2d5b9gHgpQBVdR1wIXBZkmngZ8BFVVXDL7dxW68eXV9nbxxdX5JGYmCgV9W3gAxocy1w7bCKkiQtnHeKSlIjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiO6vFN0bZKtSXYl2ZnkPXO0SZJPJNmTZEeS1y5NuZKk+XR5p+g08P6qui/JscC9SbZU1a5Zbd4InNT7vB74dO9fSdKIDNxDr6rHquq+3vRPgN3A6r5m64Gba8Y24PgkJw69WknSvBZ0DD3JOHAacE/fqtXAI7Pm9/Lc0CfJhiSTSSanpqYWWKok6WA6B3qSFwNfBN5bVU8dSmdVtamqJqpqYmxs7FA2IUmaR6dAT7KSmTD/fFV9aY4mjwJrZ82v6S2TJI1Il6tcAtwA7K6qj8/TbDPwp72rXc4A9lfVY0OsU5I0QJerXN4AvA34XpLtvWUfAF4KUFXXAXcAbwL2AD8F3jH0SiVJBzUw0KvqW0AGtCngXcMqSpK0cF320HUYuPvBfUPd3rbpBzq3veK8k4fat6Sl4a3/ktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSI3yWywJds6X7M1AW6oyHh/u8FklHF/fQJakRBrokNcJAl6RGdHkF3Y1JHk/y/XnWn5Vkf5Ltvc+Vwy9TkjRIl5OinwGuBW4+SJtvVtUFQ6lIknRIuryC7q4k4yOoRa3aevVo+jl742j6kQ5TwzqGfmaS+5PcmeRV8zVKsiHJZJLJqampIXUtSYLhBPp9wMuq6tXAJ4Evz9ewqjZV1URVTYyNjQ2ha0nSsxYd6FX1VFU93Zu+A1iZZNWiK5MkLciiAz3JS5KkN316b5ve8ihJIzbwpGiSW4CzgFVJ9gIfBFYCVNV1wIXAZUmmgZ8BF1VVLVnFkqQ5dbnK5eIB669l5rJGNWqxz6851GfUnPmKExbVr3S08U5RSWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY3o8sYiNeiMhzctdwmShsw9dElqhIEuSY0w0CWpER5DH8BjzZKOFO6hS1IjDHRJasTAQE9yY5LHk3x/nvVJ8okke5LsSPLa4ZcpSRqkyx76Z4DzD7L+jcBJvc8G4NOLL0uStFADA72q7gKeOEiT9cDNNWMbcHySE4dVoCSpm2EcQ18NPDJrfm9v2XMk2ZBkMsnk1NTUELqWJD1rpCdFq2pTVU1U1cTY2Ngou5ak5g0j0B8F1s6aX9NbJkkaoWHcWLQZuDzJF4DXA/ur6rEhbFdHubsf3Leg9tumHxha31ecd/LQtiWNysBAT3ILcBawKsle4IPASoCqug64A3gTsAf4KfCOpSpWkjS/gYFeVRcPWF/Au4ZWkSTpkHinqCQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEZ1eQZfkfOCfgBXA9VX1933rLwE+yoF3iV5bVdcPsU5poDMe3jS8jW094eDrz944vL6kIenyCroVwKeA84C9wHeSbK6qXX1Nb62qy5egRklSB1320E8H9lTVgwC9l0GvB/oDXdJS2Hr16PryL48jWpdj6KuBR2bN7+0t6/fmJDuS3J5k7VwbSrIhyWSSyampqUMoV5I0n07H0Dv4CnBLVT2T5M+Bm4Bz+htV1SZgE8DExEQNqW+pGddseeA5y854eN+S93vmKwacM9ARoUugPwrM3uNew4GTnwBU1exv3PXAPyy+NOkwtkSHQUYR3mpXl0D/DnBSkpczE+QXAX8yu0GSE6vqsd7sOmD3UKuURuzuBw1WHXkGBnpVTSe5HPgaM5ct3lhVO5NcBUxW1Wbg3UnWAdPAE8AlS1izJGkOnY6hV9UdwB19y66cNb0R8PS4dKTzipojmneKSlIjDHRJasSwLluUdARbjpPA26ZnLtG84ryTR953q9xDl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEV6HLmlZ/OqVgYNe97dYR9EjBtxDl6RGGOiS1AgDXZIa4TF0SctqqZ8j8+wzY/q1+AwZ99AlqREGuiQ1olOgJzk/yQ+T7EnyN3Osf0GSW3vr70kyPvRKJUkHNTDQk6wAPgW8ETgFuDjJKX3NLgWerKpXAtcAHxl2oZKkg+tyUvR0YE9VPQiQ5AvAemDXrDbrgQ/1pm8Hrk2Sqqoh1ipJQ3PNlrlPlo7CUp2Q7RLoq4FHZs3vBV4/X5uqmk6yHzgB+NHsRkk2ABt6s08n+eGhFA2s6t/2UcyxOMCxOMCx+JWPHXZj8b7F/feXzbdipJctVtUmYNNit5NksqomhlDSEc+xOMCxOMCxOOBoGosuJ0UfBdbOml/TWzZnmyTHAMcBo39JoSQdxboE+neAk5K8PMnzgYuAzX1tNgNv701fCHzd4+eSNFoDD7n0jolfDnwNWAHcWFU7k1wFTFbVZuAG4LNJ9gBPMBP6S2nRh20a4lgc4Fgc4FgccNSMRdyRlqQ2eKeoJDXCQJekRhzWge4jBw7oMBbvS7IryY4k/55k3mtVj3SDxmJWuzcnqSTNXrLWZSyS/FHvu7Ezyb+MusZR6fAz8tIkW5N8t/dz8qblqHNJVdVh+WHmBOx/Aq8Ang/cD5zS1+YvgOt60xcBty533cs4FmcDv9GbvuxoHoteu2OBu4BtwMRy172M34uTgO8Cv9Wb/+3lrnsZx2ITcFlv+hTgoeWue9ifw3kP/VePHKiq/wWefeTAbOuBm3rTtwPnJskIaxyVgWNRVVur6qe92W3M3C/Qoi7fC4C/Y+aZQj8fZXEj1mUs3gl8qqqeBKiqx0dc46h0GYsCfrM3fRzwPyOsbyQO50Cf65EDq+drU1XTwLOPHGhNl7GY7VLgziWtaPkMHIskrwXWVtW/jbKwZdDle3EycHKS/0iyLcn5I6tutLqMxYeAtybZC9wB/OVoShsd31jUmCRvBSaA31/uWpZDkucBHwcuWeZSDhfHMHPY5Sxm/mq7K8nvVtWPl7OoZXIx8Jmq+liSM5m5d+bUqvrlchc2LIfzHrqPHDigy1iQ5A+AvwXWVdUzI6pt1AaNxbHAqcA3kjwEnAFsbvTEaJfvxV5gc1X9X1X9F/AAMwHfmi5jcSlwG0BV3Q28kJmHmDXjcA50HzlwwMCxSHIa8M/MhHmrx0lhwFhU1f6qWlVV41U1zsz5hHVVNbk85S6pLj8jX2Zm75wkq5g5BPPgCGsclS5j8TBwLkCS32Em0KdGWuUSO2wDvXdM/NlHDuwGbqveIweSrOs1uwE4offIgfcB817CdiTrOBYfBV4M/GuS7Un6v8xN6DgWR4WOY/E1YF+SXcBW4K+qqrm/YjuOxfuBdya5H7gFuKS1HUBv/ZekRhy2e+iSpIUx0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1Ij/h+pd58lwgirnwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(phenotypes[train_list].flatten().numpy(), density=True, alpha=.5)\n",
    "plt.hist(phenotypes[test_list].flatten().numpy(), density=True, alpha=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9391b0-ee67-4f1c-8533-0b2d44b44bd6",
   "metadata": {},
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6e9d866-b721-4da2-a1e1-86b8a3a38b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, dropout):\n",
    "        super(MultiHeadAttentionLayer, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(hidden_dim, num_heads, dropout)\n",
    "        # self.multihead_attn = MultiheadAttention(hidden_dim, hidden_dim, num_heads)        \n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.multihead_attn(x, x, x)\n",
    "        x = x + attn_output\n",
    "        # x = self.layer_norm(x + attn_output)\n",
    "        return x\n",
    "\n",
    "class CustomTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, dropout):\n",
    "        super(CustomTransformer, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        \n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            MultiHeadAttentionLayer(hidden_dim, num_heads, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        # self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.fc = nn.Linear(hidden_dim*L, 1)        \n",
    "        self.sigmoid_norm = nn.BatchNorm1d(1, affine=False)        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.phi_scaling = nn.Linear(1, 1)\n",
    "        self.sigmoid_scaling = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)  # seq_len x batch x hidden_dim\n",
    "        \n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        # x = torch.mean(x, dim=0)  # batch x hidden_dim\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = x.flatten(1)\n",
    "        # print(x.shape)\n",
    "        x = self.fc(x)  # batch x 1 (scalar)\n",
    "        x = self.sigmoid_norm(x)\n",
    "#         mean = torch.mean(x)\n",
    "#         std = torch.std(x)\n",
    "#         x = (x - mean) / std\n",
    "        \n",
    "        # x = self.phi_scaling(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.sigmoid_scaling(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed508c68-c524-4d64-affa-212b045582ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AA_size = seqs1h.shape[-1]\n",
    "seqs_ex = seqs + AA_size*torch.tensor(range(L))\n",
    "\n",
    "\n",
    "X = seqs_ex.to(device)\n",
    "y = phenotypes.to(device)\n",
    "X_train, y_train = X[train_list], y[train_list]\n",
    "X_test, y_test = X[test_list], y[test_list]\n",
    "train_dataset = ProtDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38594757-9bdd-4d45-b4fd-77d56835acf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True,\n",
    "                               drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eec1806e-5870-4b64-8563-b6148ad9b3e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_length = L\n",
    "input_dim = AA_size*L\n",
    "output_dim = 1\n",
    "hidden_dim = 128\n",
    "num_layers = 3\n",
    "num_heads = 4\n",
    "dropout = 0.3\n",
    "\n",
    "model = CustomTransformer(input_dim, hidden_dim, num_layers, num_heads, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e24bc945-2398-4f45-b5dc-eba7552b75a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af05efd2-7c7e-42f5-9579-5bd48c559303",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Loss: 0.3037086457014084\n",
      "0.013094414172230336\n",
      "Epoch 2/500, Loss: 0.29272650480270385\n",
      "0.017345911819925324\n",
      "Epoch 3/500, Loss: 0.2796662837266922\n",
      "0.020373010180242002\n",
      "Epoch 4/500, Loss: 0.26717371940612794\n",
      "0.025853612204392973\n",
      "Epoch 5/500, Loss: 0.25490579605102537\n",
      "0.03939192134831626\n",
      "Epoch 6/500, Loss: 0.23847077786922455\n",
      "0.12727797227223944\n",
      "Epoch 7/500, Loss: 0.20695260614156724\n",
      "0.10782711824606812\n",
      "Epoch 8/500, Loss: 0.19225357323884965\n",
      "0.12216973102047977\n",
      "Epoch 9/500, Loss: 0.17839477509260177\n",
      "0.12013819982235224\n",
      "Epoch 10/500, Loss: 0.16467450708150863\n",
      "0.11862717737938996\n",
      "Epoch 11/500, Loss: 0.15394655615091324\n",
      "0.12414374667518376\n",
      "Epoch 12/500, Loss: 0.14897973090410233\n",
      "0.11724760095031879\n",
      "Epoch 13/500, Loss: 0.13188107460737228\n",
      "0.12987392809282333\n",
      "Epoch 14/500, Loss: 0.11951548904180527\n",
      "0.1342417661439185\n",
      "Epoch 15/500, Loss: 0.11199802160263062\n",
      "0.12762242508921215\n",
      "Epoch 16/500, Loss: 0.10580500811338425\n",
      "0.12448967209480967\n",
      "Epoch 17/500, Loss: 0.09987391307950019\n",
      "0.12517316731516542\n",
      "Epoch 18/500, Loss: 0.09465861544013024\n",
      "0.1282291098101701\n",
      "Epoch 19/500, Loss: 0.08948725312948227\n",
      "0.12975955108249074\n",
      "Epoch 20/500, Loss: 0.08511712849140167\n",
      "0.13331087982592754\n",
      "Epoch 21/500, Loss: 0.08055218011140823\n",
      "0.12640342000259486\n",
      "Epoch 22/500, Loss: 0.07673899233341216\n",
      "0.12174889059131531\n",
      "Epoch 23/500, Loss: 0.07283184006810188\n",
      "0.13796044172476524\n",
      "Epoch 24/500, Loss: 0.06937138363718987\n",
      "0.13911395888635972\n",
      "Epoch 25/500, Loss: 0.06646437346935272\n",
      "0.14197399419758505\n",
      "Epoch 26/500, Loss: 0.06308778338134288\n",
      "0.1456524512647447\n",
      "Epoch 27/500, Loss: 0.06163427717983723\n",
      "0.12353143999275518\n",
      "Epoch 28/500, Loss: 0.05879308208823204\n",
      "0.14228624191509562\n",
      "Epoch 29/500, Loss: 0.05636216551065445\n",
      "0.15901595907229363\n",
      "Epoch 30/500, Loss: 0.053851398080587386\n",
      "0.167912290130979\n",
      "Epoch 31/500, Loss: 0.05071534439921379\n",
      "0.21064132304530603\n",
      "Epoch 32/500, Loss: 0.04699621237814426\n",
      "0.26319244884173504\n",
      "Epoch 33/500, Loss: 0.04477938339114189\n",
      "0.2399270192136197\n",
      "Epoch 34/500, Loss: 0.04177742563188076\n",
      "0.27073922196484407\n",
      "Epoch 35/500, Loss: 0.039044081792235376\n",
      "0.3330543766331415\n",
      "Epoch 36/500, Loss: 0.03563649877905846\n",
      "0.3991296456976063\n",
      "Epoch 37/500, Loss: 0.03333981260657311\n",
      "0.3981840612221165\n",
      "Epoch 38/500, Loss: 0.03193611167371273\n",
      "0.4338023455849988\n",
      "Epoch 39/500, Loss: 0.02940845601260662\n",
      "0.44623671651301094\n",
      "Epoch 40/500, Loss: 0.02714779768139124\n",
      "0.4844246485717053\n",
      "Epoch 41/500, Loss: 0.025555786117911337\n",
      "0.49516704763184827\n",
      "Epoch 42/500, Loss: 0.024153669364750385\n",
      "0.520316486273194\n",
      "Epoch 43/500, Loss: 0.022658672742545606\n",
      "0.5343669368522229\n",
      "Epoch 44/500, Loss: 0.02172278519719839\n",
      "0.5517223024512679\n",
      "Epoch 45/500, Loss: 0.02047640737146139\n",
      "0.5630702427117876\n",
      "Epoch 46/500, Loss: 0.01968572959303856\n",
      "0.5172095267747412\n",
      "Epoch 47/500, Loss: 0.018674538005143404\n",
      "0.5396907753915305\n",
      "Epoch 48/500, Loss: 0.01866229884326458\n",
      "0.5640324860199626\n",
      "Epoch 49/500, Loss: 0.017474232614040373\n",
      "0.5769697871800078\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/21219464/ipykernel_1097053/892404872.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "learning_rate = 0.001\n",
    "epochs = 500\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_inputs, batch_targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "        model.eval()\n",
    "        pred, true = model(X_test.flatten(1)).flatten().detach().cpu().numpy(), y_test.flatten().detach().cpu().numpy()\n",
    "        print(pearsonr(pred, true)[0]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9217c-8699-4dae-aba9-e01c89d6b55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4fa514-d8f6-466f-a10f-36d01f8f2d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4303754b-20f4-4eb3-a0b2-f0eaf35b5c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7597c95-1498-45f9-91a1-eb680648d4c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a483e40d-6881-487d-9e1f-972f67f033e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f5cbd4e-7e77-4ef8-b642-0ed4cbe08cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AA_size = seqs1h.shape[-1]\n",
    "seqs_ex = seqs + AA_size*torch.tensor(range(L))\n",
    "\n",
    "\n",
    "X = seqs_ex.to(device)\n",
    "y = phenotypes.to(device)\n",
    "X_train, y_train = X[train_list], y[train_list]\n",
    "X_test, y_test = X[test_list], y[test_list]\n",
    "train_dataset = ProtDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "872784f8-0ab1-44f8-807a-837a39293e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "learning_rate = 0.01\n",
    "epochs = 200\n",
    "num_heads = 4\n",
    "num_layers = 1\n",
    "sequence_length = L\n",
    "input_dim = AA_size*L\n",
    "output_dim = 1\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to be optimized\n",
    "    hidden_dim_h = trial.suggest_int('hidden_dim_h', 10, 40)\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "    batch_size = trial.suggest_int('batch_size', 100, 1000)\n",
    "    model = CustomTransformer(input_dim, hidden_dim_h*num_heads, num_layers, num_heads, dropout).to(device)\n",
    "    \n",
    "    train_loader = data.DataLoader(train_dataset,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   drop_last=False)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    r2_test = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_inputs, batch_targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "            model.eval()\n",
    "            pred, true = model(X_test.flatten(1)).flatten().detach().cpu().numpy(), y_test.flatten().detach().cpu().numpy()\n",
    "            print(pearsonr(pred, true)[0]**2)\n",
    "            r2_test.append(pearsonr(pred, true)[0]**2)\n",
    "            \n",
    "    return np.array(r2_test).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d04ee00-e4db-44da-ad36-192db086ee74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 09:37:55,036] A new study created in memory with name: no-name-caa8e43f-d16f-49b6-a036-50f4e34b6008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.16076872150103252\n",
      "0.02460962474418388\n",
      "Epoch 11/200, Loss: 0.02067820690572262\n",
      "0.45474799319745074\n",
      "Epoch 21/200, Loss: 0.012890544719994068\n",
      "0.5815706300573225\n",
      "Epoch 31/200, Loss: 0.009541811794042588\n",
      "0.6041550139763224\n",
      "Epoch 41/200, Loss: 0.0078486326461037\n",
      "0.6070004244028098\n",
      "Epoch 51/200, Loss: 0.007032975740730763\n",
      "0.6147524905723236\n",
      "Epoch 61/200, Loss: 0.006762327222774426\n",
      "0.6208065557571957\n",
      "Epoch 71/200, Loss: 0.006025768878559271\n",
      "0.6240954037484165\n",
      "Epoch 81/200, Loss: 0.005700394914795955\n",
      "0.6303484764497135\n",
      "Epoch 91/200, Loss: 0.005776977290709814\n",
      "0.6245434412857095\n",
      "Epoch 101/200, Loss: 0.00546526579807202\n",
      "0.6456025967117885\n",
      "Epoch 111/200, Loss: 0.005299712376048167\n",
      "0.6426196118443033\n",
      "Epoch 121/200, Loss: 0.0050244065001606945\n",
      "0.6486054645292022\n",
      "Epoch 131/200, Loss: 0.005188775326435764\n",
      "0.6595454221890721\n",
      "Epoch 141/200, Loss: 0.005223225631440679\n",
      "0.6526674245287609\n",
      "Epoch 151/200, Loss: 0.005050923178593318\n",
      "0.6564319365119933\n",
      "Epoch 161/200, Loss: 0.0052011980985601745\n",
      "0.6445006418035543\n",
      "Epoch 171/200, Loss: 0.004954339750111103\n",
      "0.645255659535467\n",
      "Epoch 181/200, Loss: 0.004811709312101205\n",
      "0.648649131473415\n",
      "Epoch 191/200, Loss: 0.004652618740995725\n",
      "0.6431216434995732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 09:39:14,895] Trial 0 finished with value: 0.6595454221890721 and parameters: {'hidden_dim_h': 21, 'dropout': 0.3374255731217715, 'batch_size': 683}. Best is trial 0 with value: 0.6595454221890721.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 1.1227358356118202\n",
      "0.009175937131129974\n",
      "Epoch 11/200, Loss: 0.03267090301960707\n",
      "0.21828861327768165\n",
      "Epoch 21/200, Loss: 0.02922750225601097\n",
      "0.2959810601512586\n",
      "Epoch 31/200, Loss: 0.026366360873604815\n",
      "0.41331707143245955\n",
      "Epoch 41/200, Loss: 0.02435056973869602\n",
      "0.43508783233437404\n",
      "Epoch 51/200, Loss: 0.023578154854476452\n",
      "0.43750283437145526\n",
      "Epoch 61/200, Loss: 0.024262374655033152\n",
      "0.4695336803464802\n",
      "Epoch 71/200, Loss: 0.02467658929526806\n",
      "0.4002827301947721\n",
      "Epoch 81/200, Loss: 0.02351064995552103\n",
      "0.4055716196100963\n",
      "Epoch 91/200, Loss: 0.023059449236219127\n",
      "0.43446644414577773\n",
      "Epoch 101/200, Loss: 0.02285144788523515\n",
      "0.4587573081982212\n",
      "Epoch 111/200, Loss: 0.022972817455107968\n",
      "0.4359525595618604\n",
      "Epoch 121/200, Loss: 0.025243753179286916\n",
      "0.36541428841870943\n",
      "Epoch 131/200, Loss: 0.024547710704306763\n",
      "0.41930698620482965\n",
      "Epoch 141/200, Loss: 0.023058304795995355\n",
      "0.448703086036072\n",
      "Epoch 151/200, Loss: 0.022310891188681126\n",
      "0.4643792731403957\n",
      "Epoch 161/200, Loss: 0.023611735397328932\n",
      "0.40310032895577014\n",
      "Epoch 171/200, Loss: 0.023050128715112805\n",
      "0.46312699391237955\n",
      "Epoch 181/200, Loss: 0.021918228284145396\n",
      "0.44551562873151307\n",
      "Epoch 191/200, Loss: 0.022440754653265078\n",
      "0.43736803602286345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 09:40:58,341] Trial 1 finished with value: 0.4695336803464802 and parameters: {'hidden_dim_h': 40, 'dropout': 0.31866825078896116, 'batch_size': 423}. Best is trial 0 with value: 0.6595454221890721.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.5550266850379205\n",
      "0.03841669096085419\n",
      "Epoch 11/200, Loss: 0.03151838457392108\n",
      "0.2674149355067743\n",
      "Epoch 21/200, Loss: 0.0258271126977859\n",
      "0.3835836379434842\n",
      "Epoch 31/200, Loss: 0.02433441537282159\n",
      "0.4201026169405583\n",
      "Epoch 41/200, Loss: 0.022308207928173004\n",
      "0.466252121571818\n",
      "Epoch 51/200, Loss: 0.023700169017238003\n",
      "0.4785876360994336\n",
      "Epoch 61/200, Loss: 0.022698684925994566\n",
      "0.41007269584060635\n",
      "Epoch 71/200, Loss: 0.021790006949055578\n",
      "0.43281966571171465\n",
      "Epoch 81/200, Loss: 0.021869716564974478\n",
      "0.4863774331669575\n",
      "Epoch 91/200, Loss: 0.02266375612347357\n",
      "0.4707358846673016\n",
      "Epoch 101/200, Loss: 0.021492128350561666\n",
      "0.43467232764493025\n",
      "Epoch 111/200, Loss: 0.020436232128450946\n",
      "0.48798216770089975\n",
      "Epoch 121/200, Loss: 0.021917419207672918\n",
      "0.46179753689856573\n",
      "Epoch 131/200, Loss: 0.021017449036721262\n",
      "0.5211898306279664\n",
      "Epoch 141/200, Loss: 0.02177399703331532\n",
      "0.4845145293768864\n",
      "Epoch 151/200, Loss: 0.021230744918988596\n",
      "0.4534399057276292\n",
      "Epoch 161/200, Loss: 0.022412864371172844\n",
      "0.41049807613195144\n",
      "Epoch 171/200, Loss: 0.02007560197624468\n",
      "0.48445754588039003\n",
      "Epoch 181/200, Loss: 0.021568944136942585\n",
      "0.3742692201640021\n",
      "Epoch 191/200, Loss: 0.019667575135827065\n",
      "0.4143807659539043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 09:42:42,114] Trial 2 finished with value: 0.5211898306279664 and parameters: {'hidden_dim_h': 38, 'dropout': 0.1395226415623101, 'batch_size': 328}. Best is trial 0 with value: 0.6595454221890721.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.36916870437562466\n",
      "0.08143304292207157\n",
      "Epoch 11/200, Loss: 0.026922114775516093\n",
      "0.38660080308425004\n",
      "Epoch 21/200, Loss: 0.016375017759855837\n",
      "0.5530333625532795\n",
      "Epoch 31/200, Loss: 0.010866714350413531\n",
      "0.6179865720366393\n",
      "Epoch 41/200, Loss: 0.008178376621799543\n",
      "0.6293037649764056\n",
      "Epoch 51/200, Loss: 0.006633435899857432\n",
      "0.6409485310529663\n",
      "Epoch 61/200, Loss: 0.005843710096087307\n",
      "0.6402888706728055\n",
      "Epoch 71/200, Loss: 0.004940120503306389\n",
      "0.6421653299147287\n",
      "Epoch 81/200, Loss: 0.004546041047433391\n",
      "0.6566720027380343\n",
      "Epoch 91/200, Loss: 0.004334838027716614\n",
      "0.6606989982753075\n",
      "Epoch 101/200, Loss: 0.003933299783966504\n",
      "0.6612906797707228\n",
      "Epoch 111/200, Loss: 0.0037665621493943036\n",
      "0.659080089069553\n",
      "Epoch 121/200, Loss: 0.003653650710475631\n",
      "0.6613969429977479\n",
      "Epoch 131/200, Loss: 0.0036102487792959437\n",
      "0.6603766009059006\n",
      "Epoch 141/200, Loss: 0.003372601146111265\n",
      "0.6640253391549995\n",
      "Epoch 151/200, Loss: 0.0032989420724334195\n",
      "0.6744266523692696\n",
      "Epoch 161/200, Loss: 0.003237305936636403\n",
      "0.6748245462533983\n",
      "Epoch 171/200, Loss: 0.0032637006806908175\n",
      "0.6745040462527823\n",
      "Epoch 181/200, Loss: 0.003167268674587831\n",
      "0.6769998440075157\n",
      "Epoch 191/200, Loss: 0.003001599841809366\n",
      "0.6725249505697041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 09:44:08,402] Trial 3 finished with value: 0.6769998440075157 and parameters: {'hidden_dim_h': 26, 'dropout': 0.28116914913722957, 'batch_size': 635}. Best is trial 3 with value: 0.6769998440075157.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.2109223554531733\n",
      "0.12651345794916385\n",
      "Epoch 11/200, Loss: 0.009137035580351949\n",
      "0.6084916042233321\n",
      "Epoch 21/200, Loss: 0.006499299965798855\n",
      "0.6588807820968158\n",
      "Epoch 31/200, Loss: 0.005563514671909312\n",
      "0.6854093496700491\n",
      "Epoch 41/200, Loss: 0.005045976008599003\n",
      "0.6865745257637766\n",
      "Epoch 51/200, Loss: 0.00493239532224834\n",
      "0.6743833663465477\n",
      "Epoch 61/200, Loss: 0.004782739072106778\n",
      "0.6867792099747104\n",
      "Epoch 71/200, Loss: 0.004375991116588315\n",
      "0.6909969243646885\n",
      "Epoch 81/200, Loss: 0.004435272600191335\n",
      "0.6938584034237912\n",
      "Epoch 91/200, Loss: 0.004023847263306379\n",
      "0.6807644559408167\n",
      "Epoch 101/200, Loss: 0.004212953654738764\n",
      "0.680048424416231\n",
      "Epoch 111/200, Loss: 0.004082727339118719\n",
      "0.6886898425306627\n",
      "Epoch 121/200, Loss: 0.004112144443206489\n",
      "0.6910564270755036\n",
      "Epoch 131/200, Loss: 0.004208688849272827\n",
      "0.6881604288531109\n",
      "Epoch 141/200, Loss: 0.0037064785603433846\n",
      "0.67829542832048\n",
      "Epoch 151/200, Loss: 0.0037464850659792623\n",
      "0.6944926789791361\n",
      "Epoch 161/200, Loss: 0.0038835416974810264\n",
      "0.6923085583350983\n",
      "Epoch 171/200, Loss: 0.0038614276486138503\n",
      "0.6814314514784567\n",
      "Epoch 181/200, Loss: 0.0036270367757727704\n",
      "0.6986617516620607\n",
      "Epoch 191/200, Loss: 0.0037012614775449038\n",
      "0.6990770731780237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 09:45:33,428] Trial 4 finished with value: 0.6990770731780237 and parameters: {'hidden_dim_h': 24, 'dropout': 0.14887989927321255, 'batch_size': 343}. Best is trial 4 with value: 0.6990770731780237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.19272190928459168\n",
      "0.12185773863544885\n",
      "Epoch 11/200, Loss: 0.03507787038882573\n",
      "0.1297804522334774\n",
      "Epoch 21/200, Loss: 0.027065048118432362\n",
      "0.3673307317017288\n",
      "Epoch 31/200, Loss: 0.026249213392535845\n",
      "0.3496190939399878\n",
      "Epoch 41/200, Loss: 0.024038946131865184\n",
      "0.43625238284482704\n",
      "Epoch 51/200, Loss: 0.025356690709789593\n",
      "0.3390274540843344\n",
      "Epoch 61/200, Loss: 0.023236576467752457\n",
      "0.48217436021256305\n",
      "Epoch 71/200, Loss: 0.02390113448103269\n",
      "0.33625182289013095\n",
      "Epoch 81/200, Loss: 0.022701706364750864\n",
      "0.3426482105103398\n",
      "Epoch 91/200, Loss: 0.02225653106967608\n",
      "0.4544304785910575\n",
      "Epoch 101/200, Loss: 0.02235307407875856\n",
      "0.3794796201438149\n",
      "Epoch 111/200, Loss: 0.02260129638016224\n",
      "0.401412501396346\n",
      "Epoch 121/200, Loss: 0.020734828213850656\n",
      "0.4339018464269755\n",
      "Epoch 131/200, Loss: 0.02094168948630492\n",
      "0.42262452703212144\n",
      "Epoch 141/200, Loss: 0.021124541635314624\n",
      "0.4856699580672611\n",
      "Epoch 151/200, Loss: 0.020438643048206966\n",
      "0.44794277151106326\n",
      "Epoch 161/200, Loss: 0.021513414879639942\n",
      "0.4689520740934402\n",
      "Epoch 171/200, Loss: 0.02160335530837377\n",
      "0.47767602517381885\n",
      "Epoch 181/200, Loss: 0.021383756399154664\n",
      "0.46034252856483227\n",
      "Epoch 191/200, Loss: 0.021016629040241243\n",
      "0.25618501351060985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 09:47:14,742] Trial 5 finished with value: 0.4856699580672611 and parameters: {'hidden_dim_h': 39, 'dropout': 0.11744960400317489, 'batch_size': 684}. Best is trial 4 with value: 0.6990770731780237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.13093649502843618\n",
      "0.06086390896696169\n",
      "Epoch 11/200, Loss: 0.027376791129687002\n",
      "0.43484525329909124\n",
      "Epoch 21/200, Loss: 0.011867866019851394\n",
      "0.5848218236739584\n",
      "Epoch 31/200, Loss: 0.008588045935279556\n",
      "0.6170865906486421\n",
      "Epoch 41/200, Loss: 0.007731778996198305\n",
      "0.623297610476781\n",
      "Epoch 51/200, Loss: 0.007051629180620823\n",
      "0.6381147532186032\n",
      "Epoch 61/200, Loss: 0.006463419962009149\n",
      "0.6379373726682233\n",
      "Epoch 71/200, Loss: 0.006205984200018325\n",
      "0.6360334651026499\n",
      "Epoch 81/200, Loss: 0.00566596572753042\n",
      "0.6321823286386268\n",
      "Epoch 91/200, Loss: 0.005723654616823686\n",
      "0.6345070513638598\n",
      "Epoch 101/200, Loss: 0.005580726187742714\n",
      "0.6366188913870442\n",
      "Epoch 111/200, Loss: 0.005324035550334624\n",
      "0.6396091287274885\n",
      "Epoch 121/200, Loss: 0.005236876089059349\n",
      "0.6508012909897102\n",
      "Epoch 131/200, Loss: 0.005592188390437514\n",
      "0.6571865493451164\n",
      "Epoch 141/200, Loss: 0.004965109700736191\n",
      "0.653743868711902\n",
      "Epoch 151/200, Loss: 0.004844851126628262\n",
      "0.6609121003888331\n",
      "Epoch 161/200, Loss: 0.004831296292000583\n",
      "0.6651141825504274\n",
      "Epoch 171/200, Loss: 0.004800304163446916\n",
      "0.6569247830053395\n",
      "Epoch 181/200, Loss: 0.004698076934021499\n",
      "0.655568017762909\n",
      "Epoch 191/200, Loss: 0.004833314584435097\n",
      "0.6671266005790398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 09:48:30,282] Trial 6 finished with value: 0.6671266005790398 and parameters: {'hidden_dim_h': 14, 'dropout': 0.48230277498606894, 'batch_size': 368}. Best is trial 4 with value: 0.6990770731780237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.06644521570323329\n",
      "0.14104011844533232\n",
      "Epoch 11/200, Loss: 0.028201029439897912\n",
      "0.3178176562151155\n",
      "Epoch 21/200, Loss: 0.02796062263415048\n",
      "0.345638152546204\n",
      "Epoch 31/200, Loss: 0.027747184822433872\n",
      "0.24002929726375724\n",
      "Epoch 41/200, Loss: 0.026438226041040923\n",
      "0.33982048962598316\n",
      "Epoch 51/200, Loss: 0.026678509716140598\n",
      "0.36212087701485074\n",
      "Epoch 61/200, Loss: 0.02589916783433996\n",
      "0.3435335975077625\n",
      "Epoch 71/200, Loss: 0.02657727196224426\n",
      "0.3957133673617778\n",
      "Epoch 81/200, Loss: 0.025670149437102833\n",
      "0.4188022535598973\n",
      "Epoch 91/200, Loss: 0.0257305008187694\n",
      "0.4054790712897747\n",
      "Epoch 101/200, Loss: 0.024595981561823896\n",
      "0.4369976489444731\n",
      "Epoch 111/200, Loss: 0.02427330844741511\n",
      "0.37726283856664417\n",
      "Epoch 121/200, Loss: 0.02424528435068695\n",
      "0.38704137829435714\n",
      "Epoch 131/200, Loss: 0.024300230103299805\n",
      "0.4656822223305468\n",
      "Epoch 141/200, Loss: 0.024318432606952756\n",
      "0.471735175243532\n",
      "Epoch 151/200, Loss: 0.02373358614644722\n",
      "0.4523541532562319\n",
      "Epoch 161/200, Loss: 0.02375002968811283\n",
      "0.45782320204059945\n",
      "Epoch 171/200, Loss: 0.024319544691886557\n",
      "0.4473711262705357\n",
      "Epoch 181/200, Loss: 0.023618605012368215\n",
      "0.45472477856003807\n",
      "Epoch 191/200, Loss: 0.02396311272719973\n",
      "0.4521921268894151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 09:50:09,200] Trial 7 finished with value: 0.471735175243532 and parameters: {'hidden_dim_h': 30, 'dropout': 0.3301048626769548, 'batch_size': 133}. Best is trial 4 with value: 0.6990770731780237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.1172516147295634\n",
      "0.1243064975629875\n",
      "Epoch 11/200, Loss: 0.016314163183172543\n",
      "0.5657674936008142\n",
      "Epoch 21/200, Loss: 0.010087559930980206\n",
      "0.6620429766611189\n",
      "Epoch 31/200, Loss: 0.007191530816877882\n",
      "0.6711536845243172\n",
      "Epoch 41/200, Loss: 0.005873824004083872\n",
      "0.6954367410597377\n",
      "Epoch 51/200, Loss: 0.005323924279461305\n",
      "0.7012842445604526\n",
      "Epoch 61/200, Loss: 0.004885358425478141\n",
      "0.7055565975265379\n",
      "Epoch 71/200, Loss: 0.00462427440409859\n",
      "0.7066661879401218\n",
      "Epoch 81/200, Loss: 0.0042884716272561085\n",
      "0.7199453288456752\n",
      "Epoch 91/200, Loss: 0.004294700493725638\n",
      "0.7167806787372282\n",
      "Epoch 101/200, Loss: 0.004007049435232248\n",
      "0.7156440829166277\n",
      "Epoch 111/200, Loss: 0.003985649078256554\n",
      "0.7221414502363034\n",
      "Epoch 121/200, Loss: 0.004088229085836146\n",
      "0.7145781039702237\n",
      "Epoch 131/200, Loss: 0.004244384498128461\n",
      "0.7203297789544215\n",
      "Epoch 141/200, Loss: 0.004165350808762014\n",
      "0.7176091749525664\n",
      "Epoch 151/200, Loss: 0.00398426862537033\n",
      "0.7165985888578144\n",
      "Epoch 161/200, Loss: 0.003909334850807984\n",
      "0.7098083294777185\n",
      "Epoch 171/200, Loss: 0.003963500532942514\n",
      "0.714115947022156\n",
      "Epoch 181/200, Loss: 0.003934636828489602\n",
      "0.7161346757872462\n",
      "Epoch 191/200, Loss: 0.003535655482361714\n",
      "0.7172478401221807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 09:51:37,968] Trial 8 finished with value: 0.7221414502363034 and parameters: {'hidden_dim_h': 29, 'dropout': 0.12032521949901909, 'batch_size': 574}. Best is trial 8 with value: 0.7221414502363034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.22764671966433525\n",
      "0.12304728219334589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-01-15 09:51:41,771] Trial 9 failed with parameters: {'hidden_dim_h': 34, 'dropout': 0.4530618781934578, 'batch_size': 225} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juannanzhou/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/scratch/local/21219464/ipykernel_1097053/3845934773.py\", line 35, in objective\n",
      "    total_loss += loss.item()\n",
      "KeyboardInterrupt\n",
      "[W 2024-01-15 09:51:41,772] Trial 9 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/21219464/ipykernel_1097053/1568097590.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create and run the Optuna study\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Print the best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/21219464/ipykernel_1097053/3845934773.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create and run the Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "best_trial = study.best_trial\n",
    "print(\"Best Trial:\")\n",
    "print(f\"  Value: {best_trial.value:.4f}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# You can then use the best hyperparameters to train your final model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584140fd-20eb-4ae0-8133-d7176b903bfc",
   "metadata": {},
   "source": [
    "#### n_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339f487d-cdb3-4543-bf93-1267b85aae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = L\n",
    "input_dim = AA_size*L\n",
    "output_dim = 1\n",
    "hidden_dim = 128\n",
    "num_layers = 3\n",
    "num_heads = 4\n",
    "dropout = 0.3\n",
    "\n",
    "model = CustomTransformer(input_dim, hidden_dim, num_layers, num_heads, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37dcac39-3b33-4b5d-ad28-7a30b8764fda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "learning_rate = 0.001\n",
    "epochs = 200\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "sequence_length = L\n",
    "input_dim = AA_size*L\n",
    "output_dim = 1\n",
    "dropout_init = 0.3\n",
    "batch_size_init = 1000\n",
    "hidden_dim_h_init = 32\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to be optimized\n",
    "    # hidden_dim_h = trial.suggest_int('hidden_dim_h', hidden_dim_h_init, 10, 50)\n",
    "    # dropout = trial.suggest_float('dropout', dropout_init, 0.05, 0.35)\n",
    "    # batch_size = trial.suggest_int('batch_size', batch_size_init, 100, 1200)\n",
    "\n",
    "    hidden_dim_h = trial.suggest_int('hidden_dim_h', 10, 50)\n",
    "    dropout = trial.suggest_float('dropout', 0.05, 0.35)\n",
    "    batch_size = trial.suggest_int('batch_size', 100, 1200)\n",
    "    \n",
    "    model = CustomTransformer(input_dim, hidden_dim_h*num_heads, num_layers, num_heads, dropout).to(device)\n",
    "    \n",
    "    train_loader = data.DataLoader(train_dataset,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   drop_last=False)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    r2_test = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_inputs, batch_targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "            model.eval()\n",
    "            pred, true = model(X_test.flatten(1)).flatten().detach().cpu().numpy(), y_test.flatten().detach().cpu().numpy()\n",
    "            print(pearsonr(pred, true)[0]**2)\n",
    "            r2_test.append(pearsonr(pred, true)[0]**2)\n",
    "            \n",
    "    return np.array(r2_test).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be95477-f6e9-4b58-8d85-1979293d296f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:10:11,124] A new study created in memory with name: no-name-a91656f1-9f79-4474-b85c-d02817c6df3a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 1.0281103632666848\n",
      "0.015158412730883074\n",
      "Epoch 11/200, Loss: 0.3262080730813922\n",
      "0.3370707276062885\n",
      "Epoch 21/200, Loss: 0.08715979009866714\n",
      "0.5847153106323952\n",
      "Epoch 31/200, Loss: 0.02930699892793641\n",
      "0.6578787197243483\n",
      "Epoch 41/200, Loss: 0.019766556776382706\n",
      "0.6589803596564182\n",
      "Epoch 51/200, Loss: 0.017359975612524784\n",
      "0.682271691091924\n",
      "Epoch 61/200, Loss: 0.01548266179408088\n",
      "0.6812581756012823\n",
      "Epoch 71/200, Loss: 0.013751276147862276\n",
      "0.6863729982601918\n",
      "Epoch 81/200, Loss: 0.011712525350352129\n",
      "0.6870793351431073\n",
      "Epoch 91/200, Loss: 0.009951404281750773\n",
      "0.6927982661419398\n",
      "Epoch 101/200, Loss: 0.008409438880555557\n",
      "0.6908276859695699\n",
      "Epoch 111/200, Loss: 0.007023497371736801\n",
      "0.6748893674684734\n",
      "Epoch 121/200, Loss: 0.0057291021415342884\n",
      "0.6838276819574827\n",
      "Epoch 131/200, Loss: 0.004901145196830233\n",
      "0.6971078961311893\n",
      "Epoch 141/200, Loss: 0.004070296262701352\n",
      "0.6934037210391457\n",
      "Epoch 151/200, Loss: 0.0036557246754510384\n",
      "0.6883515766098759\n",
      "Epoch 161/200, Loss: 0.0032786608948795633\n",
      "0.6937947035376855\n",
      "Epoch 171/200, Loss: 0.002910236475255453\n",
      "0.6982624933417731\n",
      "Epoch 181/200, Loss: 0.002803436067717319\n",
      "0.7002292354849063\n",
      "Epoch 191/200, Loss: 0.002512835731701643\n",
      "0.7111225053946862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:12:57,210] Trial 0 finished with value: 0.7111225053946862 and parameters: {'hidden_dim_h': 32, 'dropout': 0.11781973928394508, 'batch_size': 309}. Best is trial 0 with value: 0.7111225053946862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.9554896217126113\n",
      "0.025589175368483468\n",
      "Epoch 11/200, Loss: 0.596484110905574\n",
      "0.03277537314014586\n",
      "Epoch 21/200, Loss: 0.36528111421144926\n",
      "0.16372602293833438\n",
      "Epoch 31/200, Loss: 0.20821832693540132\n",
      "0.41628346738833777\n",
      "Epoch 41/200, Loss: 0.11715855793311046\n",
      "0.5102962237916451\n",
      "Epoch 51/200, Loss: 0.06513982638716698\n",
      "0.5327858185413664\n",
      "Epoch 61/200, Loss: 0.036390527796286806\n",
      "0.5926388753740092\n",
      "Epoch 71/200, Loss: 0.019841625713385068\n",
      "0.6213066979616327\n",
      "Epoch 81/200, Loss: 0.012816822801071864\n",
      "0.6247065727968504\n",
      "Epoch 91/200, Loss: 0.010022879506532963\n",
      "0.6333855214960064\n",
      "Epoch 101/200, Loss: 0.009120702456969481\n",
      "0.640220166399708\n",
      "Epoch 111/200, Loss: 0.007839741006207008\n",
      "0.6482159087770003\n",
      "Epoch 121/200, Loss: 0.007777824532240629\n",
      "0.6593333883292785\n",
      "Epoch 131/200, Loss: 0.008157113244613776\n",
      "0.6653866037110163\n",
      "Epoch 141/200, Loss: 0.006800019898666785\n",
      "0.6796032101219343\n",
      "Epoch 151/200, Loss: 0.006613979223542488\n",
      "0.6730808005669829\n",
      "Epoch 161/200, Loss: 0.006248611992654892\n",
      "0.680977715347508\n",
      "Epoch 171/200, Loss: 0.006195387946298489\n",
      "0.6839912505765327\n",
      "Epoch 181/200, Loss: 0.005784524783778649\n",
      "0.6848433160516538\n",
      "Epoch 191/200, Loss: 0.005841854995546432\n",
      "0.6839447920277009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:16:21,211] Trial 1 finished with value: 0.6848433160516538 and parameters: {'hidden_dim_h': 45, 'dropout': 0.1262392074743765, 'batch_size': 828}. Best is trial 0 with value: 0.7111225053946862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.26159196879182545\n",
      "0.12508475121946072\n",
      "Epoch 11/200, Loss: 0.04780621986304011\n",
      "0.2983849824972106\n",
      "Epoch 21/200, Loss: 0.018182379326650074\n",
      "0.5216429539288446\n",
      "Epoch 31/200, Loss: 0.014087527890556626\n",
      "0.5907163991129167\n",
      "Epoch 41/200, Loss: 0.011997174904016512\n",
      "0.6016908932238926\n",
      "Epoch 51/200, Loss: 0.010416118195280433\n",
      "0.6458134755772331\n",
      "Epoch 61/200, Loss: 0.009426893732909645\n",
      "0.646718025010597\n",
      "Epoch 71/200, Loss: 0.008407182608997183\n",
      "0.6604648628431605\n",
      "Epoch 81/200, Loss: 0.007514138689397701\n",
      "0.665962773622834\n",
      "Epoch 91/200, Loss: 0.006756818304503602\n",
      "0.6683466836866122\n",
      "Epoch 101/200, Loss: 0.006098899175412953\n",
      "0.6769049879377073\n",
      "Epoch 111/200, Loss: 0.0054180998953857595\n",
      "0.6851113768937723\n",
      "Epoch 121/200, Loss: 0.005129061547839748\n",
      "0.6984641904153487\n",
      "Epoch 131/200, Loss: 0.0049836758241456535\n",
      "0.7021691580657962\n",
      "Epoch 141/200, Loss: 0.004600412594819707\n",
      "0.6914966205744132\n",
      "Epoch 151/200, Loss: 0.004414188791997731\n",
      "0.7100204233849218\n",
      "Epoch 161/200, Loss: 0.004109000371369932\n",
      "0.7041824351428584\n",
      "Epoch 171/200, Loss: 0.003995129497655269\n",
      "0.7071628269513096\n",
      "Epoch 181/200, Loss: 0.003829927075587745\n",
      "0.7038637924400115\n",
      "Epoch 191/200, Loss: 0.003570100267617298\n",
      "0.7096672073787131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:18:49,790] Trial 2 finished with value: 0.7100204233849218 and parameters: {'hidden_dim_h': 22, 'dropout': 0.264333692978768, 'batch_size': 365}. Best is trial 0 with value: 0.7111225053946862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.30367457303735945\n",
      "0.10259453377383092\n",
      "Epoch 11/200, Loss: 0.0363719432718224\n",
      "0.4342779878354034\n",
      "Epoch 21/200, Loss: 0.0253425732254982\n",
      "0.6086344850783728\n",
      "Epoch 31/200, Loss: 0.019917680198947588\n",
      "0.6245653391902614\n",
      "Epoch 41/200, Loss: 0.01477389449460639\n",
      "0.6618671081718585\n",
      "Epoch 51/200, Loss: 0.010661133616748784\n",
      "0.6878176033282268\n",
      "Epoch 61/200, Loss: 0.008784315186656184\n",
      "0.6801178950902553\n",
      "Epoch 71/200, Loss: 0.013134228583011363\n",
      "0.5767782976477155\n",
      "Epoch 81/200, Loss: 0.01248255144390795\n",
      "0.6230436097921146\n",
      "Epoch 91/200, Loss: 0.012546922535532051\n",
      "0.5946597900433204\n",
      "Epoch 101/200, Loss: 0.011844144823650518\n",
      "0.6105074391897033\n",
      "Epoch 111/200, Loss: 0.011897387645310826\n",
      "0.6085228526797378\n",
      "Epoch 121/200, Loss: 0.012425568865405188\n",
      "0.6054192572197625\n",
      "Epoch 131/200, Loss: 0.012107952870428563\n",
      "0.5789677828553298\n",
      "Epoch 141/200, Loss: 0.010898364511215024\n",
      "0.6164595458181776\n",
      "Epoch 151/200, Loss: 0.010950271412730217\n",
      "0.6130930925633731\n",
      "Epoch 161/200, Loss: 0.01092053624904818\n",
      "0.6175836294421707\n",
      "Epoch 171/200, Loss: 0.010182737424555752\n",
      "0.617581351141396\n",
      "Epoch 181/200, Loss: 0.010855873736242453\n",
      "0.6125833880990214\n",
      "Epoch 191/200, Loss: 0.010107865815775262\n",
      "0.5863276338280233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:22:03,671] Trial 3 finished with value: 0.6878176033282268 and parameters: {'hidden_dim_h': 39, 'dropout': 0.12533114228068604, 'batch_size': 224}. Best is trial 0 with value: 0.7111225053946862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.650307594026838\n",
      "0.12424731355890445\n",
      "Epoch 11/200, Loss: 0.1460541307926178\n",
      "0.4944034246146988\n",
      "Epoch 21/200, Loss: 0.02929556252700942\n",
      "0.5754009342348751\n",
      "Epoch 31/200, Loss: 0.012925813772848673\n",
      "0.6522392089943808\n",
      "Epoch 41/200, Loss: 0.01039146516206009\n",
      "0.6581805853137386\n",
      "Epoch 51/200, Loss: 0.009124057354139431\n",
      "0.6741813879474787\n",
      "Epoch 61/200, Loss: 0.008151054794767073\n",
      "0.6819883726289937\n",
      "Epoch 71/200, Loss: 0.007122281406606946\n",
      "0.6830068695903951\n",
      "Epoch 81/200, Loss: 0.006288002072168248\n",
      "0.678251759691031\n",
      "Epoch 91/200, Loss: 0.005629138142934868\n",
      "0.6837437929210107\n",
      "Epoch 101/200, Loss: 0.0050010723128382645\n",
      "0.7010947289652434\n",
      "Epoch 111/200, Loss: 0.004372614535636136\n",
      "0.704621850295287\n",
      "Epoch 121/200, Loss: 0.003879021021670529\n",
      "0.7150097442654222\n",
      "Epoch 131/200, Loss: 0.003712161909788847\n",
      "0.7012947048629491\n",
      "Epoch 141/200, Loss: 0.00336945949654494\n",
      "0.7185811419342195\n",
      "Epoch 151/200, Loss: 0.0031585508092705694\n",
      "0.7267271760175867\n",
      "Epoch 161/200, Loss: 0.003070902934164873\n",
      "0.7194893130262109\n",
      "Epoch 171/200, Loss: 0.003113551690642323\n",
      "0.7056915400195959\n",
      "Epoch 181/200, Loss: 0.0029953912033566406\n",
      "0.7173070086882153\n",
      "Epoch 191/200, Loss: 0.002706497481891087\n",
      "0.7236714337783087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:25:13,505] Trial 4 finished with value: 0.7267271760175867 and parameters: {'hidden_dim_h': 38, 'dropout': 0.3237856880974136, 'batch_size': 289}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.0635716241191734\n",
      "0.11085390372517458\n",
      "Epoch 11/200, Loss: 0.03750039044428955\n",
      "0.13620313437380865\n",
      "Epoch 21/200, Loss: 0.03474203277040611\n",
      "0.30541400046557876\n",
      "Epoch 31/200, Loss: 0.027457663789391518\n",
      "0.5362982928156825\n",
      "Epoch 41/200, Loss: 0.02110467724163424\n",
      "0.5610452311189069\n",
      "Epoch 51/200, Loss: 0.016411157536574385\n",
      "0.5944333659123895\n",
      "Epoch 61/200, Loss: 0.0127894801765003\n",
      "0.610874394563695\n",
      "Epoch 71/200, Loss: 0.010825758291916414\n",
      "0.6141289934680733\n",
      "Epoch 81/200, Loss: 0.009103668049316515\n",
      "0.6337503623144427\n",
      "Epoch 91/200, Loss: 0.008033619833771478\n",
      "0.6402988386226902\n",
      "Epoch 101/200, Loss: 0.0073269288351928644\n",
      "0.646407855119236\n",
      "Epoch 111/200, Loss: 0.006953050932762298\n",
      "0.6378400132489653\n",
      "Epoch 121/200, Loss: 0.006354109595783732\n",
      "0.6486999625966599\n",
      "Epoch 131/200, Loss: 0.00591332046315074\n",
      "0.654127953931076\n",
      "Epoch 141/200, Loss: 0.005638304229995067\n",
      "0.659424566588275\n",
      "Epoch 151/200, Loss: 0.005319324269128794\n",
      "0.6645211118570477\n",
      "Epoch 161/200, Loss: 0.005225151438604702\n",
      "0.6681190899984885\n",
      "Epoch 171/200, Loss: 0.00499124776317992\n",
      "0.6674759977633589\n",
      "Epoch 181/200, Loss: 0.004734466243958609\n",
      "0.6614510378685106\n",
      "Epoch 191/200, Loss: 0.004748207823881371\n",
      "0.6719833774741647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:27:28,011] Trial 5 finished with value: 0.6719833774741647 and parameters: {'hidden_dim_h': 16, 'dropout': 0.208127052503767, 'batch_size': 461}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 1.496183512841954\n",
      "0.12191021384509926\n",
      "Epoch 11/200, Loss: 0.22133812571273132\n",
      "0.0014397696520597023\n",
      "Epoch 21/200, Loss: 0.02812853776028051\n",
      "0.36428253674928684\n",
      "Epoch 31/200, Loss: 0.021792259135776582\n",
      "0.3872878545476795\n",
      "Epoch 41/200, Loss: 0.024001893340883887\n",
      "0.36575850867797427\n",
      "Epoch 51/200, Loss: 0.02215554236489184\n",
      "0.37827160856277536\n",
      "Epoch 61/200, Loss: 0.0225782834322137\n",
      "0.3874074160350013\n",
      "Epoch 71/200, Loss: 0.03157290742349099\n",
      "0.2593226905702694\n",
      "Epoch 81/200, Loss: 0.030044407967258904\n",
      "0.2691209846312611\n",
      "Epoch 91/200, Loss: 0.032798768158125526\n",
      "0.22690702084803543\n",
      "Epoch 101/200, Loss: 0.032472529092474896\n",
      "0.2636902737677579\n",
      "Epoch 111/200, Loss: 0.03280352091635851\n",
      "0.20514269590526535\n",
      "Epoch 121/200, Loss: 0.03010152400854756\n",
      "0.28808709447581615\n",
      "Epoch 131/200, Loss: 0.03100093884174438\n",
      "0.2916110015452743\n",
      "Epoch 141/200, Loss: 0.030613115714753374\n",
      "0.30503412615187664\n",
      "Epoch 151/200, Loss: 0.0325425964067964\n",
      "0.24070668754454813\n",
      "Epoch 161/200, Loss: 0.03176018677871017\n",
      "0.2675159597763135\n",
      "Epoch 171/200, Loss: 0.03329657097620999\n",
      "0.18801041758347456\n",
      "Epoch 181/200, Loss: 0.03332222600960556\n",
      "0.2007840432400342\n",
      "Epoch 191/200, Loss: 0.03315573478774989\n",
      "0.20223319095117742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:31:14,026] Trial 6 finished with value: 0.3874074160350013 and parameters: {'hidden_dim_h': 47, 'dropout': 0.19963389574986196, 'batch_size': 149}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.7747919945805161\n",
      "0.010028844245781461\n",
      "Epoch 11/200, Loss: 0.07764048763999233\n",
      "0.4819487797780522\n",
      "Epoch 21/200, Loss: 0.011129917939090066\n",
      "0.61900250810244\n",
      "Epoch 31/200, Loss: 0.006581166159810015\n",
      "0.6392746021294403\n",
      "Epoch 41/200, Loss: 0.0055464534951304946\n",
      "0.6722665658112575\n",
      "Epoch 51/200, Loss: 0.004836758206322513\n",
      "0.6557093792114413\n",
      "Epoch 61/200, Loss: 0.004431755598893182\n",
      "0.6687165518602737\n",
      "Epoch 71/200, Loss: 0.004091976262215111\n",
      "0.6870861595351639\n",
      "Epoch 81/200, Loss: 0.0037428815784450206\n",
      "0.6785820218437353\n",
      "Epoch 91/200, Loss: 0.0035811993573723294\n",
      "0.6921178107497638\n",
      "Epoch 101/200, Loss: 0.003447452169860265\n",
      "0.6848064462773333\n",
      "Epoch 111/200, Loss: 0.0032441033033171187\n",
      "0.6968911157157288\n",
      "Epoch 121/200, Loss: 0.0032317642946037704\n",
      "0.7037610741312856\n",
      "Epoch 131/200, Loss: 0.0029825530321061335\n",
      "0.6980348966291651\n",
      "Epoch 141/200, Loss: 0.0030795322187865772\n",
      "0.7007806811284236\n",
      "Epoch 151/200, Loss: 0.0028352312252132427\n",
      "0.6977147997070031\n",
      "Epoch 161/200, Loss: 0.002814134250877908\n",
      "0.7013115345548437\n",
      "Epoch 171/200, Loss: 0.0027328498351077237\n",
      "0.7067757183869265\n",
      "Epoch 181/200, Loss: 0.0026526388289682843\n",
      "0.6948254809291758\n",
      "Epoch 191/200, Loss: 0.002587199801820572\n",
      "0.7034126143702092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:34:23,788] Trial 7 finished with value: 0.7067757183869265 and parameters: {'hidden_dim_h': 36, 'dropout': 0.30120467367665155, 'batch_size': 186}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 1.233579613945701\n",
      "0.07223239608467173\n",
      "Epoch 11/200, Loss: 0.895660324530168\n",
      "0.025760325015021377\n",
      "Epoch 21/200, Loss: 0.6454003778370944\n",
      "0.04891379565151851\n",
      "Epoch 31/200, Loss: 0.44427012584426184\n",
      "0.15878884983461702\n",
      "Epoch 41/200, Loss: 0.3082572275942022\n",
      "0.34442662960448034\n",
      "Epoch 51/200, Loss: 0.207140098918568\n",
      "0.5538743779751079\n",
      "Epoch 61/200, Loss: 0.1415257386185906\n",
      "0.6144934653810564\n",
      "Epoch 71/200, Loss: 0.09847255457531322\n",
      "0.6531805982100455\n",
      "Epoch 81/200, Loss: 0.07196203348311511\n",
      "0.6643176124948881\n",
      "Epoch 91/200, Loss: 0.05539581382816488\n",
      "0.6641123306008969\n",
      "Epoch 101/200, Loss: 0.0459345822984522\n",
      "0.6608029966956436\n",
      "Epoch 111/200, Loss: 0.04049960930239071\n",
      "0.6624321630546169\n",
      "Epoch 121/200, Loss: 0.037426882508126175\n",
      "0.6694698632705486\n",
      "Epoch 131/200, Loss: 0.03548741916363889\n",
      "0.6644568238757373\n",
      "Epoch 141/200, Loss: 0.033963296901096\n",
      "0.6692964567635242\n",
      "Epoch 151/200, Loss: 0.03288147209042853\n",
      "0.6697130568983423\n",
      "Epoch 161/200, Loss: 0.03148865581236102\n",
      "0.6757302499408879\n",
      "Epoch 171/200, Loss: 0.030522128397768192\n",
      "0.6683256289978946\n",
      "Epoch 181/200, Loss: 0.029201124202121388\n",
      "0.6741492136069771\n",
      "Epoch 191/200, Loss: 0.028100462969053875\n",
      "0.6860486352645085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:36:55,556] Trial 8 finished with value: 0.6860486352645085 and parameters: {'hidden_dim_h': 25, 'dropout': 0.26112051275194076, 'batch_size': 953}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.6274914801120758\n",
      "0.07680425576221765\n",
      "Epoch 11/200, Loss: 0.4189832717180252\n",
      "0.0838427366700981\n",
      "Epoch 21/200, Loss: 0.2758780211210251\n",
      "0.10004233648670037\n",
      "Epoch 31/200, Loss: 0.1696348711848259\n",
      "0.2248648998611994\n",
      "Epoch 41/200, Loss: 0.1046435259282589\n",
      "0.34732069984555575\n",
      "Epoch 51/200, Loss: 0.06489618457853794\n",
      "0.44228935856102986\n",
      "Epoch 61/200, Loss: 0.040306539833545686\n",
      "0.5100334845928309\n",
      "Epoch 71/200, Loss: 0.02862170021981001\n",
      "0.5363230651292121\n",
      "Epoch 81/200, Loss: 0.023102558217942715\n",
      "0.5443393721779195\n",
      "Epoch 91/200, Loss: 0.0196915864944458\n",
      "0.550721682495308\n",
      "Epoch 101/200, Loss: 0.01851581037044525\n",
      "0.5561905590967648\n",
      "Epoch 111/200, Loss: 0.017425858601927757\n",
      "0.5568087811437764\n",
      "Epoch 121/200, Loss: 0.01670399624854326\n",
      "0.5542344414040131\n",
      "Epoch 131/200, Loss: 0.016112884134054185\n",
      "0.5873687811860895\n",
      "Epoch 141/200, Loss: 0.015744432620704175\n",
      "0.5801798516712824\n",
      "Epoch 151/200, Loss: 0.014982342533767224\n",
      "0.5976650791465951\n",
      "Epoch 161/200, Loss: 0.0144896125420928\n",
      "0.6040337405519123\n",
      "Epoch 171/200, Loss: 0.013930321950465441\n",
      "0.6045545315583136\n",
      "Epoch 181/200, Loss: 0.013521139789372683\n",
      "0.6057854491655842\n",
      "Epoch 191/200, Loss: 0.012934154737740755\n",
      "0.5938581654936346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:38:57,932] Trial 9 finished with value: 0.6057854491655842 and parameters: {'hidden_dim_h': 10, 'dropout': 0.10350129452275783, 'batch_size': 1008}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.8045425625408397\n",
      "0.001354065154607628\n",
      "Epoch 11/200, Loss: 0.40062815827481885\n",
      "0.17263226921368244\n",
      "Epoch 21/200, Loss: 0.20040957629680634\n",
      "0.41646641059743206\n",
      "Epoch 31/200, Loss: 0.09506263583898544\n",
      "0.5573837095395237\n",
      "Epoch 41/200, Loss: 0.04666306341395659\n",
      "0.6155089177017646\n",
      "Epoch 51/200, Loss: 0.027842355892062187\n",
      "0.6406153104216327\n",
      "Epoch 61/200, Loss: 0.021531007964821422\n",
      "0.6607270326390162\n",
      "Epoch 71/200, Loss: 0.019121017635745162\n",
      "0.6578250023397494\n",
      "Epoch 81/200, Loss: 0.017939804669688728\n",
      "0.6533504540415674\n",
      "Epoch 91/200, Loss: 0.0167999536565998\n",
      "0.660072311502439\n",
      "Epoch 101/200, Loss: 0.015774956630433306\n",
      "0.6535663680204337\n",
      "Epoch 111/200, Loss: 0.014597311615943909\n",
      "0.6653726100572714\n",
      "Epoch 121/200, Loss: 0.013545136296135537\n",
      "0.6614921616283983\n",
      "Epoch 131/200, Loss: 0.012487678185981862\n",
      "0.6540661988673018\n",
      "Epoch 141/200, Loss: 0.011471306795583051\n",
      "0.6707938828267425\n",
      "Epoch 151/200, Loss: 0.010459634749328388\n",
      "0.6725066794195901\n",
      "Epoch 161/200, Loss: 0.009522987748770154\n",
      "0.672061799734005\n",
      "Epoch 171/200, Loss: 0.008589009042171872\n",
      "0.6746366366195127\n",
      "Epoch 181/200, Loss: 0.007767305134192985\n",
      "0.6794348742297848\n",
      "Epoch 191/200, Loss: 0.00696309601121089\n",
      "0.6926558131725822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:42:42,133] Trial 10 finished with value: 0.6926558131725822 and parameters: {'hidden_dim_h': 50, 'dropout': 0.33223956764774293, 'batch_size': 593}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 2.933260897795359\n",
      "0.04844741155780644\n",
      "Epoch 11/200, Loss: 1.7874217182397842\n",
      "0.0725231177755308\n",
      "Epoch 21/200, Loss: 1.093468760450681\n",
      "0.3215467283238981\n",
      "Epoch 31/200, Loss: 0.6342854003111521\n",
      "0.4558557236628472\n",
      "Epoch 41/200, Loss: 0.34854500740766525\n",
      "0.510958205822039\n",
      "Epoch 51/200, Loss: 0.1856096008171638\n",
      "0.5389798662590319\n",
      "Epoch 61/200, Loss: 0.10235089839746554\n",
      "0.5946133429852503\n",
      "Epoch 71/200, Loss: 0.06465964562570055\n",
      "0.6136071900101838\n",
      "Epoch 81/200, Loss: 0.04926612740382552\n",
      "0.6219412958479745\n",
      "Epoch 91/200, Loss: 0.04301296422878901\n",
      "0.6294818667227886\n",
      "Epoch 101/200, Loss: 0.03972769776980082\n",
      "0.6323115861454518\n",
      "Epoch 111/200, Loss: 0.03727176715619862\n",
      "0.6347935749183059\n",
      "Epoch 121/200, Loss: 0.03490982096021374\n",
      "0.6479624502920973\n",
      "Epoch 131/200, Loss: 0.03236837452277541\n",
      "0.6495667358816589\n",
      "Epoch 141/200, Loss: 0.02982608143550654\n",
      "0.6643101743081299\n",
      "Epoch 151/200, Loss: 0.02719254101005693\n",
      "0.6731242251298938\n",
      "Epoch 161/200, Loss: 0.024488687049597502\n",
      "0.674245558695204\n",
      "Epoch 171/200, Loss: 0.021960807188103598\n",
      "0.6912150315143267\n",
      "Epoch 181/200, Loss: 0.01921392243821174\n",
      "0.6864568528739985\n",
      "Epoch 191/200, Loss: 0.016693999331134062\n",
      "0.6767052593531524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:45:27,099] Trial 11 finished with value: 0.6912150315143267 and parameters: {'hidden_dim_h': 32, 'dropout': 0.05094702887306035, 'batch_size': 419}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.8151481673121452\n",
      "0.044357120291558444\n",
      "Epoch 11/200, Loss: 0.4690378066152334\n",
      "0.033819950344337726\n",
      "Epoch 21/200, Loss: 0.2583836391568184\n",
      "0.07288120171729748\n",
      "Epoch 31/200, Loss: 0.13789029978215694\n",
      "0.15237499241501096\n",
      "Epoch 41/200, Loss: 0.0671052522957325\n",
      "0.535002252042303\n",
      "Epoch 51/200, Loss: 0.03555993945337832\n",
      "0.6288279114428023\n",
      "Epoch 61/200, Loss: 0.023706697626039386\n",
      "0.6682543373287012\n",
      "Epoch 71/200, Loss: 0.019445564248599112\n",
      "0.6743430331990099\n",
      "Epoch 81/200, Loss: 0.017703327408526093\n",
      "0.6827536665355581\n",
      "Epoch 91/200, Loss: 0.016665293311234564\n",
      "0.686825658815588\n",
      "Epoch 101/200, Loss: 0.015764573239721358\n",
      "0.671243086848578\n",
      "Epoch 111/200, Loss: 0.014858716225717217\n",
      "0.6714510969200189\n",
      "Epoch 121/200, Loss: 0.01399248221423477\n",
      "0.6575293070590292\n",
      "Epoch 131/200, Loss: 0.013053851609583944\n",
      "0.6767239141429549\n",
      "Epoch 141/200, Loss: 0.01211459340993315\n",
      "0.671322832477742\n",
      "Epoch 151/200, Loss: 0.01130539964651689\n",
      "0.683564540447626\n",
      "Epoch 161/200, Loss: 0.010375869576819241\n",
      "0.6779072785433186\n",
      "Epoch 171/200, Loss: 0.009537169942632318\n",
      "0.6746523607474811\n",
      "Epoch 181/200, Loss: 0.00875733670545742\n",
      "0.67756560514649\n",
      "Epoch 191/200, Loss: 0.007983052404597402\n",
      "0.6861371160662725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:48:31,657] Trial 12 finished with value: 0.686825658815588 and parameters: {'hidden_dim_h': 38, 'dropout': 0.18489772236579985, 'batch_size': 631}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 1.6982647303877205\n",
      "0.011330678646488335\n",
      "Epoch 11/200, Loss: 0.8209443544519359\n",
      "0.19867416938460356\n",
      "Epoch 21/200, Loss: 0.36796569413152236\n",
      "0.0026469928222890337\n",
      "Epoch 31/200, Loss: 0.13417684723590984\n",
      "0.4371758915444293\n",
      "Epoch 41/200, Loss: 0.045821579879727854\n",
      "0.6232662262743456\n",
      "Epoch 51/200, Loss: 0.019632530238094\n",
      "0.6741694759018012\n",
      "Epoch 61/200, Loss: 0.013259402219334552\n",
      "0.6859814315909278\n",
      "Epoch 71/200, Loss: 0.011482788667339703\n",
      "0.6914873487267489\n",
      "Epoch 81/200, Loss: 0.010630689304450462\n",
      "0.6907802576787266\n",
      "Epoch 91/200, Loss: 0.00991381634155224\n",
      "0.6959608678367731\n",
      "Epoch 101/200, Loss: 0.009086605562860596\n",
      "0.6953753560408683\n",
      "Epoch 111/200, Loss: 0.00825609168808522\n",
      "0.70847569890274\n",
      "Epoch 121/200, Loss: 0.007450375192124268\n",
      "0.7000610618168366\n",
      "Epoch 131/200, Loss: 0.006739519970041925\n",
      "0.7017135178461678\n",
      "Epoch 141/200, Loss: 0.006019756181872097\n",
      "0.6946719971292994\n",
      "Epoch 151/200, Loss: 0.005342639693669204\n",
      "0.6985910224736046\n",
      "Epoch 161/200, Loss: 0.00482631283651652\n",
      "0.6933330669890024\n",
      "Epoch 171/200, Loss: 0.0043409259604482815\n",
      "0.7012382874896222\n",
      "Epoch 181/200, Loss: 0.0040044057150853095\n",
      "0.6893324137012828\n",
      "Epoch 191/200, Loss: 0.0036970682658961623\n",
      "0.6905936317625785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:51:14,865] Trial 13 finished with value: 0.70847569890274 and parameters: {'hidden_dim_h': 30, 'dropout': 0.34787101228428424, 'batch_size': 347}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.12409578206447455\n",
      "0.06542232253727522\n",
      "Epoch 11/200, Loss: 0.04732150813707939\n",
      "0.2941300508052278\n",
      "Epoch 21/200, Loss: 0.02855870299614393\n",
      "0.5091451219874262\n",
      "Epoch 31/200, Loss: 0.023659174402172748\n",
      "0.5967396970894222\n",
      "Epoch 41/200, Loss: 0.021000872151209757\n",
      "0.6486162791061224\n",
      "Epoch 51/200, Loss: 0.018879977986216545\n",
      "0.6519042696426758\n",
      "Epoch 61/200, Loss: 0.01651269097167712\n",
      "0.6415174652210291\n",
      "Epoch 71/200, Loss: 0.014404484429038487\n",
      "0.6867872283787085\n",
      "Epoch 81/200, Loss: 0.012558535027962465\n",
      "0.7075707214520982\n",
      "Epoch 91/200, Loss: 0.01088366936892271\n",
      "0.6991269389126545\n",
      "Epoch 101/200, Loss: 0.009307276314267745\n",
      "0.7168540258686755\n",
      "Epoch 111/200, Loss: 0.008306886356037397\n",
      "0.7150440761261592\n",
      "Epoch 121/200, Loss: 0.006988057795052345\n",
      "0.7047414863473678\n",
      "Epoch 131/200, Loss: 0.006015073185643325\n",
      "0.7204060098193807\n",
      "Epoch 141/200, Loss: 0.005295437653190815\n",
      "0.7198681689001422\n",
      "Epoch 151/200, Loss: 0.004866528951634581\n",
      "0.7240682237200363\n",
      "Epoch 161/200, Loss: 0.004317378858104348\n",
      "0.718484897700394\n",
      "Epoch 171/200, Loss: 0.0038356135348574473\n",
      "0.7181484567211164\n",
      "Epoch 181/200, Loss: 0.0037891459113989887\n",
      "0.7067515082457736\n",
      "Epoch 191/200, Loss: 0.003325474520142262\n",
      "0.7120475589159146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:54:28,837] Trial 14 finished with value: 0.7240682237200363 and parameters: {'hidden_dim_h': 41, 'dropout': 0.07028702858961314, 'batch_size': 773}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.9374818939429063\n",
      "0.0725899495192052\n",
      "Epoch 11/200, Loss: 0.5926892528167138\n",
      "0.0026090827692178786\n",
      "Epoch 21/200, Loss: 0.3440289474450625\n",
      "0.24989184213833932\n",
      "Epoch 31/200, Loss: 0.2048709736420558\n",
      "0.4668666944342695\n",
      "Epoch 41/200, Loss: 0.11892279867942517\n",
      "0.5287739504321701\n",
      "Epoch 51/200, Loss: 0.06935275260072488\n",
      "0.6014737410473279\n",
      "Epoch 61/200, Loss: 0.04343561398295256\n",
      "0.6424997256149111\n",
      "Epoch 71/200, Loss: 0.03131812552993114\n",
      "0.6477956849861446\n",
      "Epoch 81/200, Loss: 0.025780092351711713\n",
      "0.6588390280258771\n",
      "Epoch 91/200, Loss: 0.023062346789699335\n",
      "0.6713448502653927\n",
      "Epoch 101/200, Loss: 0.02090928416985732\n",
      "0.675120656203767\n",
      "Epoch 111/200, Loss: 0.01978572694441447\n",
      "0.6702645437029396\n",
      "Epoch 121/200, Loss: 0.018910460317364104\n",
      "0.6826697313164598\n",
      "Epoch 131/200, Loss: 0.01805428250764425\n",
      "0.6936732300169327\n",
      "Epoch 141/200, Loss: 0.017312961129041817\n",
      "0.6725342121921156\n",
      "Epoch 151/200, Loss: 0.016391299450053617\n",
      "0.6830231306723826\n",
      "Epoch 161/200, Loss: 0.015418596780644013\n",
      "0.6658193665350098\n",
      "Epoch 171/200, Loss: 0.014581367445106689\n",
      "0.6885443622120125\n",
      "Epoch 181/200, Loss: 0.013871573484860934\n",
      "0.6750856800535259\n",
      "Epoch 191/200, Loss: 0.012808670289814472\n",
      "0.6952824554692923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 11:57:42,931] Trial 15 finished with value: 0.6952824554692923 and parameters: {'hidden_dim_h': 42, 'dropout': 0.05011668030583204, 'batch_size': 821}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.0717619055738816\n",
      "0.11073280279634302\n",
      "Epoch 11/200, Loss: 0.03347160824789451\n",
      "0.27350019601544834\n",
      "Epoch 21/200, Loss: 0.015107538980933337\n",
      "0.5519049954184401\n",
      "Epoch 31/200, Loss: 0.008949540304736449\n",
      "0.6087502788620672\n",
      "Epoch 41/200, Loss: 0.007025774604139419\n",
      "0.6783314444046509\n",
      "Epoch 51/200, Loss: 0.006363964997805082\n",
      "0.680987999010982\n",
      "Epoch 61/200, Loss: 0.005748153091050112\n",
      "0.6853567440116362\n",
      "Epoch 71/200, Loss: 0.005284954292269854\n",
      "0.6872491385139934\n",
      "Epoch 81/200, Loss: 0.004942257225943299\n",
      "0.6927376282956125\n",
      "Epoch 91/200, Loss: 0.004696578127690232\n",
      "0.6927943695165616\n",
      "Epoch 101/200, Loss: 0.004390752766854488\n",
      "0.702979841418105\n",
      "Epoch 111/200, Loss: 0.004467321828437539\n",
      "0.6942970260700435\n",
      "Epoch 121/200, Loss: 0.004133915904766092\n",
      "0.7112819673612639\n",
      "Epoch 131/200, Loss: 0.003913914766879036\n",
      "0.7129268075916952\n",
      "Epoch 141/200, Loss: 0.00379340578085528\n",
      "0.7147165380903022\n",
      "Epoch 151/200, Loss: 0.0036652111269247075\n",
      "0.7086713626247356\n",
      "Epoch 161/200, Loss: 0.003656262388596168\n",
      "0.7207187308363433\n",
      "Epoch 171/200, Loss: 0.0034367070676615606\n",
      "0.7196822022645205\n",
      "Epoch 181/200, Loss: 0.003362207100368463\n",
      "0.7167052693232222\n",
      "Epoch 191/200, Loss: 0.0032097635647425284\n",
      "0.7170349021931648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:01:02,417] Trial 16 finished with value: 0.7207187308363433 and parameters: {'hidden_dim_h': 43, 'dropout': 0.16886612254531871, 'batch_size': 770}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.09648650139570236\n",
      "0.11442022606482738\n",
      "Epoch 11/200, Loss: 0.0570216683877839\n",
      "0.13172765953732582\n",
      "Epoch 21/200, Loss: 0.030489213971628085\n",
      "0.2722448833234483\n",
      "Epoch 31/200, Loss: 0.01979648590915733\n",
      "0.48995254253461196\n",
      "Epoch 41/200, Loss: 0.016301194930242166\n",
      "0.5081502864837719\n",
      "Epoch 51/200, Loss: 0.014017197406954236\n",
      "0.5313598083750927\n",
      "Epoch 61/200, Loss: 0.011986407244371044\n",
      "0.545542703616855\n",
      "Epoch 71/200, Loss: 0.011162278449369801\n",
      "0.543812479468657\n",
      "Epoch 81/200, Loss: 0.009967004362907674\n",
      "0.5787861624575799\n",
      "Epoch 91/200, Loss: 0.008999194225503339\n",
      "0.5866743880547391\n",
      "Epoch 101/200, Loss: 0.008322744630277157\n",
      "0.6115347944893421\n",
      "Epoch 111/200, Loss: 0.008057605113006301\n",
      "0.621160084532093\n",
      "Epoch 121/200, Loss: 0.007272603352450662\n",
      "0.6328180834879914\n",
      "Epoch 131/200, Loss: 0.006896618132789929\n",
      "0.6329941949197209\n",
      "Epoch 141/200, Loss: 0.0067651790256301565\n",
      "0.6307440121369955\n",
      "Epoch 151/200, Loss: 0.0066670519299805164\n",
      "0.6254595452212581\n",
      "Epoch 161/200, Loss: 0.006320560092313422\n",
      "0.6315771032640868\n",
      "Epoch 171/200, Loss: 0.006032073559860389\n",
      "0.6394348510142568\n",
      "Epoch 181/200, Loss: 0.005788308309598101\n",
      "0.6434762005269375\n",
      "Epoch 191/200, Loss: 0.005560826199750106\n",
      "0.6418970874273304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:03:38,416] Trial 17 finished with value: 0.6434762005269375 and parameters: {'hidden_dim_h': 27, 'dropout': 0.24353453980671558, 'batch_size': 1161}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.36981703639030455\n",
      "0.09646986503648741\n",
      "Epoch 11/200, Loss: 0.1307476844638586\n",
      "0.22823678294631533\n",
      "Epoch 21/200, Loss: 0.03380524916574359\n",
      "0.547740867753293\n",
      "Epoch 31/200, Loss: 0.011805742513388395\n",
      "0.6229564410287315\n",
      "Epoch 41/200, Loss: 0.007970381900668145\n",
      "0.6582286939489782\n",
      "Epoch 51/200, Loss: 0.006589255458675325\n",
      "0.6803440333443326\n",
      "Epoch 61/200, Loss: 0.006219367845915258\n",
      "0.6751429863375042\n",
      "Epoch 71/200, Loss: 0.00561970928683877\n",
      "0.6832294376439453\n",
      "Epoch 81/200, Loss: 0.005137303215451539\n",
      "0.6929518962829826\n",
      "Epoch 91/200, Loss: 0.004981741087976843\n",
      "0.695103427085896\n",
      "Epoch 101/200, Loss: 0.004689699946902692\n",
      "0.6951954924077725\n",
      "Epoch 111/200, Loss: 0.004607992409728467\n",
      "0.677431727673617\n",
      "Epoch 121/200, Loss: 0.004121383186429739\n",
      "0.6829440230534543\n",
      "Epoch 131/200, Loss: 0.0045095821958966555\n",
      "0.6899257111133577\n",
      "Epoch 141/200, Loss: 0.004276066122110933\n",
      "0.6862177059921651\n",
      "Epoch 151/200, Loss: 0.0037538732518441974\n",
      "0.6946693223044803\n",
      "Epoch 161/200, Loss: 0.003786241065245122\n",
      "0.6963293350093974\n",
      "Epoch 171/200, Loss: 0.003483455587411299\n",
      "0.6887795564552652\n",
      "Epoch 181/200, Loss: 0.003503003530204296\n",
      "0.6963949629740556\n",
      "Epoch 191/200, Loss: 0.003438813122920692\n",
      "0.6954539983514209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:06:38,881] Trial 18 finished with value: 0.6963949629740556 and parameters: {'hidden_dim_h': 36, 'dropout': 0.3088772738445496, 'batch_size': 522}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.08313104808330536\n",
      "0.057197797212318574\n",
      "Epoch 11/200, Loss: 0.030877175802985827\n",
      "0.2456675138165145\n",
      "Epoch 21/200, Loss: 0.014007931388914586\n",
      "0.5999911103118278\n",
      "Epoch 31/200, Loss: 0.010530373640358448\n",
      "0.6604119387247904\n",
      "Epoch 41/200, Loss: 0.008854719437658786\n",
      "0.6736656330996416\n",
      "Epoch 51/200, Loss: 0.007405082229524851\n",
      "0.6655608330264341\n",
      "Epoch 61/200, Loss: 0.00668300058071812\n",
      "0.6819134484311392\n",
      "Epoch 71/200, Loss: 0.005831720369557539\n",
      "0.7075425835307279\n",
      "Epoch 81/200, Loss: 0.005105008898923794\n",
      "0.7058651002533591\n",
      "Epoch 91/200, Loss: 0.004671158098305265\n",
      "0.701873440115838\n",
      "Epoch 101/200, Loss: 0.004319204498703281\n",
      "0.6996077208073492\n",
      "Epoch 111/200, Loss: 0.004143399621049563\n",
      "0.706378108468557\n",
      "Epoch 121/200, Loss: 0.003909203875809908\n",
      "0.706387733398738\n",
      "Epoch 131/200, Loss: 0.003681143218030532\n",
      "0.7097271625371694\n",
      "Epoch 141/200, Loss: 0.0035618414326260488\n",
      "0.7088403997211455\n",
      "Epoch 151/200, Loss: 0.003357116458937526\n",
      "0.7026955921436215\n",
      "Epoch 161/200, Loss: 0.0033269953137884537\n",
      "0.7077266095076956\n",
      "Epoch 171/200, Loss: 0.003144309250637889\n",
      "0.7021770497403611\n",
      "Epoch 181/200, Loss: 0.0030913043146332106\n",
      "0.7083019089120332\n",
      "Epoch 191/200, Loss: 0.00298220570354412\n",
      "0.7015030760304903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:09:53,935] Trial 19 finished with value: 0.7097271625371694 and parameters: {'hidden_dim_h': 41, 'dropout': 0.22951733721887418, 'batch_size': 695}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.7069848125631158\n",
      "0.015840113042867213\n",
      "Epoch 11/200, Loss: 0.4671272174878554\n",
      "0.0012869281329340393\n",
      "Epoch 21/200, Loss: 0.26300476355986163\n",
      "0.21954735697751537\n",
      "Epoch 31/200, Loss: 0.16014562682671982\n",
      "0.4949481500490293\n",
      "Epoch 41/200, Loss: 0.09460227665576068\n",
      "0.5586460955469609\n",
      "Epoch 51/200, Loss: 0.056122890588912094\n",
      "0.6025998971775517\n",
      "Epoch 61/200, Loss: 0.03501320410181175\n",
      "0.6457764599603201\n",
      "Epoch 71/200, Loss: 0.024137820201841267\n",
      "0.6577221382599212\n",
      "Epoch 81/200, Loss: 0.01893107203597372\n",
      "0.6641363663996099\n",
      "Epoch 91/200, Loss: 0.016384793022139507\n",
      "0.6833827450518732\n",
      "Epoch 101/200, Loss: 0.01535215796056119\n",
      "0.6727750011006818\n",
      "Epoch 111/200, Loss: 0.014572220261801373\n",
      "0.6791376101409359\n",
      "Epoch 121/200, Loss: 0.014029091732068495\n",
      "0.6842050394710392\n",
      "Epoch 131/200, Loss: 0.013423716310750355\n",
      "0.6831689135620391\n",
      "Epoch 141/200, Loss: 0.012908464720980688\n",
      "0.6707564232012815\n",
      "Epoch 151/200, Loss: 0.012290473011406984\n",
      "0.6850931405768158\n",
      "Epoch 161/200, Loss: 0.011747933162206953\n",
      "0.6936568868142234\n",
      "Epoch 171/200, Loss: 0.011234288696538319\n",
      "0.6862132949086379\n",
      "Epoch 181/200, Loss: 0.0106126597489823\n",
      "0.6834742540843481\n",
      "Epoch 191/200, Loss: 0.010069759308614513\n",
      "0.6836995037882151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:13:37,602] Trial 20 finished with value: 0.6936568868142234 and parameters: {'hidden_dim_h': 49, 'dropout': 0.15484995967324078, 'batch_size': 937}. Best is trial 4 with value: 0.7267271760175867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.21296665498188563\n",
      "0.021418132788516328\n",
      "Epoch 11/200, Loss: 0.08610507047602109\n",
      "0.2867671920382877\n",
      "Epoch 21/200, Loss: 0.03487743543727057\n",
      "0.5551995777754809\n",
      "Epoch 31/200, Loss: 0.02066487180335181\n",
      "0.6583098803287787\n",
      "Epoch 41/200, Loss: 0.017181004264525006\n",
      "0.6864967936532099\n",
      "Epoch 51/200, Loss: 0.015573706743972642\n",
      "0.6775300455087538\n",
      "Epoch 61/200, Loss: 0.014440674600856645\n",
      "0.7142305464001867\n",
      "Epoch 71/200, Loss: 0.01314116142956274\n",
      "0.7093591429169271\n",
      "Epoch 81/200, Loss: 0.011973274139953511\n",
      "0.7240705364588289\n",
      "Epoch 91/200, Loss: 0.011014055527214493\n",
      "0.7063051296782841\n",
      "Epoch 101/200, Loss: 0.00964548934384116\n",
      "0.7284529223194621\n",
      "Epoch 111/200, Loss: 0.008688046729990415\n",
      "0.7325452829742117\n",
      "Epoch 121/200, Loss: 0.0077429914048739844\n",
      "0.7256103008681897\n",
      "Epoch 131/200, Loss: 0.00698652770370245\n",
      "0.7266019398210178\n",
      "Epoch 141/200, Loss: 0.006168263665001307\n",
      "0.7244904054065368\n",
      "Epoch 151/200, Loss: 0.005508044834381768\n",
      "0.7222713588980431\n",
      "Epoch 161/200, Loss: 0.004882324037940374\n",
      "0.7334518543433192\n",
      "Epoch 171/200, Loss: 0.004426864508007254\n",
      "0.7307891404486327\n",
      "Epoch 181/200, Loss: 0.003983993415853807\n",
      "0.7392912055877313\n",
      "Epoch 191/200, Loss: 0.0036720632508929285\n",
      "0.7425865426643594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:17:00,614] Trial 21 finished with value: 0.7425865426643594 and parameters: {'hidden_dim_h': 45, 'dropout': 0.07999199169804899, 'batch_size': 736}. Best is trial 21 with value: 0.7425865426643594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 2.2843485832214356\n",
      "0.1229810977496061\n",
      "Epoch 11/200, Loss: 1.676029634475708\n",
      "0.12155797351881187\n",
      "Epoch 21/200, Loss: 1.1785526831944784\n",
      "0.20029025995299088\n",
      "Epoch 31/200, Loss: 0.8265440901120503\n",
      "0.334315765014376\n",
      "Epoch 41/200, Loss: 0.5666505972544352\n",
      "0.4392871577231968\n",
      "Epoch 51/200, Loss: 0.3790020664532979\n",
      "0.48621028640210334\n",
      "Epoch 61/200, Loss: 0.2488766183455785\n",
      "0.540316278047815\n",
      "Epoch 71/200, Loss: 0.16276754339536031\n",
      "0.5907604938513348\n",
      "Epoch 81/200, Loss: 0.10878129700819651\n",
      "0.6205470995531094\n",
      "Epoch 91/200, Loss: 0.07672417908906937\n",
      "0.6338341825515036\n",
      "Epoch 101/200, Loss: 0.058629804849624635\n",
      "0.6403770034632881\n",
      "Epoch 111/200, Loss: 0.048802999903758366\n",
      "0.6492668210500625\n",
      "Epoch 121/200, Loss: 0.04350267375508944\n",
      "0.6508986483564871\n",
      "Epoch 131/200, Loss: 0.04043525531888008\n",
      "0.6556424708837822\n",
      "Epoch 141/200, Loss: 0.03837364812692006\n",
      "0.6511592573887687\n",
      "Epoch 151/200, Loss: 0.036698172241449355\n",
      "0.644505440914464\n",
      "Epoch 161/200, Loss: 0.03512643687427044\n",
      "0.6445253641147398\n",
      "Epoch 171/200, Loss: 0.033606605231761934\n",
      "0.646822854447797\n",
      "Epoch 181/200, Loss: 0.03199508463342984\n",
      "0.6621765136576309\n",
      "Epoch 191/200, Loss: 0.030364100883404414\n",
      "0.6439883026075452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:20:23,965] Trial 22 finished with value: 0.6621765136576309 and parameters: {'hidden_dim_h': 45, 'dropout': 0.08202801457444284, 'batch_size': 668}. Best is trial 21 with value: 0.7425865426643594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.07053130276893314\n",
      "0.11070943500987541\n",
      "Epoch 11/200, Loss: 0.035895084079943206\n",
      "0.20310512968789976\n",
      "Epoch 21/200, Loss: 0.02987557169246046\n",
      "0.544843727930468\n",
      "Epoch 31/200, Loss: 0.022730922424479535\n",
      "0.6217282809096093\n",
      "Epoch 41/200, Loss: 0.01695201889072594\n",
      "0.6879382991490286\n",
      "Epoch 51/200, Loss: 0.0124596309308943\n",
      "0.6950851353746639\n",
      "Epoch 61/200, Loss: 0.009334644670353123\n",
      "0.6999066485669462\n",
      "Epoch 71/200, Loss: 0.007347512083422197\n",
      "0.6994645723866931\n",
      "Epoch 81/200, Loss: 0.005937118990052687\n",
      "0.7222524153676255\n",
      "Epoch 91/200, Loss: 0.005055019962846448\n",
      "0.7269509913013857\n",
      "Epoch 101/200, Loss: 0.0044873437206996115\n",
      "0.728542801381809\n",
      "Epoch 111/200, Loss: 0.003984758912242557\n",
      "0.7268559486690356\n",
      "Epoch 121/200, Loss: 0.003813016951378239\n",
      "0.72179866963663\n",
      "Epoch 131/200, Loss: 0.0035630106484811556\n",
      "0.7332288972311597\n",
      "Epoch 141/200, Loss: 0.0033992608261637783\n",
      "0.7324493819303429\n",
      "Epoch 151/200, Loss: 0.003204920549729937\n",
      "0.7313195226981026\n",
      "Epoch 161/200, Loss: 0.0029720211230022343\n",
      "0.7425963534660985\n",
      "Epoch 171/200, Loss: 0.0029823215568046037\n",
      "0.7379424307408472\n",
      "Epoch 181/200, Loss: 0.002747260175008131\n",
      "0.7390294480528552\n",
      "Epoch 191/200, Loss: 0.0026141960590489602\n",
      "0.7227468949180166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:23:23,558] Trial 23 finished with value: 0.7425963534660985 and parameters: {'hidden_dim_h': 35, 'dropout': 0.08799028532005918, 'batch_size': 539}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.7641636039081373\n",
      "0.004304349230736258\n",
      "Epoch 11/200, Loss: 0.38314280384465266\n",
      "0.0014718398180843947\n",
      "Epoch 21/200, Loss: 0.18380172393823924\n",
      "0.00019820489673480057\n",
      "Epoch 31/200, Loss: 0.08268223271558159\n",
      "0.2375815230918496\n",
      "Epoch 41/200, Loss: 0.039042425783056965\n",
      "0.5218587875145406\n",
      "Epoch 51/200, Loss: 0.025034038448020032\n",
      "0.5522245694021928\n",
      "Epoch 61/200, Loss: 0.020709943026304245\n",
      "0.5833746644497936\n",
      "Epoch 71/200, Loss: 0.0190009747288729\n",
      "0.5828594596222768\n",
      "Epoch 81/200, Loss: 0.017792413991532828\n",
      "0.6089767921267144\n",
      "Epoch 91/200, Loss: 0.016741702578177576\n",
      "0.6038611774706533\n",
      "Epoch 101/200, Loss: 0.015681360014959386\n",
      "0.6053314634940825\n",
      "Epoch 111/200, Loss: 0.014602924746118094\n",
      "0.6135069788966406\n",
      "Epoch 121/200, Loss: 0.013609857543518669\n",
      "0.6204818950929594\n",
      "Epoch 131/200, Loss: 0.01256547775119543\n",
      "0.6056921947732978\n",
      "Epoch 141/200, Loss: 0.011841884961253718\n",
      "0.6218391947582207\n",
      "Epoch 151/200, Loss: 0.011243138462305069\n",
      "0.632083442785107\n",
      "Epoch 161/200, Loss: 0.010544790004036929\n",
      "0.604817617965722\n",
      "Epoch 171/200, Loss: 0.010097775314199297\n",
      "0.6175636264735461\n",
      "Epoch 181/200, Loss: 0.00955526354281526\n",
      "0.6292613383751806\n",
      "Epoch 191/200, Loss: 0.009763025997304603\n",
      "0.6103621131015183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:26:23,640] Trial 24 finished with value: 0.632083442785107 and parameters: {'hidden_dim_h': 35, 'dropout': 0.14557325725571946, 'batch_size': 528}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.12573975506352214\n",
      "0.11961130932493585\n",
      "Epoch 11/200, Loss: 0.021986296877446698\n",
      "0.4995341107931106\n",
      "Epoch 21/200, Loss: 0.011361987352734658\n",
      "0.6216830741070537\n",
      "Epoch 31/200, Loss: 0.008703226859613163\n",
      "0.6365072418695872\n",
      "Epoch 41/200, Loss: 0.007088279930829275\n",
      "0.6428320497435732\n",
      "Epoch 51/200, Loss: 0.005891189740107554\n",
      "0.663407720101992\n",
      "Epoch 61/200, Loss: 0.005132906774922115\n",
      "0.6653029248466492\n",
      "Epoch 71/200, Loss: 0.0047022543858918475\n",
      "0.6784269976180192\n",
      "Epoch 81/200, Loss: 0.004483054715731159\n",
      "0.6866009714197608\n",
      "Epoch 91/200, Loss: 0.004281392201735843\n",
      "0.6735422800997232\n",
      "Epoch 101/200, Loss: 0.003988182541300974\n",
      "0.6694895502807611\n",
      "Epoch 111/200, Loss: 0.004016959693328273\n",
      "0.6701197727306163\n",
      "Epoch 121/200, Loss: 0.0037109968138904106\n",
      "0.6755621700721441\n",
      "Epoch 131/200, Loss: 0.003717999774735512\n",
      "0.6598132330288108\n",
      "Epoch 141/200, Loss: 0.0036545251581318132\n",
      "0.6758905736241071\n",
      "Epoch 151/200, Loss: 0.0035706844561301716\n",
      "0.67819018551323\n",
      "Epoch 161/200, Loss: 0.003756936188083051\n",
      "0.6854379689826055\n",
      "Epoch 171/200, Loss: 0.0037296988388023727\n",
      "0.6827454124585169\n",
      "Epoch 181/200, Loss: 0.0037878158093407385\n",
      "0.6724015309480653\n",
      "Epoch 191/200, Loss: 0.0037737130045481936\n",
      "0.699609467393633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:29:28,335] Trial 25 finished with value: 0.699609467393633 and parameters: {'hidden_dim_h': 33, 'dropout': 0.08392144024280992, 'batch_size': 247}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.10251053529126304\n",
      "0.09413843376028434\n",
      "Epoch 11/200, Loss: 0.03626822015004499\n",
      "0.23483021629542875\n",
      "Epoch 21/200, Loss: 0.013763151175919034\n",
      "0.5358495552393077\n",
      "Epoch 31/200, Loss: 0.010035119130320493\n",
      "0.6337911603558898\n",
      "Epoch 41/200, Loss: 0.008019156066612118\n",
      "0.6673920095916412\n",
      "Epoch 51/200, Loss: 0.007021713048397075\n",
      "0.6761744276356858\n",
      "Epoch 61/200, Loss: 0.006049338240353834\n",
      "0.6847621743398561\n",
      "Epoch 71/200, Loss: 0.005400396351303373\n",
      "0.7045335021145079\n",
      "Epoch 81/200, Loss: 0.004974392032073368\n",
      "0.6984186869466757\n",
      "Epoch 91/200, Loss: 0.0043846572017563245\n",
      "0.6987779652052897\n",
      "Epoch 101/200, Loss: 0.0041171696280971875\n",
      "0.7045617509946992\n",
      "Epoch 111/200, Loss: 0.003734699505869122\n",
      "0.7062785363383749\n",
      "Epoch 121/200, Loss: 0.003705577037873722\n",
      "0.698972151547051\n",
      "Epoch 131/200, Loss: 0.0035526391806169635\n",
      "0.7176453061790214\n",
      "Epoch 141/200, Loss: 0.003445661793063794\n",
      "0.7177273833664322\n",
      "Epoch 151/200, Loss: 0.003139668975823692\n",
      "0.7202175218221103\n",
      "Epoch 161/200, Loss: 0.0031734362322216234\n",
      "0.7155826730351293\n",
      "Epoch 171/200, Loss: 0.0029541709670974385\n",
      "0.7207673492666069\n",
      "Epoch 181/200, Loss: 0.0030106115210357877\n",
      "0.7227158346789644\n",
      "Epoch 191/200, Loss: 0.00295277385573302\n",
      "0.7209248884684765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:32:34,654] Trial 26 finished with value: 0.7227158346789644 and parameters: {'hidden_dim_h': 38, 'dropout': 0.28234819353294655, 'batch_size': 487}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.1187809738444119\n",
      "0.12292732355362876\n",
      "Epoch 11/200, Loss: 0.03504884463348767\n",
      "0.17386906457768828\n",
      "Epoch 21/200, Loss: 0.03276025537946602\n",
      "0.21347124462757647\n",
      "Epoch 31/200, Loss: 0.033173069267011274\n",
      "0.19114068996091596\n",
      "Epoch 41/200, Loss: 0.032772244522120894\n",
      "0.19872566767348393\n",
      "Epoch 51/200, Loss: 0.032632379224751054\n",
      "0.18762655538607323\n",
      "Epoch 61/200, Loss: 0.03209745622717026\n",
      "0.23158102965714938\n",
      "Epoch 71/200, Loss: 0.03319935407489538\n",
      "0.17845115738273712\n",
      "Epoch 81/200, Loss: 0.03190158711882626\n",
      "0.21311009265726472\n",
      "Epoch 91/200, Loss: 0.032924047398676236\n",
      "0.2089959116644155\n",
      "Epoch 101/200, Loss: 0.03177256923078037\n",
      "0.237764280788077\n",
      "Epoch 111/200, Loss: 0.03194096938865941\n",
      "0.2230592708515322\n",
      "Epoch 121/200, Loss: 0.03170956073828587\n",
      "0.25328950572104875\n",
      "Epoch 131/200, Loss: 0.031454675353881786\n",
      "0.25104428857648753\n",
      "Epoch 141/200, Loss: 0.031635167417911496\n",
      "0.26523043957558334\n",
      "Epoch 151/200, Loss: 0.029773190685706896\n",
      "0.3157584523790777\n",
      "Epoch 161/200, Loss: 0.029422268112439934\n",
      "0.27828626884462515\n",
      "Epoch 171/200, Loss: 0.028793897025468872\n",
      "0.3396775398058014\n",
      "Epoch 181/200, Loss: 0.028484987322150206\n",
      "0.34283047979342424\n",
      "Epoch 191/200, Loss: 0.028523095474555726\n",
      "0.35514995151001866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:35:32,044] Trial 27 finished with value: 0.35514995151001866 and parameters: {'hidden_dim_h': 28, 'dropout': 0.09830648880118494, 'batch_size': 122}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.5546202090653506\n",
      "0.12153106646430169\n",
      "Epoch 11/200, Loss: 0.10472990707917647\n",
      "0.364180656098778\n",
      "Epoch 21/200, Loss: 0.02314514336599545\n",
      "0.5487148564778591\n",
      "Epoch 31/200, Loss: 0.010414305552275795\n",
      "0.5969148060584757\n",
      "Epoch 41/200, Loss: 0.008935137411974596\n",
      "0.6100207873375526\n",
      "Epoch 51/200, Loss: 0.007415391166101803\n",
      "0.640709307730365\n",
      "Epoch 61/200, Loss: 0.006914588354640838\n",
      "0.6429994427232463\n",
      "Epoch 71/200, Loss: 0.006838329094038768\n",
      "0.6314908459119659\n",
      "Epoch 81/200, Loss: 0.0060242932769611025\n",
      "0.6531996809823882\n",
      "Epoch 91/200, Loss: 0.005773244228101138\n",
      "0.6462805417654225\n",
      "Epoch 101/200, Loss: 0.005310915410518646\n",
      "0.6402921011890105\n",
      "Epoch 111/200, Loss: 0.005010595989667557\n",
      "0.6524088445211892\n",
      "Epoch 121/200, Loss: 0.0045750675525403385\n",
      "0.6686194038257998\n",
      "Epoch 131/200, Loss: 0.004285564173408078\n",
      "0.6741070452283249\n",
      "Epoch 141/200, Loss: 0.00378697234643341\n",
      "0.671407963600338\n",
      "Epoch 151/200, Loss: 0.0037331912264397197\n",
      "0.6846353734214877\n",
      "Epoch 161/200, Loss: 0.003434949953137248\n",
      "0.6732706652322946\n",
      "Epoch 171/200, Loss: 0.003281279519962316\n",
      "0.6852859282025803\n",
      "Epoch 181/200, Loss: 0.003222705549419378\n",
      "0.6905284459543343\n",
      "Epoch 191/200, Loss: 0.0035985082663087683\n",
      "0.6957361471899398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:39:01,784] Trial 28 finished with value: 0.6957361471899398 and parameters: {'hidden_dim_h': 46, 'dropout': 0.14724383440863734, 'batch_size': 309}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.06475427726076709\n",
      "0.12002356990956917\n",
      "Epoch 11/200, Loss: 0.03271367111139827\n",
      "0.23726941336232407\n",
      "Epoch 21/200, Loss: 0.021098303608596325\n",
      "0.5249995245094411\n",
      "Epoch 31/200, Loss: 0.01471866351655788\n",
      "0.5268218297454407\n",
      "Epoch 41/200, Loss: 0.011460197623819113\n",
      "0.5966908350587946\n",
      "Epoch 51/200, Loss: 0.009833855192280479\n",
      "0.6217017774420349\n",
      "Epoch 61/200, Loss: 0.008912464396821128\n",
      "0.6317463966170136\n",
      "Epoch 71/200, Loss: 0.007763199637540513\n",
      "0.6478274315386474\n",
      "Epoch 81/200, Loss: 0.007283812543998162\n",
      "0.6406573699097773\n",
      "Epoch 91/200, Loss: 0.006267696800124314\n",
      "0.6603599493864976\n",
      "Epoch 101/200, Loss: 0.006117754253662295\n",
      "0.6661391024520865\n",
      "Epoch 111/200, Loss: 0.005472071132519179\n",
      "0.6718564725346995\n",
      "Epoch 121/200, Loss: 0.004879892156976793\n",
      "0.6769379248559203\n",
      "Epoch 131/200, Loss: 0.005394131384996904\n",
      "0.6788111225891207\n",
      "Epoch 141/200, Loss: 0.0045741838014995055\n",
      "0.6721470222049879\n",
      "Epoch 151/200, Loss: 0.004407336844855713\n",
      "0.6874205689352573\n",
      "Epoch 161/200, Loss: 0.0044014850734836524\n",
      "0.6926574007723878\n",
      "Epoch 171/200, Loss: 0.004234955270981623\n",
      "0.6936470291754167\n",
      "Epoch 181/200, Loss: 0.004105769408245881\n",
      "0.6880811559014733\n",
      "Epoch 191/200, Loss: 0.004005925587585403\n",
      "0.6990743061837769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:41:26,675] Trial 29 finished with value: 0.6990743061837769 and parameters: {'hidden_dim_h': 22, 'dropout': 0.10883031713643214, 'batch_size': 566}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.18688454665243626\n",
      "0.032332193038281526\n",
      "Epoch 11/200, Loss: 0.0525797032751143\n",
      "0.16923244849288022\n",
      "Epoch 21/200, Loss: 0.03498633570658664\n",
      "0.41815554803021987\n",
      "Epoch 31/200, Loss: 0.028983519955848653\n",
      "0.5950780741514697\n",
      "Epoch 41/200, Loss: 0.02437960938550532\n",
      "0.6357810991329322\n",
      "Epoch 51/200, Loss: 0.019995062068725627\n",
      "0.6499090889085142\n",
      "Epoch 61/200, Loss: 0.015962783945724368\n",
      "0.6706798646928998\n",
      "Epoch 71/200, Loss: 0.012603065658671161\n",
      "0.6772527474202383\n",
      "Epoch 81/200, Loss: 0.009884072855735818\n",
      "0.700621202173886\n",
      "Epoch 91/200, Loss: 0.007913747006872049\n",
      "0.6922949810025004\n",
      "Epoch 101/200, Loss: 0.006358549328676115\n",
      "0.7004597343950886\n",
      "Epoch 111/200, Loss: 0.005224734515650198\n",
      "0.7016364927909756\n",
      "Epoch 121/200, Loss: 0.0044945108917697025\n",
      "0.6895748043179475\n",
      "Epoch 131/200, Loss: 0.004080069629708305\n",
      "0.7013479067601316\n",
      "Epoch 141/200, Loss: 0.0038036361899382123\n",
      "0.6974081619839102\n",
      "Epoch 151/200, Loss: 0.003557068014439816\n",
      "0.6960864491582279\n",
      "Epoch 161/200, Loss: 0.00345227978444503\n",
      "0.6864020282125793\n",
      "Epoch 171/200, Loss: 0.0032543991207300373\n",
      "0.6918320769125552\n",
      "Epoch 181/200, Loss: 0.003355301421834156\n",
      "0.6935205624870148\n",
      "Epoch 191/200, Loss: 0.0032498986644592756\n",
      "0.693349265193832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:44:25,619] Trial 30 finished with value: 0.7016364927909756 and parameters: {'hidden_dim_h': 34, 'dropout': 0.22535816709665013, 'batch_size': 422}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.07103848514648584\n",
      "0.1103939639947518\n",
      "Epoch 11/200, Loss: 0.042631833599163935\n",
      "0.13020963274735195\n",
      "Epoch 21/200, Loss: 0.0257291947133266\n",
      "0.390906561423897\n",
      "Epoch 31/200, Loss: 0.01231481793981332\n",
      "0.6193363614773892\n",
      "Epoch 41/200, Loss: 0.009256686513813643\n",
      "0.6652629193219118\n",
      "Epoch 51/200, Loss: 0.007821529136540798\n",
      "0.6931802998704178\n",
      "Epoch 61/200, Loss: 0.006797402631491423\n",
      "0.7137038697893038\n",
      "Epoch 71/200, Loss: 0.0061065823269578125\n",
      "0.7162379167278885\n",
      "Epoch 81/200, Loss: 0.005537627049936698\n",
      "0.7071268403075992\n",
      "Epoch 91/200, Loss: 0.005021723506685633\n",
      "0.7236505868787926\n",
      "Epoch 101/200, Loss: 0.004718920789085901\n",
      "0.7170382184269543\n",
      "Epoch 111/200, Loss: 0.0043802815847671945\n",
      "0.7215036454920655\n",
      "Epoch 121/200, Loss: 0.004276387286014282\n",
      "0.7338539303358496\n",
      "Epoch 131/200, Loss: 0.0038017749141615173\n",
      "0.7338657145925036\n",
      "Epoch 141/200, Loss: 0.003682505052823287\n",
      "0.7345775438952495\n",
      "Epoch 151/200, Loss: 0.0036014161036851313\n",
      "0.7349631466972019\n",
      "Epoch 161/200, Loss: 0.0033595268077288684\n",
      "0.7422729816001994\n",
      "Epoch 171/200, Loss: 0.0033393860078201843\n",
      "0.7331693342565194\n",
      "Epoch 181/200, Loss: 0.003224882995709777\n",
      "0.7358372599925203\n",
      "Epoch 191/200, Loss: 0.003058666694694414\n",
      "0.7301566877624412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:47:33,590] Trial 31 finished with value: 0.7422729816001994 and parameters: {'hidden_dim_h': 40, 'dropout': 0.06861649559773875, 'batch_size': 776}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.5028234400919506\n",
      "0.0933270711020186\n",
      "Epoch 11/200, Loss: 0.25917368275778635\n",
      "0.10422043595004339\n",
      "Epoch 21/200, Loss: 0.11606004621301379\n",
      "0.4118460594577439\n",
      "Epoch 31/200, Loss: 0.0517762436398438\n",
      "0.5846714916380454\n",
      "Epoch 41/200, Loss: 0.026849966097090925\n",
      "0.6403956751606978\n",
      "Epoch 51/200, Loss: 0.01763015187212399\n",
      "0.6641330780565626\n",
      "Epoch 61/200, Loss: 0.014732103129582745\n",
      "0.6582567912132716\n",
      "Epoch 71/200, Loss: 0.0132839884608984\n",
      "0.6820581942392883\n",
      "Epoch 81/200, Loss: 0.01241009436281664\n",
      "0.6883373324677028\n",
      "Epoch 91/200, Loss: 0.011812977625855378\n",
      "0.7003694853908725\n",
      "Epoch 101/200, Loss: 0.011148997782064336\n",
      "0.6978688735200089\n",
      "Epoch 111/200, Loss: 0.010501319808619363\n",
      "0.699327199736136\n",
      "Epoch 121/200, Loss: 0.009815243604992117\n",
      "0.6915961977612806\n",
      "Epoch 131/200, Loss: 0.009186650393530726\n",
      "0.7000535854638087\n",
      "Epoch 141/200, Loss: 0.008578973722511105\n",
      "0.6970857186704726\n",
      "Epoch 151/200, Loss: 0.008026686430509602\n",
      "0.7056807426372073\n",
      "Epoch 161/200, Loss: 0.00749979680404067\n",
      "0.7164430584132722\n",
      "Epoch 171/200, Loss: 0.006968855325664792\n",
      "0.7163139769438425\n",
      "Epoch 181/200, Loss: 0.006440682303426521\n",
      "0.7097510744759707\n",
      "Epoch 191/200, Loss: 0.006006376584991813\n",
      "0.7109498406614119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:50:40,258] Trial 32 finished with value: 0.7164430584132722 and parameters: {'hidden_dim_h': 39, 'dropout': 0.07334474186446856, 'batch_size': 721}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.11272254958748817\n",
      "0.033235761685888966\n",
      "Epoch 11/200, Loss: 0.03689334293206533\n",
      "0.1167409886979121\n",
      "Epoch 21/200, Loss: 0.021673059711853664\n",
      "0.41196308870095477\n",
      "Epoch 31/200, Loss: 0.011539590544998646\n",
      "0.5732091313675757\n",
      "Epoch 41/200, Loss: 0.007750010738770167\n",
      "0.6205265695809267\n",
      "Epoch 51/200, Loss: 0.006705486370871465\n",
      "0.6456714012852608\n",
      "Epoch 61/200, Loss: 0.0061302838536600275\n",
      "0.6684565172307578\n",
      "Epoch 71/200, Loss: 0.0056478938010210795\n",
      "0.6609762490121031\n",
      "Epoch 81/200, Loss: 0.005027226832074423\n",
      "0.6851967992352344\n",
      "Epoch 91/200, Loss: 0.0050278689013794065\n",
      "0.6831091866562293\n",
      "Epoch 101/200, Loss: 0.00449578136128063\n",
      "0.6959211893591255\n",
      "Epoch 111/200, Loss: 0.004380744299851358\n",
      "0.6931764193463023\n",
      "Epoch 121/200, Loss: 0.004433953552506864\n",
      "0.6851972304204456\n",
      "Epoch 131/200, Loss: 0.004216418310534209\n",
      "0.6996718783371173\n",
      "Epoch 141/200, Loss: 0.003990469849668443\n",
      "0.7015485730816247\n",
      "Epoch 151/200, Loss: 0.004101882630493492\n",
      "0.715020788133015\n",
      "Epoch 161/200, Loss: 0.0036065519670955837\n",
      "0.7094993607861744\n",
      "Epoch 171/200, Loss: 0.003635087031094978\n",
      "0.7145850698366024\n",
      "Epoch 181/200, Loss: 0.003498260397464037\n",
      "0.7134387470242012\n",
      "Epoch 191/200, Loss: 0.003342200187034905\n",
      "0.7150294656936156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:53:56,600] Trial 33 finished with value: 0.7150294656936156 and parameters: {'hidden_dim_h': 42, 'dropout': 0.12896434920329897, 'batch_size': 881}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.22789661586284637\n",
      "0.11327387305573026\n",
      "Epoch 11/200, Loss: 0.07919285314924576\n",
      "0.026603656539101534\n",
      "Epoch 21/200, Loss: 0.023195275708156472\n",
      "0.5239846377279347\n",
      "Epoch 31/200, Loss: 0.011092573952148943\n",
      "0.6520806835390512\n",
      "Epoch 41/200, Loss: 0.008513817180167227\n",
      "0.6772926568759928\n",
      "Epoch 51/200, Loss: 0.0071368082700406805\n",
      "0.6846733605807944\n",
      "Epoch 61/200, Loss: 0.006385193973341409\n",
      "0.6974272361676425\n",
      "Epoch 71/200, Loss: 0.005967310629785061\n",
      "0.6909356078047559\n",
      "Epoch 81/200, Loss: 0.0056061871240244195\n",
      "0.701437927365458\n",
      "Epoch 91/200, Loss: 0.005127093357527081\n",
      "0.6930706382574099\n",
      "Epoch 101/200, Loss: 0.004803373820751029\n",
      "0.6977300491908743\n",
      "Epoch 111/200, Loss: 0.004596888375304201\n",
      "0.6995719400629828\n",
      "Epoch 121/200, Loss: 0.0043327054008841515\n",
      "0.7161853214714107\n",
      "Epoch 131/200, Loss: 0.004599386415279964\n",
      "0.7049016794614709\n",
      "Epoch 141/200, Loss: 0.004028902060407049\n",
      "0.7142027659470052\n",
      "Epoch 151/200, Loss: 0.0037496267708347123\n",
      "0.7081523147250792\n",
      "Epoch 161/200, Loss: 0.0036050395300502285\n",
      "0.7187769595107989\n",
      "Epoch 171/200, Loss: 0.003384954871281105\n",
      "0.7126107104402909\n",
      "Epoch 181/200, Loss: 0.003337519325535087\n",
      "0.7135425039583455\n",
      "Epoch 191/200, Loss: 0.0031907618771690655\n",
      "0.7028711253461658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:57:18,101] Trial 34 finished with value: 0.7187769595107989 and parameters: {'hidden_dim_h': 44, 'dropout': 0.06639431375989213, 'batch_size': 621}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.22204357534646987\n",
      "0.06610099053050411\n",
      "Epoch 11/200, Loss: 0.12461828887462616\n",
      "0.06207480527931638\n",
      "Epoch 21/200, Loss: 0.07170515656471252\n",
      "0.016406630234334488\n",
      "Epoch 31/200, Loss: 0.03529368303716183\n",
      "0.36213883862697194\n",
      "Epoch 41/200, Loss: 0.022724057734012603\n",
      "0.503131569027976\n",
      "Epoch 51/200, Loss: 0.014307926874607801\n",
      "0.5524913900606602\n",
      "Epoch 61/200, Loss: 0.010961043927818537\n",
      "0.6274238912407298\n",
      "Epoch 71/200, Loss: 0.00885012592189014\n",
      "0.6542212137704355\n",
      "Epoch 81/200, Loss: 0.007889450155198574\n",
      "0.6623165358953569\n",
      "Epoch 91/200, Loss: 0.007086351606994867\n",
      "0.6862421196137358\n",
      "Epoch 101/200, Loss: 0.006745656998828053\n",
      "0.675422468110519\n",
      "Epoch 111/200, Loss: 0.006468149740248919\n",
      "0.6846667806750001\n",
      "Epoch 121/200, Loss: 0.006108855083584786\n",
      "0.6851519644954447\n",
      "Epoch 131/200, Loss: 0.005643046833574772\n",
      "0.6885728357563483\n",
      "Epoch 141/200, Loss: 0.005483331065624953\n",
      "0.6921747939253721\n",
      "Epoch 151/200, Loss: 0.00516346690710634\n",
      "0.6816776396429604\n",
      "Epoch 161/200, Loss: 0.005072601512074471\n",
      "0.6907896717674671\n",
      "Epoch 171/200, Loss: 0.004757745005190372\n",
      "0.6907963227518652\n",
      "Epoch 181/200, Loss: 0.005038660601712763\n",
      "0.6843598366813546\n",
      "Epoch 191/200, Loss: 0.0045975859509781005\n",
      "0.6874135714302876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 12:59:58,640] Trial 35 finished with value: 0.6921747939253721 and parameters: {'hidden_dim_h': 31, 'dropout': 0.08979272390357249, 'batch_size': 1066}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.21534613839217595\n",
      "0.03274795805895232\n",
      "Epoch 11/200, Loss: 0.08817105101687568\n",
      "0.1780230791798831\n",
      "Epoch 21/200, Loss: 0.0388389171234199\n",
      "0.47150660103870173\n",
      "Epoch 31/200, Loss: 0.027330797032586167\n",
      "0.6212617238564678\n",
      "Epoch 41/200, Loss: 0.02420125582388469\n",
      "0.6589201994049922\n",
      "Epoch 51/200, Loss: 0.022192454231636866\n",
      "0.670468056260486\n",
      "Epoch 61/200, Loss: 0.020217612651841983\n",
      "0.6810665694957652\n",
      "Epoch 71/200, Loss: 0.018329510199172155\n",
      "0.6863385920300648\n",
      "Epoch 81/200, Loss: 0.01639151799359492\n",
      "0.6900199967904113\n",
      "Epoch 91/200, Loss: 0.014707265887409449\n",
      "0.6926016089805657\n",
      "Epoch 101/200, Loss: 0.013055221177637577\n",
      "0.6834754027063031\n",
      "Epoch 111/200, Loss: 0.011563691377107586\n",
      "0.6908347769587325\n",
      "Epoch 121/200, Loss: 0.010179813951253891\n",
      "0.7042170742760047\n",
      "Epoch 131/200, Loss: 0.00883826260854091\n",
      "0.7030344830376539\n",
      "Epoch 141/200, Loss: 0.007749846570992044\n",
      "0.70570041653865\n",
      "Epoch 151/200, Loss: 0.0069885944415416035\n",
      "0.7115982040277669\n",
      "Epoch 161/200, Loss: 0.006242218926282865\n",
      "0.7087360681301595\n",
      "Epoch 171/200, Loss: 0.005549520387181214\n",
      "0.7155348394856824\n",
      "Epoch 181/200, Loss: 0.0050648309157363\n",
      "0.7117619184761991\n",
      "Epoch 191/200, Loss: 0.004615232531380441\n",
      "0.7062397307642089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:03:27,450] Trial 36 finished with value: 0.7155348394856824 and parameters: {'hidden_dim_h': 47, 'dropout': 0.11733924135680505, 'batch_size': 746}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.21155889828999838\n",
      "9.105230284153858e-07\n",
      "Epoch 11/200, Loss: 0.0975959338247776\n",
      "0.17418608179805067\n",
      "Epoch 21/200, Loss: 0.05536216963082552\n",
      "0.4182394084565368\n",
      "Epoch 31/200, Loss: 0.04229089586685101\n",
      "0.5127174041987408\n",
      "Epoch 41/200, Loss: 0.03820830086867014\n",
      "0.5742023728434531\n",
      "Epoch 51/200, Loss: 0.0356157161295414\n",
      "0.6045193006418187\n",
      "Epoch 61/200, Loss: 0.03298809860522548\n",
      "0.6060032219654533\n",
      "Epoch 71/200, Loss: 0.030384010014434654\n",
      "0.629493346906659\n",
      "Epoch 81/200, Loss: 0.027554319084932406\n",
      "0.6279580926424563\n",
      "Epoch 91/200, Loss: 0.0249359627875189\n",
      "0.6424567082138954\n",
      "Epoch 101/200, Loss: 0.022320406511425972\n",
      "0.6382087924019157\n",
      "Epoch 111/200, Loss: 0.019951478112488985\n",
      "0.6388055798616911\n",
      "Epoch 121/200, Loss: 0.017674841452389956\n",
      "0.6493100275457845\n",
      "Epoch 131/200, Loss: 0.015567692539965114\n",
      "0.6450321243628042\n",
      "Epoch 141/200, Loss: 0.013696229240546623\n",
      "0.6321432320159824\n",
      "Epoch 151/200, Loss: 0.012056925101205707\n",
      "0.6535929874357141\n",
      "Epoch 161/200, Loss: 0.010489692523454627\n",
      "0.657946169859372\n",
      "Epoch 171/200, Loss: 0.009201025745520989\n",
      "0.6641768600529989\n",
      "Epoch 181/200, Loss: 0.008133301162160933\n",
      "0.6613932058126021\n",
      "Epoch 191/200, Loss: 0.00716628316634645\n",
      "0.67299881841853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:06:33,422] Trial 37 finished with value: 0.67299881841853 and parameters: {'hidden_dim_h': 39, 'dropout': 0.06368221859972958, 'batch_size': 850}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.5577047479913589\n",
      "0.11906584402672789\n",
      "Epoch 11/200, Loss: 0.06338742240629297\n",
      "0.3900325046956733\n",
      "Epoch 21/200, Loss: 0.014686219889591349\n",
      "0.6296332426806404\n",
      "Epoch 31/200, Loss: 0.011646631728619971\n",
      "0.6682085676326495\n",
      "Epoch 41/200, Loss: 0.009772744148652604\n",
      "0.6897768013947851\n",
      "Epoch 51/200, Loss: 0.008227533214983153\n",
      "0.703799260182805\n",
      "Epoch 61/200, Loss: 0.006925052814581927\n",
      "0.6993920555407281\n",
      "Epoch 71/200, Loss: 0.005874677843592586\n",
      "0.699158735937163\n",
      "Epoch 81/200, Loss: 0.005158606881989126\n",
      "0.704874883237811\n",
      "Epoch 91/200, Loss: 0.004676876772948085\n",
      "0.7011897094345865\n",
      "Epoch 101/200, Loss: 0.0045084195568206465\n",
      "0.7054830717180494\n",
      "Epoch 111/200, Loss: 0.004730492513230506\n",
      "0.7144064676944518\n",
      "Epoch 121/200, Loss: 0.0047094467086123025\n",
      "0.7126944000975627\n",
      "Epoch 131/200, Loss: 0.00462574610347919\n",
      "0.7044224926045438\n",
      "Epoch 141/200, Loss: 0.004969116761051911\n",
      "0.7160434558304523\n",
      "Epoch 151/200, Loss: 0.005172353901682382\n",
      "0.7106036743637054\n",
      "Epoch 161/200, Loss: 0.005345417513571521\n",
      "0.6983615924448751\n",
      "Epoch 171/200, Loss: 0.007059273101944238\n",
      "0.6533347611258624\n",
      "Epoch 181/200, Loss: 0.009395282339066901\n",
      "0.6583001738313231\n",
      "Epoch 191/200, Loss: 0.010193802168632441\n",
      "0.6657797017034087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:09:43,482] Trial 38 finished with value: 0.7160434558304523 and parameters: {'hidden_dim_h': 37, 'dropout': 0.127951156614985, 'batch_size': 214}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.18904881064708418\n",
      "0.06862037809885356\n",
      "Epoch 11/200, Loss: 0.042943972234542556\n",
      "0.19566287844924293\n",
      "Epoch 21/200, Loss: 0.015604285666575799\n",
      "0.5596127951223523\n",
      "Epoch 31/200, Loss: 0.012131518541047206\n",
      "0.6212084819386392\n",
      "Epoch 41/200, Loss: 0.010134280748808613\n",
      "0.6465707791679223\n",
      "Epoch 51/200, Loss: 0.008531102301696172\n",
      "0.6407698522853936\n",
      "Epoch 61/200, Loss: 0.007236578931602148\n",
      "0.6600204885489216\n",
      "Epoch 71/200, Loss: 0.0062084935892086765\n",
      "0.6753245710295561\n",
      "Epoch 81/200, Loss: 0.005413225243011346\n",
      "0.6769535403564125\n",
      "Epoch 91/200, Loss: 0.0047178845583962705\n",
      "0.680740210506557\n",
      "Epoch 101/200, Loss: 0.004340694214289005\n",
      "0.6753277484465013\n",
      "Epoch 111/200, Loss: 0.004069862573837431\n",
      "0.6875229724526103\n",
      "Epoch 121/200, Loss: 0.0036817187120994697\n",
      "0.6825697941825128\n",
      "Epoch 131/200, Loss: 0.0034440841901904116\n",
      "0.6863687092407146\n",
      "Epoch 141/200, Loss: 0.0032099045839948724\n",
      "0.6912489133386044\n",
      "Epoch 151/200, Loss: 0.0032092377883740342\n",
      "0.6863959479652716\n",
      "Epoch 161/200, Loss: 0.0029980618990241336\n",
      "0.6926342589009885\n",
      "Epoch 171/200, Loss: 0.0030041485129354093\n",
      "0.6989347305503724\n",
      "Epoch 181/200, Loss: 0.0030402441804583827\n",
      "0.6973542443529623\n",
      "Epoch 191/200, Loss: 0.002876454068777653\n",
      "0.7003014882485104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:12:52,894] Trial 39 finished with value: 0.7003014882485104 and parameters: {'hidden_dim_h': 40, 'dropout': 0.17551016538675018, 'batch_size': 390}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.759954585478856\n",
      "0.007311702334422837\n",
      "Epoch 11/200, Loss: 0.44717559906152576\n",
      "0.10541265504174104\n",
      "Epoch 21/200, Loss: 0.270935241992657\n",
      "0.22921464533521257\n",
      "Epoch 31/200, Loss: 0.15428471221373632\n",
      "0.4481133641123204\n",
      "Epoch 41/200, Loss: 0.09188717202498363\n",
      "0.46275155764769194\n",
      "Epoch 51/200, Loss: 0.06000378240759556\n",
      "0.5919009316445174\n",
      "Epoch 61/200, Loss: 0.04492248881321687\n",
      "0.6190514503950432\n",
      "Epoch 71/200, Loss: 0.037989405198739126\n",
      "0.6368777660616404\n",
      "Epoch 81/200, Loss: 0.03458675713493274\n",
      "0.638542861533865\n",
      "Epoch 91/200, Loss: 0.03260168590797828\n",
      "0.6518943222518511\n",
      "Epoch 101/200, Loss: 0.03114969999744342\n",
      "0.6551824400403635\n",
      "Epoch 111/200, Loss: 0.029231503319281798\n",
      "0.651674953050807\n",
      "Epoch 121/200, Loss: 0.02791039874920478\n",
      "0.6678673113504547\n",
      "Epoch 131/200, Loss: 0.02631747221144346\n",
      "0.6642512036823224\n",
      "Epoch 141/200, Loss: 0.024770464891424544\n",
      "0.6769546441673993\n",
      "Epoch 151/200, Loss: 0.02304538253408212\n",
      "0.6705740643576974\n",
      "Epoch 161/200, Loss: 0.021446648268745497\n",
      "0.6902070649313815\n",
      "Epoch 171/200, Loss: 0.01974212020062483\n",
      "0.6891814068329183\n",
      "Epoch 181/200, Loss: 0.01841284606892329\n",
      "0.69703618206086\n",
      "Epoch 191/200, Loss: 0.016722781870227594\n",
      "0.6971759610901215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:16:21,318] Trial 40 finished with value: 0.6971759610901215 and parameters: {'hidden_dim_h': 48, 'dropout': 0.20270463865926333, 'batch_size': 809}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.931057463089625\n",
      "0.04863613731165292\n",
      "Epoch 11/200, Loss: 0.6324102828900019\n",
      "0.00353748087830774\n",
      "Epoch 21/200, Loss: 0.4001936490337054\n",
      "0.30235836939034016\n",
      "Epoch 31/200, Loss: 0.24145150308807692\n",
      "0.46853759988219745\n",
      "Epoch 41/200, Loss: 0.14294441044330597\n",
      "0.5757808668671444\n",
      "Epoch 51/200, Loss: 0.08210139411191146\n",
      "0.6377782985281314\n",
      "Epoch 61/200, Loss: 0.04471619054675102\n",
      "0.6348816954277989\n",
      "Epoch 71/200, Loss: 0.024897140140334766\n",
      "0.6801014814667729\n",
      "Epoch 81/200, Loss: 0.014509430155158043\n",
      "0.6705559834317352\n",
      "Epoch 91/200, Loss: 0.009329373831860721\n",
      "0.6659585337422865\n",
      "Epoch 101/200, Loss: 0.0069510713607693715\n",
      "0.6738679854996834\n",
      "Epoch 111/200, Loss: 0.006157477929567297\n",
      "0.6829103254899622\n",
      "Epoch 121/200, Loss: 0.005499685105557243\n",
      "0.6875003927212353\n",
      "Epoch 131/200, Loss: 0.00507213994084547\n",
      "0.6847532041562303\n",
      "Epoch 141/200, Loss: 0.005078321478019158\n",
      "0.6972134998066708\n",
      "Epoch 151/200, Loss: 0.004921461067472895\n",
      "0.6931028628245284\n",
      "Epoch 161/200, Loss: 0.004632186086382717\n",
      "0.6678076547385153\n",
      "Epoch 171/200, Loss: 0.00428469250133882\n",
      "0.6768094421268649\n",
      "Epoch 181/200, Loss: 0.004530193381166707\n",
      "0.6713357472731989\n",
      "Epoch 191/200, Loss: 0.004285079989737521\n",
      "0.6933459841586201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:19:38,279] Trial 41 finished with value: 0.6972134998066708 and parameters: {'hidden_dim_h': 41, 'dropout': 0.09306564358786806, 'batch_size': 896}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.6893022911889213\n",
      "0.024705675369757197\n",
      "Epoch 11/200, Loss: 0.4044387361833027\n",
      "0.05846550628712175\n",
      "Epoch 21/200, Loss: 0.23233806980507715\n",
      "0.35467978116166793\n",
      "Epoch 31/200, Loss: 0.1326415240764618\n",
      "0.12287504791719113\n",
      "Epoch 41/200, Loss: 0.06826391496828624\n",
      "0.45330693982555215\n",
      "Epoch 51/200, Loss: 0.03896699526480266\n",
      "0.616640485477641\n",
      "Epoch 61/200, Loss: 0.026179107704332898\n",
      "0.6123625794612267\n",
      "Epoch 71/200, Loss: 0.02110205284718956\n",
      "0.6497337551165191\n",
      "Epoch 81/200, Loss: 0.019233138965708867\n",
      "0.657422165445812\n",
      "Epoch 91/200, Loss: 0.01783031305032117\n",
      "0.6618183260254227\n",
      "Epoch 101/200, Loss: 0.017108304958258356\n",
      "0.6739124667104576\n",
      "Epoch 111/200, Loss: 0.015956762778971876\n",
      "0.6720310105390541\n",
      "Epoch 121/200, Loss: 0.015084244177809783\n",
      "0.6725104436279337\n",
      "Epoch 131/200, Loss: 0.013823552722377437\n",
      "0.6740974407193426\n",
      "Epoch 141/200, Loss: 0.012884484537478005\n",
      "0.6747431336048267\n",
      "Epoch 151/200, Loss: 0.01211686578712293\n",
      "0.6715056235529202\n",
      "Epoch 161/200, Loss: 0.011156190186738968\n",
      "0.6830210994109625\n",
      "Epoch 171/200, Loss: 0.010316444161747183\n",
      "0.6808587310111462\n",
      "Epoch 181/200, Loss: 0.009585386541272913\n",
      "0.6870622258974447\n",
      "Epoch 191/200, Loss: 0.009072412271052599\n",
      "0.6827663330481804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:22:58,765] Trial 42 finished with value: 0.6870622258974447 and parameters: {'hidden_dim_h': 44, 'dropout': 0.06460726346336469, 'batch_size': 756}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 1.9859091135171743\n",
      "0.018584638543141335\n",
      "Epoch 11/200, Loss: 1.4855702015069814\n",
      "0.0063354671605972065\n",
      "Epoch 21/200, Loss: 1.0856437683105469\n",
      "0.16236668405072086\n",
      "Epoch 31/200, Loss: 0.7917652772023127\n",
      "0.2961573194860687\n",
      "Epoch 41/200, Loss: 0.5687350722459646\n",
      "0.011634271145181159\n",
      "Epoch 51/200, Loss: 0.3832746331508343\n",
      "0.32542497262547754\n",
      "Epoch 61/200, Loss: 0.2498814486540281\n",
      "0.4682520190118751\n",
      "Epoch 71/200, Loss: 0.15874795959546015\n",
      "0.5784149981392668\n",
      "Epoch 81/200, Loss: 0.09874292176503402\n",
      "0.5926231382138282\n",
      "Epoch 91/200, Loss: 0.06065105933409471\n",
      "0.5803192671849933\n",
      "Epoch 101/200, Loss: 0.03768077836586879\n",
      "0.6105379227916251\n",
      "Epoch 111/200, Loss: 0.024127275181504395\n",
      "0.6407184368168312\n",
      "Epoch 121/200, Loss: 0.01652188548961511\n",
      "0.6447154379210562\n",
      "Epoch 131/200, Loss: 0.01248984096141962\n",
      "0.635091536707432\n",
      "Epoch 141/200, Loss: 0.010322212169949826\n",
      "0.6609422732292121\n",
      "Epoch 151/200, Loss: 0.009332594318458667\n",
      "0.6568890917488204\n",
      "Epoch 161/200, Loss: 0.008669212102316894\n",
      "0.6631278858777591\n",
      "Epoch 171/200, Loss: 0.008297231155805863\n",
      "0.6543516139421808\n",
      "Epoch 181/200, Loss: 0.007874272907009492\n",
      "0.664974895940917\n",
      "Epoch 191/200, Loss: 0.007694979484837789\n",
      "0.6615238787130128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:25:57,860] Trial 43 finished with value: 0.664974895940917 and parameters: {'hidden_dim_h': 35, 'dropout': 0.11032893800323691, 'batch_size': 781}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.07944270620743434\n",
      "0.09556498859253014\n",
      "Epoch 11/200, Loss: 0.03956907540559769\n",
      "0.12043325408913126\n",
      "Epoch 21/200, Loss: 0.03536831463376681\n",
      "0.1696386955762212\n",
      "Epoch 31/200, Loss: 0.0319670661042134\n",
      "0.3537338212494225\n",
      "Epoch 41/200, Loss: 0.028375195090969405\n",
      "0.3949187456008586\n",
      "Epoch 51/200, Loss: 0.02565441479285558\n",
      "0.4302105686200031\n",
      "Epoch 61/200, Loss: 0.023914787049094836\n",
      "0.44476000642473634\n",
      "Epoch 71/200, Loss: 0.023269268746177355\n",
      "0.43248793136296293\n",
      "Epoch 81/200, Loss: 0.021686872094869615\n",
      "0.41402491040961215\n",
      "Epoch 91/200, Loss: 0.022821776444713275\n",
      "0.3810042362953314\n",
      "Epoch 101/200, Loss: 0.021998274077971777\n",
      "0.40566756392477593\n",
      "Epoch 111/200, Loss: 0.02522720495859782\n",
      "0.35651734378423083\n",
      "Epoch 121/200, Loss: 0.021929689620931943\n",
      "0.40811576525193466\n",
      "Epoch 131/200, Loss: 0.02176237354675929\n",
      "0.3759790113768958\n",
      "Epoch 141/200, Loss: 0.019999194766084354\n",
      "0.4235224784116807\n",
      "Epoch 151/200, Loss: 0.02005317956209183\n",
      "0.3842149078199096\n",
      "Epoch 161/200, Loss: 0.023064460853735605\n",
      "0.3677618813365913\n",
      "Epoch 171/200, Loss: 0.02406043584148089\n",
      "0.32039749724890076\n",
      "Epoch 181/200, Loss: 0.027158035337924956\n",
      "0.3018140916669236\n",
      "Epoch 191/200, Loss: 0.02568117467065652\n",
      "0.350412627352114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:29:04,887] Trial 44 finished with value: 0.44476000642473634 and parameters: {'hidden_dim_h': 40, 'dropout': 0.07333147737918332, 'batch_size': 682}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 1.0432220829857721\n",
      "0.03449452548833238\n",
      "Epoch 11/200, Loss: 0.5974090099334717\n",
      "0.12401808148275346\n",
      "Epoch 21/200, Loss: 0.3132132639487584\n",
      "0.2235359352107697\n",
      "Epoch 31/200, Loss: 0.14969980799489552\n",
      "0.39199410542503427\n",
      "Epoch 41/200, Loss: 0.06736104252437751\n",
      "0.5708835779584625\n",
      "Epoch 51/200, Loss: 0.03083626553416252\n",
      "0.6053929169630109\n",
      "Epoch 61/200, Loss: 0.016237789816740487\n",
      "0.6422841658586909\n",
      "Epoch 71/200, Loss: 0.011141728609800339\n",
      "0.6600742779344583\n",
      "Epoch 81/200, Loss: 0.009243679025934802\n",
      "0.6615333365544034\n",
      "Epoch 91/200, Loss: 0.008596191079252295\n",
      "0.6733667092182417\n",
      "Epoch 101/200, Loss: 0.008080265381269984\n",
      "0.6890578042728875\n",
      "Epoch 111/200, Loss: 0.007682325111495124\n",
      "0.692998030122305\n",
      "Epoch 121/200, Loss: 0.007313787678463591\n",
      "0.6844076893148301\n",
      "Epoch 131/200, Loss: 0.007057691536222895\n",
      "0.6842661036602986\n",
      "Epoch 141/200, Loss: 0.0065665880166408085\n",
      "0.6872206915973722\n",
      "Epoch 151/200, Loss: 0.006389476669331391\n",
      "0.691182482887083\n",
      "Epoch 161/200, Loss: 0.006025042928134401\n",
      "0.6894616633324686\n",
      "Epoch 171/200, Loss: 0.005925314319837425\n",
      "0.687863021133635\n",
      "Epoch 181/200, Loss: 0.005597851174469624\n",
      "0.6969404430222491\n",
      "Epoch 191/200, Loss: 0.005312722305663758\n",
      "0.6956087554304695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:32:08,032] Trial 45 finished with value: 0.6969404430222491 and parameters: {'hidden_dim_h': 37, 'dropout': 0.050441412804427266, 'batch_size': 573}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.5275269336998463\n",
      "0.0033315971702656006\n",
      "Epoch 11/200, Loss: 0.2969237696379423\n",
      "0.004148338249005104\n",
      "Epoch 21/200, Loss: 0.09555725893005729\n",
      "0.23941161423580432\n",
      "Epoch 31/200, Loss: 0.04631515429355204\n",
      "0.33080700586111117\n",
      "Epoch 41/200, Loss: 0.029794815462082624\n",
      "0.4208129643477594\n",
      "Epoch 51/200, Loss: 0.022448395611718297\n",
      "0.45633454396259077\n",
      "Epoch 61/200, Loss: 0.018176765413954854\n",
      "0.45566960679594726\n",
      "Epoch 71/200, Loss: 0.01990740589099005\n",
      "0.4137932463649336\n",
      "Epoch 81/200, Loss: 0.016968470183201134\n",
      "0.5143977590537658\n",
      "Epoch 91/200, Loss: 0.01673931599361822\n",
      "0.5036697325825776\n",
      "Epoch 101/200, Loss: 0.016009193321224302\n",
      "0.5264500201389839\n",
      "Epoch 111/200, Loss: 0.015150876017287374\n",
      "0.5306071824363346\n",
      "Epoch 121/200, Loss: 0.015891901683062315\n",
      "0.523424388707007\n",
      "Epoch 131/200, Loss: 0.01571548613719642\n",
      "0.5067561302668874\n",
      "Epoch 141/200, Loss: 0.01359211967792362\n",
      "0.5587352477371332\n",
      "Epoch 151/200, Loss: 0.011149821686558425\n",
      "0.5733451731986691\n",
      "Epoch 161/200, Loss: 0.012879219662863761\n",
      "0.5744699112539128\n",
      "Epoch 171/200, Loss: 0.011480028042569757\n",
      "0.5823863113548461\n",
      "Epoch 181/200, Loss: 0.010770620545372367\n",
      "0.5931678248728111\n",
      "Epoch 191/200, Loss: 0.010386592301074415\n",
      "0.581747526981663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:34:14,078] Trial 46 finished with value: 0.5931678248728111 and parameters: {'hidden_dim_h': 11, 'dropout': 0.08019674764208672, 'batch_size': 641}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.13540171480013263\n",
      "0.10778892383838165\n",
      "Epoch 11/200, Loss: 0.023439679346564744\n",
      "0.42172082042727016\n",
      "Epoch 21/200, Loss: 0.01106934019157456\n",
      "0.6018787081382484\n",
      "Epoch 31/200, Loss: 0.007827049341156252\n",
      "0.647442056148075\n",
      "Epoch 41/200, Loss: 0.006663476091085209\n",
      "0.6685829174367334\n",
      "Epoch 51/200, Loss: 0.005737338810124331\n",
      "0.6758620774329421\n",
      "Epoch 61/200, Loss: 0.005143178038350824\n",
      "0.6830766547603013\n",
      "Epoch 71/200, Loss: 0.004685043079209411\n",
      "0.6902167443853277\n",
      "Epoch 81/200, Loss: 0.004170184680131367\n",
      "0.7006783972295313\n",
      "Epoch 91/200, Loss: 0.004271253012120724\n",
      "0.7059492176909014\n",
      "Epoch 101/200, Loss: 0.0036282674215423563\n",
      "0.7079863128032707\n",
      "Epoch 111/200, Loss: 0.003529922260592381\n",
      "0.7047295799969652\n",
      "Epoch 121/200, Loss: 0.0033711629156540665\n",
      "0.7110643153515697\n",
      "Epoch 131/200, Loss: 0.0032285384982565623\n",
      "0.7139047009870342\n",
      "Epoch 141/200, Loss: 0.003205237780801124\n",
      "0.7134684892974402\n",
      "Epoch 151/200, Loss: 0.0030748417710937145\n",
      "0.7181495144268722\n",
      "Epoch 161/200, Loss: 0.002932065923232585\n",
      "0.7140375523851256\n",
      "Epoch 171/200, Loss: 0.003040559977913896\n",
      "0.7112772924194667\n",
      "Epoch 181/200, Loss: 0.002803025573181609\n",
      "0.7195979746637525\n",
      "Epoch 191/200, Loss: 0.0028175840012004804\n",
      "0.7178373435312555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:37:14,499] Trial 47 finished with value: 0.7195979746637525 and parameters: {'hidden_dim_h': 33, 'dropout': 0.3046498572657762, 'batch_size': 283}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.5199495662342418\n",
      "0.08160448349562795\n",
      "Epoch 11/200, Loss: 0.3281212394887751\n",
      "0.0077917465888547085\n",
      "Epoch 21/200, Loss: 0.19692322476343674\n",
      "0.05121325337407032\n",
      "Epoch 31/200, Loss: 0.10895964300090616\n",
      "0.3289367639391379\n",
      "Epoch 41/200, Loss: 0.060543783686377785\n",
      "0.4776542119664553\n",
      "Epoch 51/200, Loss: 0.035265284844420174\n",
      "0.5634283827202444\n",
      "Epoch 61/200, Loss: 0.022845478389750828\n",
      "0.6041224777990346\n",
      "Epoch 71/200, Loss: 0.017095285806466232\n",
      "0.6135710683705349\n",
      "Epoch 81/200, Loss: 0.014520112255757505\n",
      "0.6442232945748384\n",
      "Epoch 91/200, Loss: 0.013289330442520704\n",
      "0.6483688076866154\n",
      "Epoch 101/200, Loss: 0.01245889567177404\n",
      "0.6607449099776738\n",
      "Epoch 111/200, Loss: 0.011870257471772757\n",
      "0.6571437903158098\n",
      "Epoch 121/200, Loss: 0.011386352591216564\n",
      "0.6704404375858709\n",
      "Epoch 131/200, Loss: 0.010771912099285559\n",
      "0.6701577602806377\n",
      "Epoch 141/200, Loss: 0.010154099880971691\n",
      "0.6773358576959967\n",
      "Epoch 151/200, Loss: 0.009661649692464958\n",
      "0.6851083109026463\n",
      "Epoch 161/200, Loss: 0.00921472246673974\n",
      "0.6779550958311596\n",
      "Epoch 171/200, Loss: 0.008800315797667612\n",
      "0.6598043016154501\n",
      "Epoch 181/200, Loss: 0.008262529672885483\n",
      "0.6840425923494785\n",
      "Epoch 191/200, Loss: 0.007829523941671307\n",
      "0.6879897443278342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:40:39,408] Trial 48 finished with value: 0.6879897443278342 and parameters: {'hidden_dim_h': 43, 'dropout': 0.26150248843275004, 'batch_size': 931}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.13042027205228807\n",
      "0.10283754634390052\n",
      "Epoch 11/200, Loss: 0.06845754384994507\n",
      "0.11881264647658901\n",
      "Epoch 21/200, Loss: 0.04529933705925941\n",
      "0.09960847897922885\n",
      "Epoch 31/200, Loss: 0.03709298819303512\n",
      "0.14396327554909738\n",
      "Epoch 41/200, Loss: 0.03469845131039619\n",
      "0.20219663463489182\n",
      "Epoch 51/200, Loss: 0.03472235985100269\n",
      "0.20966480613135716\n",
      "Epoch 61/200, Loss: 0.03436243459582329\n",
      "0.2144143121681992\n",
      "Epoch 71/200, Loss: 0.03374173194169998\n",
      "0.22887773802356343\n",
      "Epoch 81/200, Loss: 0.03332984987646341\n",
      "0.21677980348318115\n",
      "Epoch 91/200, Loss: 0.032718551158905027\n",
      "0.21084113908389313\n",
      "Epoch 101/200, Loss: 0.03255918025970459\n",
      "0.22131889635761132\n",
      "Epoch 111/200, Loss: 0.031912236288189885\n",
      "0.2326651149157351\n",
      "Epoch 121/200, Loss: 0.031604260206222534\n",
      "0.23544908929710173\n",
      "Epoch 131/200, Loss: 0.031353802792727946\n",
      "0.23304737525166164\n",
      "Epoch 141/200, Loss: 0.03169944938272238\n",
      "0.21630875988775616\n",
      "Epoch 151/200, Loss: 0.032258133962750436\n",
      "0.18921937263029548\n",
      "Epoch 161/200, Loss: 0.03125706110149622\n",
      "0.2205938717895983\n",
      "Epoch 171/200, Loss: 0.030913181975483893\n",
      "0.2305130401765168\n",
      "Epoch 181/200, Loss: 0.030866030789911746\n",
      "0.23589718759015713\n",
      "Epoch 191/200, Loss: 0.03131798803806305\n",
      "0.230769257745433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:44:23,738] Trial 49 finished with value: 0.23589718759015713 and parameters: {'hidden_dim_h': 50, 'dropout': 0.32431957135492506, 'batch_size': 1059}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 1.0154782618795122\n",
      "0.041631043339537314\n",
      "Epoch 11/200, Loss: 0.6595437952450344\n",
      "0.0030896359560106876\n",
      "Epoch 21/200, Loss: 0.3916350709540503\n",
      "0.27721883420759386\n",
      "Epoch 31/200, Loss: 0.2227781734296254\n",
      "0.43106344186277584\n",
      "Epoch 41/200, Loss: 0.12076448063765254\n",
      "0.6018363398216174\n",
      "Epoch 51/200, Loss: 0.0627052504569292\n",
      "0.6173456881637804\n",
      "Epoch 61/200, Loss: 0.03175472468137741\n",
      "0.6532727801388319\n",
      "Epoch 71/200, Loss: 0.016565898034189428\n",
      "0.6840113156930596\n",
      "Epoch 81/200, Loss: 0.00953562670786466\n",
      "0.6902350845415973\n",
      "Epoch 91/200, Loss: 0.006605641251163823\n",
      "0.6928752103577823\n",
      "Epoch 101/200, Loss: 0.005336903634348086\n",
      "0.6985877341532295\n",
      "Epoch 111/200, Loss: 0.004722761788538524\n",
      "0.7046633079151566\n",
      "Epoch 121/200, Loss: 0.0043936843950567505\n",
      "0.7078335016269682\n",
      "Epoch 131/200, Loss: 0.004176719263861222\n",
      "0.7105267858291918\n",
      "Epoch 141/200, Loss: 0.003992320686977889\n",
      "0.7079037712628103\n",
      "Epoch 151/200, Loss: 0.0037742378689082606\n",
      "0.7056644009166297\n",
      "Epoch 161/200, Loss: 0.00365597937655236\n",
      "0.7060261016344125\n",
      "Epoch 171/200, Loss: 0.0035800981401864973\n",
      "0.7101913556673164\n",
      "Epoch 181/200, Loss: 0.0034626125125214458\n",
      "0.7125293767983322\n",
      "Epoch 191/200, Loss: 0.0033513240216832075\n",
      "0.7144787146825241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:47:49,677] Trial 50 finished with value: 0.7144787146825241 and parameters: {'hidden_dim_h': 46, 'dropout': 0.27704475428254116, 'batch_size': 718}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.08880200646817685\n",
      "0.00011533058958142011\n",
      "Epoch 11/200, Loss: 0.03662712182849646\n",
      "0.14923915821299086\n",
      "Epoch 21/200, Loss: 0.013154100254178047\n",
      "0.5191532693648475\n",
      "Epoch 31/200, Loss: 0.008631697413511575\n",
      "0.5565414023473235\n",
      "Epoch 41/200, Loss: 0.0072265868075191975\n",
      "0.6403584308391866\n",
      "Epoch 51/200, Loss: 0.006029029726050794\n",
      "0.6303101495641716\n",
      "Epoch 61/200, Loss: 0.005713679292239249\n",
      "0.6499258130925071\n",
      "Epoch 71/200, Loss: 0.0051246724324300885\n",
      "0.6335543435835136\n",
      "Epoch 81/200, Loss: 0.005049737764056772\n",
      "0.6436628729807358\n",
      "Epoch 91/200, Loss: 0.004585471074096859\n",
      "0.6514836533557878\n",
      "Epoch 101/200, Loss: 0.004297262814361602\n",
      "0.6701921020407744\n",
      "Epoch 111/200, Loss: 0.004355294036213308\n",
      "0.6519193779050594\n",
      "Epoch 121/200, Loss: 0.004028730874415487\n",
      "0.6697520351095467\n",
      "Epoch 131/200, Loss: 0.00376829692395404\n",
      "0.6756756912746782\n",
      "Epoch 141/200, Loss: 0.0035015781759284437\n",
      "0.6716802140247804\n",
      "Epoch 151/200, Loss: 0.003570557862985879\n",
      "0.6685620137690219\n",
      "Epoch 161/200, Loss: 0.0034339248028118162\n",
      "0.6731936404987423\n",
      "Epoch 171/200, Loss: 0.0033062053436879067\n",
      "0.691530008589001\n",
      "Epoch 181/200, Loss: 0.0033530834421981125\n",
      "0.6840433918848003\n",
      "Epoch 191/200, Loss: 0.0032241174834780396\n",
      "0.6909365364255862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:50:58,533] Trial 51 finished with value: 0.691530008589001 and parameters: {'hidden_dim_h': 40, 'dropout': 0.28764103131828195, 'batch_size': 517}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.11798470297997649\n",
      "0.09865280805404021\n",
      "Epoch 11/200, Loss: 0.04242490231990814\n",
      "0.13486119577312664\n",
      "Epoch 21/200, Loss: 0.01586215380071239\n",
      "0.5471681806343734\n",
      "Epoch 31/200, Loss: 0.010293304581533779\n",
      "0.6591325700975759\n",
      "Epoch 41/200, Loss: 0.008405186130072583\n",
      "0.669908214159623\n",
      "Epoch 51/200, Loss: 0.0071264402305876665\n",
      "0.680113662511391\n",
      "Epoch 61/200, Loss: 0.006349463883618062\n",
      "0.6791646230376776\n",
      "Epoch 71/200, Loss: 0.005592843983322382\n",
      "0.6862355541476284\n",
      "Epoch 81/200, Loss: 0.005267075178298083\n",
      "0.6794966172363343\n",
      "Epoch 91/200, Loss: 0.0047399391716515474\n",
      "0.6830938743450216\n",
      "Epoch 101/200, Loss: 0.004477405962957578\n",
      "0.6757570094729098\n",
      "Epoch 111/200, Loss: 0.0042267589385367255\n",
      "0.6854649408413672\n",
      "Epoch 121/200, Loss: 0.003926654600284316\n",
      "0.6869193542601674\n",
      "Epoch 131/200, Loss: 0.003708253307691352\n",
      "0.6958660338445675\n",
      "Epoch 141/200, Loss: 0.003652376323853704\n",
      "0.6856686127770946\n",
      "Epoch 151/200, Loss: 0.0035475297428836875\n",
      "0.6915983630057052\n",
      "Epoch 161/200, Loss: 0.003430090675299818\n",
      "0.6884734244694993\n",
      "Epoch 171/200, Loss: 0.00346892167263749\n",
      "0.6852624571020076\n",
      "Epoch 181/200, Loss: 0.00313891618068076\n",
      "0.6938671001904546\n",
      "Epoch 191/200, Loss: 0.0030994105671363122\n",
      "0.6966815270545441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-15 13:54:03,085] Trial 52 finished with value: 0.6966815270545441 and parameters: {'hidden_dim_h': 38, 'dropout': 0.3386745074928317, 'batch_size': 457}. Best is trial 23 with value: 0.7425963534660985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.11825802109458229\n",
      "0.11272059751046157\n",
      "Epoch 11/200, Loss: 0.030463710173287174\n",
      "0.27797545719141387\n",
      "Epoch 21/200, Loss: 0.019184360830959948\n",
      "0.5340459349190205\n",
      "Epoch 31/200, Loss: 0.013915268534963781\n",
      "0.5424372157628001\n",
      "Epoch 41/200, Loss: 0.010051562493159012\n",
      "0.618555282825221\n",
      "Epoch 51/200, Loss: 0.007474723377857696\n",
      "0.6727375950990782\n",
      "Epoch 61/200, Loss: 0.006372723537920551\n",
      "0.6826279330530823\n",
      "Epoch 71/200, Loss: 0.00560281683944843\n",
      "0.6821482555745707\n",
      "Epoch 81/200, Loss: 0.005269514481452378\n",
      "0.6788360053218352\n"
     ]
    }
   ],
   "source": [
    "# Create and run the Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "best_trial = study.best_trial\n",
    "print(\"Best Trial:\")\n",
    "print(f\"  Value: {best_trial.value:.4f}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# You can then use the best hyperparameters to train your final model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f54a216-2b77-44b8-8711-23db2597354c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8.1",
   "language": "python",
   "name": "pytorch-1.8.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
