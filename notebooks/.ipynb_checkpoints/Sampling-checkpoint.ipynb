{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be862153-b321-4bbc-8757-0306fdcd708e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  5% |  1% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% | 98% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6284190c-2479-449b-a618-1c7783ee271e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from functools import partial\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import GPUtil\n",
    "from scipy.stats import pearsonr\n",
    "# import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "sys.path.append('../model/')\n",
    "from utils import amino_acid_to_number, tokenize, Tee\n",
    "from models import make_predictions, ProtDataset, LinearModel, Transformer_2k\n",
    "from functions import get_A2N_list, tokenize, make_train_val_test_lists_rand, prepare_data\n",
    "from kernels import EpModel\n",
    "import random\n",
    "import gpytorch\n",
    "from scipy.special._basic import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6002ceb4-67c7-499e-9311-7afb9246c048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fe6d49-f101-4dbf-ab2a-fadbabdf35b6",
   "metadata": {},
   "source": [
    "### Sampling sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ea50b314-0eb7-48c2-84d3-e99c6d066ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AA_size = 20\n",
    "alphabet = list(range(AA_size))\n",
    "L = 10\n",
    "\n",
    "mu = .2 # mutation rate\n",
    "n = 25000 # number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3ac540ee-7d8a-464c-8034-129ca3c57eda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_seqs(mu, n):\n",
    "    weights = [1 - mu]\n",
    "    for _ in range(AA_size - 1):\n",
    "        weights.append(mu / (AA_size - 1))  \n",
    "\n",
    "    for R in range(20):\n",
    "        seqs = [random.choices(alphabet, k=L, weights=weights) for _ in range(n*R)]\n",
    "        seqs = {tuple(seq) for seq in seqs}\n",
    "        seqs = [list(seq) for seq in seqs]    \n",
    "        if len(seqs) > n:\n",
    "            print(f\"sampling completed at R = {R}\")\n",
    "            return seqs[:n]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "439ea5a0-8f14-4d4b-b665-4199a21a1101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling completed at R = 2\n"
     ]
    }
   ],
   "source": [
    "seqs = sample_seqs(mu, n)\n",
    "\n",
    "seqs_ = seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8926c5-c570-4d93-85f0-0c84fc0c6105",
   "metadata": {},
   "source": [
    "### Sampling phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7eefaecf-3dce-445b-8127-bf83a997e3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "seqs = torch.tensor(seqs)\n",
    "seqs = seqs.squeeze(1)\n",
    "seqs1h = one_hot(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "86c12239-366d-48a9-b9b4-0c1c94c836fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = seqs1h.float().flatten(1).cuda()\n",
    "y = torch.ones(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "84f3ffaf-dab2-4b69-a30e-789f2f85d8f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_x = seqs1h[train_list].float().flatten(1)\n",
    "# train_y = torch.ones(train_x.shape[0])\n",
    "# train_x = train_x.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c1719501-96d6-4af7-872e-234b34770b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raw_lda = torch.nn.Parameter(torch.tensor([ 3.7921,  7.7892, 11.7760, 15.7680, 19.7600, 23.7520, 27.7440, 32.1356]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3295bbd6-5668-4021-845e-24cfb8aa7c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decay = 6.\n",
    "raw_lda = torch.nn.Parameter(torch.tensor(decay*np.arange(8)).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0a119fac-d10f-4ce9-9ee8-77e5851ed8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().cuda()\n",
    "\n",
    "model = EpModel(X, y, likelihood, AA_size, L, d_max=L, k_max=8, get_alpha=False).cuda()\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "model.covar_module.w_kd = model.covar_module.w_kd.to(device)\n",
    "model.covar_module.raw_lda = raw_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c335cca3-b5e1-4ce5-8158-d40045f43bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mks = torch.tensor([comb(L, k) * (AA_size - 1)**k for k in range(1, 9)]).to(device)\n",
    "\n",
    "VC = mks*torch.exp(model.covar_module.lda)\n",
    "VC = (VC/VC.sum()).detach().cpu().numpy()\n",
    "\n",
    "plt.bar(range(1, 9), VC)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "73d81dbe-1c10-420d-8453-46942fd5dbf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "mvn = model(X)\n",
    "\n",
    "phenotypes = mvn.rsample()\n",
    "\n",
    "del model, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "02583fc4-1828-41c4-9d9c-b2f18669abd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phenotypes = phenotypes.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0c5ce6a5-7e63-4c45-9053-1b61cc057d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phenotypes = torch.tensor(phenotypes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2382fd0d-d0ff-4200-b9e8-bbdcb96dbd10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def numbers_to_amino_acid_sequence(numbers):\n",
    "    amino_acids = [\n",
    "        \"A\", \"R\", \"N\", \"D\", \"C\",\n",
    "        \"Q\", \"E\", \"G\", \"H\", \"I\",\n",
    "        \"L\", \"K\", \"M\", \"F\", \"P\",\n",
    "        \"S\", \"T\", \"W\", \"Y\", \"V\"\n",
    "    ]\n",
    "    amino_acid_sequence = \"\"\n",
    "    for num in numbers:\n",
    "        if 0 <= num <= 19:\n",
    "            amino_acid_sequence += amino_acids[num]\n",
    "        else:\n",
    "            amino_acid_sequence += \"X\"  # Placeholder for unknown amino acids\n",
    "    return amino_acid_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "078fa491-5814-43af-9c18-c2bd65c23e39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CEAAAPAAAV',\n",
       " 'ARAAAAAAAK',\n",
       " 'AAALMAAAAA',\n",
       " 'AMLAAAAAEA',\n",
       " 'TPTAAAAAAA',\n",
       " 'YAAAAAYAAV',\n",
       " 'SAAAAAFAAA',\n",
       " 'AADAAGASAA',\n",
       " 'AAAAAAAIKD',\n",
       " 'AAAAHLPARA',\n",
       " 'ADAAAAAAFA',\n",
       " 'AAAANIAAAA',\n",
       " 'KAAAAAMRAA',\n",
       " 'AAAAAPAIAA',\n",
       " 'AAAATAALAW',\n",
       " 'AAAALIAKAA',\n",
       " 'AAAAANAADA',\n",
       " 'AAAAGRAAAK',\n",
       " 'AAANAAAAWA',\n",
       " 'AAAHAAAHWA',\n",
       " 'TAAAAAEAAR',\n",
       " 'AAGAAACAAA',\n",
       " 'AAAWAAFAAA',\n",
       " 'IAAAPAAQAA',\n",
       " 'DAQYAAAAAK',\n",
       " 'IPAACAAAAA',\n",
       " 'AAAAAAARAM',\n",
       " 'AAAARAHRPA',\n",
       " 'AACTATAGAA',\n",
       " 'TAAAASAAAA',\n",
       " 'AAAMAAAKFA',\n",
       " 'AANAATAAAD',\n",
       " 'CAAAAAAYAA',\n",
       " 'AAAAAAAVAV',\n",
       " 'AAANFAMAAA',\n",
       " 'AAAEAWVAAA',\n",
       " 'AAAAMAAADA',\n",
       " 'AAAAAANCAC',\n",
       " 'AAAAPAAWAQ',\n",
       " 'AAAPAAAEAT',\n",
       " 'AAAGAQAAAA',\n",
       " 'FAAAFAAAAA',\n",
       " 'AAAAFACIAA',\n",
       " 'AAAHAQAAAA',\n",
       " 'AVAAAARAPA',\n",
       " 'AAAAAAANAV',\n",
       " 'AMFAAAAAAP',\n",
       " 'AEAADHAAGA',\n",
       " 'AAAAPAAAAQ',\n",
       " 'AAAACNAAAN',\n",
       " 'AAWAGAAAAA',\n",
       " 'AAARMYAAAA',\n",
       " 'AAFFAAAAAA',\n",
       " 'EWAAAAAAAF',\n",
       " 'AAYTAAAFAA',\n",
       " 'AAYQAAAHAA',\n",
       " 'VAAIAWRAAA',\n",
       " 'AFAAHAAAAA',\n",
       " 'AAANAKAAIM',\n",
       " 'FFAASAARTA',\n",
       " 'AAHGGAAAAA',\n",
       " 'ATKAAAAAAG',\n",
       " 'NARAKKAASA',\n",
       " 'ALAALAAAAA',\n",
       " 'VAAASAAENA',\n",
       " 'AAAAFTAATA',\n",
       " 'AGASAAAAAA',\n",
       " 'AAAYACAAIA',\n",
       " 'AQARAAAAEA',\n",
       " 'AAAAAALYAA',\n",
       " 'CAQAALAACN',\n",
       " 'AADAAALVAA',\n",
       " 'AAEAAACAAA',\n",
       " 'AAAAAEYAWA',\n",
       " 'AAAAEASAAF',\n",
       " 'HAAWAAAAAL',\n",
       " 'ADAQTAAAAA',\n",
       " 'AAPAAAACAA',\n",
       " 'AAAAAFFQAA',\n",
       " 'AWAAAASWGA',\n",
       " 'AAAAAAVKRA',\n",
       " 'SACHGEAAKA',\n",
       " 'VAAHAAAAAA',\n",
       " 'CAAAAAAACA',\n",
       " 'AAAAAAAGMA',\n",
       " 'WAAAYAAAAA',\n",
       " 'AAAAALAAAQ',\n",
       " 'AAHFAAALAA',\n",
       " 'HAMMAAAAAT',\n",
       " 'LAAAAAAAVL',\n",
       " 'AAAAEAAAMA',\n",
       " 'AAAAFNAAAF',\n",
       " 'KAAAAAAGEI',\n",
       " 'QAAARPAAAA',\n",
       " 'LAAPAAAEEA',\n",
       " 'AAAAASALAR',\n",
       " 'DAADFARAYA',\n",
       " 'AAGAAAAAWA',\n",
       " 'IAAAKIAAAP',\n",
       " 'AWARAAAAAA',\n",
       " 'AAAALAADAA',\n",
       " 'AAAAAAAKPA',\n",
       " 'VAAAALAAAA',\n",
       " 'AAAAAAAELA',\n",
       " 'AAQPAKATAA',\n",
       " 'AAKAAAAYAA',\n",
       " 'NAAIAAAAQA',\n",
       " 'ACAVATAAAA',\n",
       " 'ACAAAAVCAA',\n",
       " 'WACAEDALAA',\n",
       " 'AVAAAAAAAI',\n",
       " 'HAAAEAAAYA',\n",
       " 'AAPARTAAAM',\n",
       " 'AAYAEAAAAA',\n",
       " 'AGAWWWQEAA',\n",
       " 'NAAAAAPAAA',\n",
       " 'AAADAAMAAA',\n",
       " 'AAWKAAADAA',\n",
       " 'AANAAWFAAA',\n",
       " 'ALAAAFAAAA',\n",
       " 'AAKAAAARAA',\n",
       " 'AAAAAAAYAG',\n",
       " 'AAAAAAAEWT',\n",
       " 'AFAAAAACAL',\n",
       " 'AAAAAAALAW',\n",
       " 'AAAAAAFPAG',\n",
       " 'AAVAAAAKAA',\n",
       " 'AAAYAWAATA',\n",
       " 'AMAAFARAAA',\n",
       " 'AAAMACHAAA',\n",
       " 'AAAAAKAAKA',\n",
       " 'AAAAAAARYA',\n",
       " 'AATAAAAAAG',\n",
       " 'AAAAAAALMA',\n",
       " 'AAFAAYEAAA',\n",
       " 'WMACAAAAAC',\n",
       " 'QADITAAAAA',\n",
       " 'AAEAAAAAWA',\n",
       " 'AAAIAAAAAL',\n",
       " 'AQACAAAAAD',\n",
       " 'MSAAAAHAAG',\n",
       " 'AEAAAAAAAV',\n",
       " 'AAAASAAMAA',\n",
       " 'AAAAATCAAA',\n",
       " 'AAAAMEQAAA',\n",
       " 'AAAAAACPFA',\n",
       " 'AWKSAVAAHR',\n",
       " 'ACWAAAAAAA',\n",
       " 'AAAFAAAAAR',\n",
       " 'WAAAAIAAAA',\n",
       " 'LAAAFAAAAA',\n",
       " 'IAALAAAQAA',\n",
       " 'AMAGAAAAAA',\n",
       " 'CAADAAAIAA',\n",
       " 'AAAAFAANAM',\n",
       " 'GAAAAATAAA',\n",
       " 'AGAAAYGAAG',\n",
       " 'YAYAAAAAAY',\n",
       " 'KGWRAAAAAA',\n",
       " 'AAAARAASAA',\n",
       " 'AGAAAIAAAW',\n",
       " 'AMAAAVEAAA',\n",
       " 'AAPAAPAAAA',\n",
       " 'VAACKAAAAA',\n",
       " 'AAAAAPAAQA',\n",
       " 'AQAAAAAFAT',\n",
       " 'AAATAADAAM',\n",
       " 'AAAAAATAIF',\n",
       " 'AASAAARAAR',\n",
       " 'ATAAASAAAA',\n",
       " 'AAPAAAAAGI',\n",
       " 'PAAFAAAAAA',\n",
       " 'AAFAAAVAAA',\n",
       " 'NAQAAAWAAA',\n",
       " 'AAAWADCLVA',\n",
       " 'QAAAAAWAAI',\n",
       " 'NQAMLIDAAA',\n",
       " 'NARAAWHAAA',\n",
       " 'NCAAIALAAA',\n",
       " 'DAYAAIAAAA',\n",
       " 'AAALAAAAAM',\n",
       " 'AAAVAADHAQ',\n",
       " 'AARTAAAAAA',\n",
       " 'AAAAAAIAAR',\n",
       " 'AAAAAAPAAG',\n",
       " 'AAASAAAAGA',\n",
       " 'GAAAAAFAAA',\n",
       " 'AAAAAAAARH',\n",
       " 'AAAAGWCAAA',\n",
       " 'AAIAAQAADA',\n",
       " 'APAANANAAA',\n",
       " 'AAIACAAAAA',\n",
       " 'AETAAAQAAA',\n",
       " 'AVGAAAAAAM',\n",
       " 'EAAAAAAACA',\n",
       " 'AAVAAHAWKA',\n",
       " 'AAAAEISPAA',\n",
       " 'AAAAVAPAAF',\n",
       " 'VAAAAAACAN',\n",
       " 'ACAAAAFMAA',\n",
       " 'AAAAMWAAAA',\n",
       " 'VAAAAIAAAA',\n",
       " 'KAPAAEAAAA',\n",
       " 'ACAPAAAAAA',\n",
       " 'AAANVAAASA',\n",
       " 'EAARAAAAAA',\n",
       " 'APAAMAAAAR',\n",
       " 'AAFAAAAMAA',\n",
       " 'AAAAAAKAAG',\n",
       " 'FAACAAAACA',\n",
       " 'DAAAAHAAAA',\n",
       " 'AAYAAAAASA',\n",
       " 'FANAAAAAAA',\n",
       " 'ADQAAAAHAP',\n",
       " 'AAGMAAAVAA',\n",
       " 'ASAAHAADQA',\n",
       " 'MAAAAIARAA',\n",
       " 'PAAAAAEFAA',\n",
       " 'PAAGAAAANY',\n",
       " 'LAAAAAMAYM',\n",
       " 'AAWAACRAAA',\n",
       " 'AAAGPNAAAA',\n",
       " 'AAAAQVAAAA',\n",
       " 'NAAAAAAKMA',\n",
       " 'AAAAAAAYNA',\n",
       " 'AAAAAQANNA',\n",
       " 'SGAAKISAAA',\n",
       " 'PMAEAPAWAY',\n",
       " 'ACAKAAAAPA',\n",
       " 'AAAFARAAAA',\n",
       " 'AAHAWAAEAA',\n",
       " 'AAAFAAAQAS',\n",
       " 'AAAALAALYA',\n",
       " 'AATAAAAANA',\n",
       " 'RAVAAAAAAA',\n",
       " 'AAAAAANAPA',\n",
       " 'ADAKAAAAAA',\n",
       " 'AAAMAAMQAA',\n",
       " 'FAAAAAAFNA',\n",
       " 'AAAAAAFALA',\n",
       " 'AAKAKAAAPA',\n",
       " 'AAAAAAHACA',\n",
       " 'AKAACAQAAA',\n",
       " 'YNEAAAAPTA',\n",
       " 'YAAFAATHAA',\n",
       " 'AAAYMAAIAA',\n",
       " 'DDAANAAAAA',\n",
       " 'AAAAAAAWAA',\n",
       " 'GAADAAARAE',\n",
       " 'AHASAAAAAA',\n",
       " 'AAGACANAAA',\n",
       " 'AAEAAAAGQA',\n",
       " 'ACACAARAAA',\n",
       " 'AAWAAAAAIA',\n",
       " 'IPAMAAARAA',\n",
       " 'AASAAANALA',\n",
       " 'SAAAAAAQAY',\n",
       " 'AASAAAAFAA',\n",
       " 'ARAARASAEA',\n",
       " 'AAMAAAAAPA',\n",
       " 'NAAALAAAAA',\n",
       " 'APADANAAAA',\n",
       " 'AAALAAAAYA',\n",
       " 'AAQAASAADA',\n",
       " 'AAHSAAAMAA',\n",
       " 'AAVAAAIPLA',\n",
       " 'AAAADAAASA',\n",
       " 'AAAAYAAVYA',\n",
       " 'RAYAAAAAAA',\n",
       " 'AAAAAAKALA',\n",
       " 'AQAANAAAAA',\n",
       " 'FAVAAADAAA',\n",
       " 'FAAAAAPWAA',\n",
       " 'LQAAAAAAAA',\n",
       " 'AAAAAAEAQA',\n",
       " 'DAAAAKNAAA',\n",
       " 'SAAAAFIAAL',\n",
       " 'AAAAPASAAA',\n",
       " 'AMANAAAAAA',\n",
       " 'AAATAAAAMA',\n",
       " 'AARFWAQALA',\n",
       " 'ASAIHAKAAA',\n",
       " 'HAAAATAAAM',\n",
       " 'TAAAAAAQAG',\n",
       " 'CCAAAAAASA',\n",
       " 'AAKANFAAAA',\n",
       " 'AAAAFDTAFQ',\n",
       " 'AESAAAQAAA',\n",
       " 'AANAAAAAMA',\n",
       " 'PAAAAATAAA',\n",
       " 'AHAAAAALMA',\n",
       " 'KLAAAAAAAV',\n",
       " 'AEAASAAAAA',\n",
       " 'IAAAAAAWAL',\n",
       " 'AALAWAAKPA',\n",
       " 'AFAAAAAYAK',\n",
       " 'PAQAAAAAHA',\n",
       " 'AAALANAAAA',\n",
       " 'AAAATAANVA',\n",
       " 'NAAAAAFEIA',\n",
       " 'NAAAYAAAAA',\n",
       " 'MAGARAAWAA',\n",
       " 'AAAAFIAAAA',\n",
       " 'AAACAFAAAA',\n",
       " 'AAAQAVARAA',\n",
       " 'ANIFAIAAAS',\n",
       " 'NVAAAAAAAA',\n",
       " 'AALAAKVAAM',\n",
       " 'LAYAAWAALA',\n",
       " 'AAAAAADAQA',\n",
       " 'YMAAAQAIAA',\n",
       " 'AAAAAAAGAY',\n",
       " 'PAAAAAKIYA',\n",
       " 'AAWACAAACA',\n",
       " 'NRAAAASAAA',\n",
       " 'AAYGEALAAA',\n",
       " 'AAAGKATAAA',\n",
       " 'AQAAQSPAAA',\n",
       " 'ASAAAAAAVA',\n",
       " 'AARAAIAAAA',\n",
       " 'AAATAAIAIA',\n",
       " 'EAAAYAAAEA',\n",
       " 'EAAAAAAVAA',\n",
       " 'ASYAAAAFAA',\n",
       " 'MDHAAAAAAA',\n",
       " 'ARAAAASAAA',\n",
       " 'AAHAAAAARY',\n",
       " 'EADAALAASA',\n",
       " 'SWAAQAAAAL',\n",
       " 'AADEAWAAAA',\n",
       " 'AAAAHAAIAA',\n",
       " 'AIALIAEAAA',\n",
       " 'EAGAPAAAAA',\n",
       " 'ACAMAWAAAA',\n",
       " 'WAAAAWAMAA',\n",
       " 'AAAAQAAIAA',\n",
       " 'AAMAANADAA',\n",
       " 'AMAAAAYAAA',\n",
       " 'AALAAEAAET',\n",
       " 'APKARAARAA',\n",
       " 'AAQLAAAAAN',\n",
       " 'FAAAAQAAAF',\n",
       " 'AAAAIAIYAI',\n",
       " 'VIAFAAWAAV',\n",
       " 'AAAMQAAAAA',\n",
       " 'AAAAAAFAAL',\n",
       " 'MHSAAAAYAG',\n",
       " 'AAAAAAQAAC',\n",
       " 'AAAEAALARQ',\n",
       " 'AFAAVFTAAA',\n",
       " 'AAAAVAMAAA',\n",
       " 'PADMAAAAAA',\n",
       " 'KAAAHAAAAA',\n",
       " 'SARVKAAAAA',\n",
       " 'VPKITAAAGP',\n",
       " 'ARKAAAAAAA',\n",
       " 'AATAHARHAA',\n",
       " 'ANAAAAAEEA',\n",
       " 'AAAAAIAAGA',\n",
       " 'RAAAAAAAAC',\n",
       " 'GATAYALAHS',\n",
       " 'AAFAAMAAAQ',\n",
       " 'AAAALKAYAM',\n",
       " 'AAIVAAAAHQ',\n",
       " 'GAAYAMAAAA',\n",
       " 'LAAAWDMAAA',\n",
       " 'AWAMAAARAA',\n",
       " 'TMALAAAAAA',\n",
       " 'AAAAPAACAT',\n",
       " 'AAYAQAAAAA',\n",
       " 'ACALFAAAAA',\n",
       " 'AQAEAWAAAA',\n",
       " 'AMAAAAASAA',\n",
       " 'AAAAVATMAA',\n",
       " 'WLPAAAAAGE',\n",
       " 'IAHAAAANAA',\n",
       " 'AAKAYAAALV',\n",
       " 'AAAAFAARAA',\n",
       " 'AAFAAAYAAD',\n",
       " 'AAAALAARAA',\n",
       " 'ANAGAAAAAA',\n",
       " 'AAKAWHAAHA',\n",
       " 'PAAAAASAGA',\n",
       " 'AAALAAATAA',\n",
       " 'VAEAAEAAAE',\n",
       " 'AAAVCAHGAA',\n",
       " 'AAAAYFTRAA',\n",
       " 'AMAAAAAAAK',\n",
       " 'ALAAKNAAAA',\n",
       " 'AAAADIRAAA',\n",
       " 'AAAAAMAANA',\n",
       " 'AACAAAAARA',\n",
       " 'AAVAAAAIAA',\n",
       " 'RAAAAAANAA',\n",
       " 'AAAIVAAAAA',\n",
       " 'AFNAFAAAAA',\n",
       " 'AAAASAMSAF',\n",
       " 'DAIAAKALAA',\n",
       " 'AAQAAFAAPA',\n",
       " 'AAAAMAAAAD',\n",
       " 'AAAACAASAA',\n",
       " 'AAGAKEAAAA',\n",
       " 'AATAAFAQAR',\n",
       " 'AANAAAAGAA',\n",
       " 'AAAVAAANAA',\n",
       " 'AAIIAAAFAA',\n",
       " 'CAADAFAAAD',\n",
       " 'RPAALAAAKA',\n",
       " 'AAAAYAARAA',\n",
       " 'AFAAAAAADA',\n",
       " 'AAAKAAWGQN',\n",
       " 'AKAAAAVAGA',\n",
       " 'AAAAAGAACA',\n",
       " 'AAFSAASHAA',\n",
       " 'AAASAAFAAA',\n",
       " 'AAAQAAAHAA',\n",
       " 'AAAAAGKAAA',\n",
       " 'ACAAAAAPAA',\n",
       " 'ACAAEVAAAA',\n",
       " 'WSAAAAIAAA',\n",
       " 'CAAAAACAAA',\n",
       " 'FAAKMRAAAA',\n",
       " 'AFAAAAATAA',\n",
       " 'AAATWAAAAA',\n",
       " 'AAARAAADAA',\n",
       " 'AARAAAEHAA',\n",
       " 'FYAAANAAAH',\n",
       " 'RQQNAAAAYA',\n",
       " 'WFAPGAIDAA',\n",
       " 'AGAACFAAAA',\n",
       " 'WTAAPAAAAA',\n",
       " 'PSAAAAAWAM',\n",
       " 'AAADAIANAA',\n",
       " 'HANAYVQAAA',\n",
       " 'APAAKAPAAA',\n",
       " 'AAAAFAPAAA',\n",
       " 'AAPAQAAAAA',\n",
       " 'AQAAAAAANA',\n",
       " 'AAAATYAAAA',\n",
       " 'ANAAAATAAA',\n",
       " 'FAQAAAANAA',\n",
       " 'AGCNAFALAA',\n",
       " 'AAHAASHAAA',\n",
       " 'AAAAAKAAAN',\n",
       " 'AAKSAAAINA',\n",
       " 'FAAAAEAAAP',\n",
       " 'FNAAAADAAA',\n",
       " 'AAAAGIAAAD',\n",
       " 'AAAAPAAAAI',\n",
       " 'AIAAAAAANA',\n",
       " 'ICAACACACA',\n",
       " 'AAAAGAAAPA',\n",
       " 'LTAAAAAAAA',\n",
       " 'VAACRRAAAA',\n",
       " 'SAAAAAAASL',\n",
       " 'ANAAAQAQAA',\n",
       " 'AIAHAAAYAA',\n",
       " 'AAIVHAAAAF',\n",
       " 'AAAAAAAIIP',\n",
       " 'PAAAKAAAAV',\n",
       " 'RAAADACAAW',\n",
       " 'AAADIAAAAA',\n",
       " 'AAAAAAADAD',\n",
       " 'MAAAAGAAAA',\n",
       " 'AAAAAAAACF',\n",
       " 'AAAAAKCAGA',\n",
       " 'YASADAAAAA',\n",
       " 'ANAAAAPAAA',\n",
       " 'WAMLWAAAAA',\n",
       " 'QKAAAAAAGA',\n",
       " 'AIAAAAACCA',\n",
       " 'AAAAAPAALA',\n",
       " 'AAADAAAMDA',\n",
       " 'AAAGAATAQA',\n",
       " 'HAAAADAAAA',\n",
       " 'AIAAAAKCAA',\n",
       " 'AAAPAAAAAW',\n",
       " 'AAAEAAYEAA',\n",
       " 'SAAMTYAAAA',\n",
       " 'AEAQAAADAA',\n",
       " 'AAATAWCAAA',\n",
       " 'AANAADAAAA',\n",
       " 'AAAAEAQAAA',\n",
       " 'RAAAPEAAAA',\n",
       " 'AEAAAIAAAF',\n",
       " 'GAAAAAAAAM',\n",
       " 'RRAAMAAAWA',\n",
       " 'AAEDQAAAAA',\n",
       " 'AAADWAAAAA',\n",
       " 'ASAHSGAAAA',\n",
       " 'AAADNAATAA',\n",
       " 'IAASAAALAA',\n",
       " 'TAAAAAATAA',\n",
       " 'AARMAAMAAA',\n",
       " 'AAAAAEAQAL',\n",
       " 'AEAWCAADCC',\n",
       " 'IAAAAHAAWA',\n",
       " 'AAEAACAAAA',\n",
       " 'IYAAAAAVAA',\n",
       " 'AAADAAAKAA',\n",
       " 'AAVAYAHNAA',\n",
       " 'EAAAAAAASA',\n",
       " 'AAGASWAATW',\n",
       " 'AAACAAAALQ',\n",
       " 'ATAAKANEAA',\n",
       " 'AAAVDAAAAA',\n",
       " 'AAAAAAAQKA',\n",
       " 'NAAWAKAATE',\n",
       " 'AAADAAAALK',\n",
       " 'AAAAPYADAV',\n",
       " 'AGAIAASEAA',\n",
       " 'AAAQLAAAAA',\n",
       " 'AMAAAAANLA',\n",
       " 'AVAAAAAAAF',\n",
       " 'AAAAAYAAAV',\n",
       " 'AAAKWQEAAG',\n",
       " 'AAAGAFAKAA',\n",
       " 'AAATAAAAAY',\n",
       " 'AAAAAAAYAK',\n",
       " 'ARAAAAALAA',\n",
       " 'AFFDVAHAAA',\n",
       " 'AAAAAASAWW',\n",
       " 'HACAAAAEAA',\n",
       " 'AAARAIAAAA',\n",
       " 'FIAACAACAA',\n",
       " 'AAAIAAWAVI',\n",
       " 'AYAAAAAAKM',\n",
       " 'AAAGAARAKA',\n",
       " 'AATAAAAAAK',\n",
       " 'AARAAIADAD',\n",
       " 'AAAAQAVAAI',\n",
       " 'YCQAACIAPE',\n",
       " 'AAAAAAAIFA',\n",
       " 'PAAAAAKAAH',\n",
       " 'DAAAYAAMAA',\n",
       " 'AAAAATMAAA',\n",
       " 'AAAARPAAAA',\n",
       " 'AATAAAAQAE',\n",
       " 'AAAAAACLAD',\n",
       " 'AAAIAAAAAP',\n",
       " 'AAAAIAMAAA',\n",
       " 'AAIADVAAAA',\n",
       " 'AAADDAHAAE',\n",
       " 'MAAAAYAAAC',\n",
       " 'AEAAAKAAAY',\n",
       " 'AAAAAAARHT',\n",
       " 'AASAAAHAAK',\n",
       " 'AAEMAAAAAA',\n",
       " 'AASAAAAAIA',\n",
       " 'VAADATAAHA',\n",
       " 'AAFAAAIAAA',\n",
       " 'WANAAAHMPA',\n",
       " 'AARAGAAAAA',\n",
       " 'AAAAFMAAAA',\n",
       " 'AAHAAAAAAL',\n",
       " 'AKAAAAASHA',\n",
       " 'DYAAAAAAAA',\n",
       " 'AAAAANAIAA',\n",
       " 'AAYAAAAAAW',\n",
       " 'GAAPAAAAAY',\n",
       " 'NEAAAMAWAA',\n",
       " 'AAALLAAAVA',\n",
       " 'ADAAAAAAAH',\n",
       " 'AAAAKAAKAA',\n",
       " 'AAAAAWEAKI',\n",
       " 'AAFACAAAAS',\n",
       " 'AAAKAAADLA',\n",
       " 'AAGAAASAAV',\n",
       " 'ATADAVIAPA',\n",
       " 'IAAAAGAADG',\n",
       " 'GADAAHAEAW',\n",
       " 'CADQAAAAAA',\n",
       " 'AAIARAAAAA',\n",
       " 'AAAEAQVAAA',\n",
       " 'AASANAAAAA',\n",
       " 'ARQAVAAAAP',\n",
       " 'APAAAAAAAA',\n",
       " 'AAAAAVVAAA',\n",
       " 'ASAMAAAAAA',\n",
       " 'AAYAAAAYAA',\n",
       " 'ARKFAFAATA',\n",
       " 'AAAWAIAAAA',\n",
       " 'IAAAAAVAAA',\n",
       " 'AAAAAAIAAQ',\n",
       " 'AAAAAAPAAK',\n",
       " 'AHAAAEARAA',\n",
       " 'AAMAIAAFAA',\n",
       " 'AAANIASAAA',\n",
       " 'AGAAAKAGAA',\n",
       " 'AAAAAAAARM',\n",
       " 'AAAASASAAI',\n",
       " 'HRAAWNAMAA',\n",
       " 'EARAAAKAAA',\n",
       " 'PKAAAAAAAA',\n",
       " 'AGAAATAASA',\n",
       " 'KRAANAAAAA',\n",
       " 'AAAAKPAAED',\n",
       " 'AAAANAQAAA',\n",
       " 'AAYYSAAMAA',\n",
       " 'HAAARAAAAA',\n",
       " 'AGAAAAAYDA',\n",
       " 'ASAAAAAHAA',\n",
       " 'AIAAFAAAAA',\n",
       " 'SAAHAYHLAA',\n",
       " 'AKWWTAAAAA',\n",
       " 'APAAAASAYA',\n",
       " 'AAAMAAAAWA',\n",
       " 'GAAAAAASAR',\n",
       " 'AMAMESADAG',\n",
       " 'AYAAAAAMAA',\n",
       " 'AAAVNDAAAA',\n",
       " 'AALAAAAAFT',\n",
       " 'AAKAADAYVA',\n",
       " 'AFAAAFAAAA',\n",
       " 'AAYAAAAALL',\n",
       " 'AAAFAAAAQC',\n",
       " 'SQAPAAAAAA',\n",
       " 'AAAAAYVAAA',\n",
       " 'KQAAYAAAAA',\n",
       " 'ADASAAAAMK',\n",
       " 'ADAAAHAMCA',\n",
       " 'AAAHAYAAAA',\n",
       " 'AAAKAGAAAP',\n",
       " 'AAAAQAKAAK',\n",
       " 'AAAAACTALA',\n",
       " 'EAAAAGAAPA',\n",
       " 'AAIAYAAQAA',\n",
       " 'AAIAAAHAAA',\n",
       " 'AAAAIAAAKA',\n",
       " 'AGPAAAAATA',\n",
       " 'FAAGAAAAAA',\n",
       " 'AAYAAAACAA',\n",
       " 'IANAAAMAAA',\n",
       " 'IAADAAAAAC',\n",
       " 'AAEAAAFETA',\n",
       " 'ADAAAARAAA',\n",
       " 'AAAPADASAA',\n",
       " 'AGAATAASAA',\n",
       " 'AHAGAAAAAA',\n",
       " 'AAAAAAWQAC',\n",
       " 'AAEAYAAAAA',\n",
       " 'RAAVAAAVAA',\n",
       " 'CAAAAAAKFT',\n",
       " 'ALAAWAAAQA',\n",
       " 'ASYAAAAAAA',\n",
       " 'AAAGMAAAGA',\n",
       " 'AIAAATYAAC',\n",
       " 'WAVAAAAAAA',\n",
       " 'AATAAAASAA',\n",
       " 'AACAPARAAW',\n",
       " 'AAACAAAGQA',\n",
       " 'AAAAAAFMAA',\n",
       " 'TAAAAGAAAH',\n",
       " 'YAIAAAADQA',\n",
       " 'AESAAHAAAC',\n",
       " 'AAAFAAANAA',\n",
       " 'AAMGATAAGV',\n",
       " 'AEAKSCSAAA',\n",
       " 'AAAAPAQAAA',\n",
       " 'AAAAATANWA',\n",
       " 'ADATAYALAA',\n",
       " 'AAAMAAYAMA',\n",
       " 'AAAQIAAAAA',\n",
       " 'AAWCAAAAAA',\n",
       " 'LAGAAAARAA',\n",
       " 'KAALADAAAA',\n",
       " 'NAAEAAQAAK',\n",
       " 'AAASACAAAA',\n",
       " 'AAAAAAAECA',\n",
       " 'ANANAAAAGA',\n",
       " 'AAAADATAAA',\n",
       " 'WAAAAAAAKA',\n",
       " 'AATAAHAAAA',\n",
       " 'AAAALAAATA',\n",
       " 'AAHAAAVAAA',\n",
       " 'AARAAAAANA',\n",
       " 'NVAAAVAIAD',\n",
       " 'QAAKAAAVAG',\n",
       " 'AAKAAAAAHT',\n",
       " 'AAAAADLHAA',\n",
       " 'TAAAAACKAA',\n",
       " 'AAAHAAMDAA',\n",
       " 'AKAAKAAAAA',\n",
       " 'GAAAAPAAAE',\n",
       " 'YAQAAAAAAA',\n",
       " 'VAAAAAAAWA',\n",
       " 'AACAAAARHA',\n",
       " 'DAFACAAAVA',\n",
       " 'AAASAAAVAA',\n",
       " 'AAAAQAQAAA',\n",
       " 'KDWAAAAFAA',\n",
       " 'AHAAGQAAAA',\n",
       " 'WADAAKAAAA',\n",
       " 'AKAAAAAWCA',\n",
       " 'ATAWANAAAW',\n",
       " 'GFPAAAFWAA',\n",
       " 'AAAAVAATAA',\n",
       " 'AAAADAACAA',\n",
       " 'AAASCIAAAS',\n",
       " 'AAAIAAAIAK',\n",
       " 'AAAAAVANWA',\n",
       " 'KCAAAAAAAN',\n",
       " 'AAAAAAHEAA',\n",
       " 'AAALGAAAAL',\n",
       " 'AAFANEAAAA',\n",
       " 'VTAKAAAAAA',\n",
       " 'AAAWTAAAAA',\n",
       " 'FAASTTAAPA',\n",
       " 'AAAKAAAPAA',\n",
       " 'AAAIAAAAMA',\n",
       " 'KAMAAAAADA',\n",
       " 'QAAAAFAAAA',\n",
       " 'ADAAPAAAAA',\n",
       " 'ACAAAMAAAA',\n",
       " 'AAANMNAAAA',\n",
       " 'PQAAAKAAAA',\n",
       " 'SAGVAAAAAA',\n",
       " 'PIAAIWAAAS',\n",
       " 'ANKAAAAAAA',\n",
       " 'AAAAAADAAL',\n",
       " 'KAAASANAAA',\n",
       " 'AADHAHADRA',\n",
       " 'PTAAAAAAAA',\n",
       " 'AADAAAEKAE',\n",
       " 'AAAAAWDAAA',\n",
       " 'AAAIAAAAVT',\n",
       " 'AAAKAAAAHA',\n",
       " 'AAAAAARVAA',\n",
       " 'AWSAAAAAAS',\n",
       " 'VTRAASAAAA',\n",
       " 'GAAAAWAAAA',\n",
       " 'KAAAAFAAAA',\n",
       " 'AAAAAAAHAN',\n",
       " 'FAAAAAAGAW',\n",
       " 'AAAAAAVAKH',\n",
       " 'AMLAAAAAAA',\n",
       " 'AASAEAACTD',\n",
       " 'AAAAAARNAA',\n",
       " 'WAAASAAALM',\n",
       " 'AAAACAATAT',\n",
       " 'AYAIAAAWAA',\n",
       " 'EANLWAIAAA',\n",
       " 'AAYCAAANAK',\n",
       " 'ADAAAAAAGA',\n",
       " 'AASKAAAACA',\n",
       " 'DAAAAAAWAA',\n",
       " 'AASKAAKAAA',\n",
       " 'ALAWAAAAAA',\n",
       " 'AAAAAAAIAI',\n",
       " 'LAAAHNAVAA',\n",
       " 'AYAIAAAAAA',\n",
       " 'EARAAASAAI',\n",
       " 'AAAAYAAAHA',\n",
       " 'SAAAAAPNQS',\n",
       " 'AEAAAWAAAA',\n",
       " 'AAAACPNAAA',\n",
       " 'DAAAAAAAAA',\n",
       " 'ANAAAAAADA',\n",
       " 'KAADAAAAAA',\n",
       " 'AGAAQAWAAF',\n",
       " 'RAAAAAAAAH',\n",
       " 'AADAAAGMAV',\n",
       " 'MATAAAAAKA',\n",
       " 'AHAAAAHAAA',\n",
       " 'AAFAAMAAAI',\n",
       " 'NAAGAAAEGA',\n",
       " 'ATKADAAPAR',\n",
       " 'AAALAHAGAA',\n",
       " 'AAAAAAYLAA',\n",
       " 'AIAAAAKAIA',\n",
       " 'KAAAAACAAA',\n",
       " 'AAAARAAAAA',\n",
       " 'KACAANAAAA',\n",
       " 'AAAYARNAAA',\n",
       " 'TKAAAAAAAA',\n",
       " 'MEAAAAAVAA',\n",
       " 'CNFAAAAAAA',\n",
       " 'ARAAKKAAAA',\n",
       " 'AAADAAWWHA',\n",
       " 'FAAQAAFAAA',\n",
       " 'AAWAAAIAAN',\n",
       " 'AAPAAAASRA',\n",
       " 'AYAATAAAAD',\n",
       " 'AAAAATAAKA',\n",
       " 'CAAAAIAAAH',\n",
       " 'AAAAALAACA',\n",
       " 'TYAAAAALRA',\n",
       " 'AAAAAFASAC',\n",
       " 'AAADAAAAEA',\n",
       " 'VKAAAATAAA',\n",
       " 'KAAKAEAADV',\n",
       " 'MADAAAAAAA',\n",
       " 'NAHNAAAAAW',\n",
       " 'AAFAAAYAAG',\n",
       " 'AAAKAAWAAA',\n",
       " 'AAAAAAWAAI',\n",
       " 'AAAAAASRAA',\n",
       " 'ANAAAAIAAA',\n",
       " 'MMAAAKAAAA',\n",
       " 'AAAAAAAKAQ',\n",
       " 'QAAAFAAEAA',\n",
       " 'AAAAAGRAAA',\n",
       " 'AAAAAAALPA',\n",
       " 'AMAAAAAAAS',\n",
       " 'AAAQAIIRAA',\n",
       " 'AIADWAMAAA',\n",
       " 'GADAAAAAAW',\n",
       " 'YAAAHPAAQA',\n",
       " 'YAAAAAAPAA',\n",
       " 'AYAADANAFA',\n",
       " 'AWACAAAAAA',\n",
       " 'AACAAHAAAM',\n",
       " 'AWLAAAAAAA',\n",
       " 'AASAAAAAAV',\n",
       " 'ALAVAAAAQC',\n",
       " 'ADAWAATAAW',\n",
       " 'AANTAWAAAA',\n",
       " 'GAPYEAAAAA',\n",
       " 'AAAAAHSAEA',\n",
       " 'AAAAAAANHA',\n",
       " 'AATAAAARHA',\n",
       " 'CAAAAMMLAA',\n",
       " 'FAAAAAAKAA',\n",
       " 'AAARRAAAAA',\n",
       " 'AAAAAACAAF',\n",
       " 'AAAAAVAIQA',\n",
       " 'AGAHAHSFAA',\n",
       " 'AAAAAFAWAA',\n",
       " 'LAAALEAAAA',\n",
       " 'IAAAAAASAD',\n",
       " 'CAAAIAAMAA',\n",
       " 'VAATAPAAAA',\n",
       " 'TAAAAAAAAT',\n",
       " 'AAAIAAAGAA',\n",
       " 'QDAAPNAAAQ',\n",
       " 'FCALAAAAVA',\n",
       " 'KVAAAAQQAL',\n",
       " 'AANIACMAAV',\n",
       " 'AAAAAVTRAA',\n",
       " 'ANDAAAAAAA',\n",
       " 'CNAAAAAWAA',\n",
       " 'AAAAAVQQAA',\n",
       " 'AQKAMAAAAS',\n",
       " 'AQWAAARAAA',\n",
       " 'LAAAFAHAAA',\n",
       " 'ACAQAAAAAF',\n",
       " 'APAAAAAAFA',\n",
       " 'AAAIAMAAAA',\n",
       " 'EVAAAACAAA',\n",
       " 'ALAAGAYAAQ',\n",
       " 'AAAYAAALAA',\n",
       " 'ATAYAAALAA',\n",
       " 'AANGTAAWHA',\n",
       " 'NAAVAASAAA',\n",
       " 'AAAAAKAAAE',\n",
       " 'CNAAAAAAAA',\n",
       " 'AIAANAAAAA',\n",
       " 'CAAAARGAQL',\n",
       " 'AAALWEATAA',\n",
       " 'GQAAAAAAAA',\n",
       " 'AAEAAAAAKA',\n",
       " 'AAAAAGAQAP',\n",
       " 'AAMHAAAAAW',\n",
       " 'AWWAAAEMAA',\n",
       " 'AVACSAAAAA',\n",
       " 'AAAEAWAAAA',\n",
       " 'AGAAAAAAAV',\n",
       " 'APAAAAPAAA',\n",
       " 'MAAADAQAAD',\n",
       " 'AAHANEAFAA',\n",
       " 'AAVAAGAAAA',\n",
       " 'AACHADAAAA',\n",
       " 'AMQAEAAAAA',\n",
       " 'AAQAAAVAAP',\n",
       " 'WWAAMAAAAA',\n",
       " 'NAAAAAASAF',\n",
       " 'EAAAEAAAMA',\n",
       " 'AHAAAQADAA',\n",
       " 'AGAAVDAAAA',\n",
       " 'YAEAAWAAAA',\n",
       " 'AAAAAARIWA',\n",
       " 'AAAAIQQAAA',\n",
       " 'NAANAAAPAA',\n",
       " 'LAAPMAAAAA',\n",
       " 'AGAWAAANAA',\n",
       " 'AETASAAAEA',\n",
       " 'YAAAAARAAA',\n",
       " 'AAAEAYAADA',\n",
       " 'AAAAAQAFAG',\n",
       " 'ATAAAAACAA',\n",
       " 'WAAAAAPAAM',\n",
       " 'APAAHFKEIA',\n",
       " 'AAAAAAADAG',\n",
       " 'AAEAAASAAA',\n",
       " 'AMAAAAVFAF',\n",
       " 'AAAHAAAVAL',\n",
       " 'AAAAYAAAAQ',\n",
       " 'DAAAAVRAAA',\n",
       " 'NASAAAATRA',\n",
       " 'ERMAAAAAAA',\n",
       " 'AARAAAYAAS',\n",
       " 'AAMAAMATAA',\n",
       " 'CAATASAAAP',\n",
       " 'AAAHAAALAA',\n",
       " 'APAKAAAKAA',\n",
       " 'ASAAAAAAFA',\n",
       " 'IAAYAAAAAA',\n",
       " 'APEAAAAAAA',\n",
       " 'AARAAAAAAF',\n",
       " 'AATARAYRAA',\n",
       " 'ANAMAARAAA',\n",
       " 'AAAAAACHAK',\n",
       " 'SAAAAGAAMA',\n",
       " 'GAAAAAAAAT',\n",
       " 'AAAAQMAAYA',\n",
       " 'AACHIPARAA',\n",
       " 'AAQNAAPAAA',\n",
       " 'AAPEAAAAAD',\n",
       " 'GAANNAAAAK',\n",
       " 'AALAAATAAW',\n",
       " 'AAQAAATAGA',\n",
       " 'AAKARAAAAA',\n",
       " 'AASTAAAAEA',\n",
       " 'ATASAAAAAA',\n",
       " 'LFNAAAAAAA',\n",
       " 'NCAAAAACAA',\n",
       " 'ADAAAAARAA',\n",
       " 'AAAHAAAACA',\n",
       " 'AAFAAAAKAA',\n",
       " 'AQAAAHFSAA',\n",
       " 'AAACANAAGG',\n",
       " 'ANAASANAQA',\n",
       " 'AGAAAAKATA',\n",
       " 'AAAAAAYAWA',\n",
       " 'AATWAAAAAP',\n",
       " 'AAAACAAATA',\n",
       " 'NAAAAPAAAR',\n",
       " 'AAMAIAAAAA',\n",
       " 'AIHAYAAAAA',\n",
       " 'AWLAMARAAA',\n",
       " 'AAAAAAFAMA',\n",
       " 'AAACAADMHA',\n",
       " 'AYAAAAAACA',\n",
       " 'CAAAAAADVA',\n",
       " 'RASLAAAAAA',\n",
       " 'QAAAATAIAV',\n",
       " 'AATAAWAAGA',\n",
       " 'AAAAATAKAA',\n",
       " 'AACAKASAAA',\n",
       " 'NAAAAEAAFA',\n",
       " 'PIAAAAQKAA',\n",
       " 'AAAAAAAWNA',\n",
       " 'AHACYMPNAA',\n",
       " 'AHAAFSAAAA',\n",
       " 'WAAAAAAFAE',\n",
       " 'MAAAIAAVAA',\n",
       " 'AAFAAAAATA',\n",
       " 'AAAAAAQAGA',\n",
       " 'AAYAAAAAIA',\n",
       " 'LAAALAAARD',\n",
       " 'ATDAEAAAAA',\n",
       " 'AAAAAHAAAI',\n",
       " 'AAAAALAIDA',\n",
       " 'IAAAAAMAAA',\n",
       " 'AAAAAANAAQ',\n",
       " 'AAAAPAPADA',\n",
       " 'AAAQYAAADA',\n",
       " 'AAAAAAAANA',\n",
       " 'VPAAAAKHWM',\n",
       " 'AAAAWAAQAA',\n",
       " 'AACAAKAWAA',\n",
       " 'AAACAAAARA',\n",
       " 'CAAAAASAAA',\n",
       " 'AHAEAAAADA',\n",
       " 'AAGAAAAVAA',\n",
       " 'SAAMARAAAA',\n",
       " 'ACSAFAAAYA',\n",
       " 'GAANAAAAAA',\n",
       " 'ACSAAHAKAA',\n",
       " 'RPAATAARAA',\n",
       " 'PATDAAAAAA',\n",
       " 'AAAAANLAAA',\n",
       " 'AAADGAAAAP',\n",
       " 'VAAAAANAAA',\n",
       " 'AAAPCAAAAF',\n",
       " 'MARAAAAAAP',\n",
       " 'AHIAAAAARA',\n",
       " 'AAMAAAAAAQ',\n",
       " 'AAAAAAACCA',\n",
       " 'PAAYAFAAAA',\n",
       " 'AASAAAAMAA',\n",
       " 'MAKAAAAAAA',\n",
       " 'AAAAAAPACA',\n",
       " 'YARMEAAAAA',\n",
       " 'AAAAAYAADA',\n",
       " 'AWAYAVAAAA',\n",
       " 'AAIYVAAARK',\n",
       " 'ANAAADAAAA',\n",
       " 'GARAAAAALA',\n",
       " 'AQEAAAAACM',\n",
       " ...]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[numbers_to_amino_acid_sequence(seq) for seq in seqs_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131697c-1215-4e89-bbf7-596a7991301b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907844d5-cd09-4885-bc8a-1154e639276f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66772dc4-8bf7-42b6-b70a-dc39a9495e65",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "203205e5-8c22-4c42-a2fb-0d433e41595d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "prop = .9\n",
    "num_train = int(prop * n)\n",
    "num_test = n - num_train\n",
    "\n",
    "preds = {\"linear\": {}, \"1_layer\": {}, \"2_layers\": {}, \"3_layers\": {}}\n",
    "names = list(preds.keys())\n",
    "train_lists = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d2d643b0-5279-4653-96c8-82a3562916e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f25c342c-adb4-4840-a6e8-77f066d194b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_class = Transformer_2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "aaa7ee99-cf78-4e95-a15a-d022b1f8fdff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting linear regression\n",
      "Epoch 1/100, Loss: 174.1378130231585\n",
      "5.440664402049465e-05\n",
      "Epoch 11/100, Loss: 131.2292752947126\n",
      "7.091973468342215e-05\n",
      "Epoch 21/100, Loss: 100.97922879173642\n",
      "0.00013423161054982222\n",
      "Epoch 31/100, Loss: 79.06435793922061\n",
      "0.00019221239315712042\n",
      "Epoch 41/100, Loss: 65.357668195452\n",
      "0.0002628941826999674\n",
      "Epoch 51/100, Loss: 56.18692997523716\n",
      "0.0002447889367886955\n",
      "Epoch 61/100, Loss: 50.991781507219585\n",
      "0.0003021538708998493\n",
      "Epoch 71/100, Loss: 47.81891432262602\n",
      "0.0001835518385843168\n",
      "Epoch 81/100, Loss: 46.540838877360024\n",
      "0.0003027951857230136\n",
      "Epoch 91/100, Loss: 45.871249244326634\n",
      "0.0003747073727119762\n",
      "Build model with 1 layers of attention\n",
      "Epoch 1/1000, Loss: 52.366264371449134\n",
      "0.049046526618542904\n",
      "Epoch 11/1000, Loss: 45.67603815012965\n",
      "0.10184711298242084\n",
      "Epoch 21/1000, Loss: 45.559474550444506\n",
      "0.1364069432217717\n",
      "Epoch 31/1000, Loss: 45.6588733466388\n",
      "0.25841677018536446\n",
      "Epoch 41/1000, Loss: 45.671469392447634\n",
      "0.1779353653230733\n",
      "Epoch 51/1000, Loss: 45.52921004835608\n",
      "0.31871614262322906\n",
      "Epoch 61/1000, Loss: 45.57578412887498\n",
      "0.27650734100264235\n",
      "Epoch 71/1000, Loss: 45.51823456299129\n",
      "0.30845803044234016\n",
      "Epoch 81/1000, Loss: 45.59110026993775\n",
      "0.19455861941197217\n",
      "Epoch 91/1000, Loss: 45.516190458401084\n",
      "0.2920411026298809\n",
      "Epoch 101/1000, Loss: 45.53033388072047\n",
      "0.16109892722360616\n",
      "Epoch 111/1000, Loss: 45.49302211066185\n",
      "0.10963334947617659\n",
      "Epoch 121/1000, Loss: 45.501401018039346\n",
      "0.34724289903362177\n",
      "Epoch 131/1000, Loss: 45.54608451204347\n",
      "0.4135031459296269\n",
      "Epoch 141/1000, Loss: 45.50616070789657\n",
      "0.34455407533344445\n",
      "Epoch 151/1000, Loss: 45.533633368355886\n",
      "0.2996958088365869\n",
      "Epoch 161/1000, Loss: 45.525712149483816\n",
      "0.16397551500875082\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 129\u001b[0m\n\u001b[1;32m    127\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpre_sig_forward(batch_inputs)\n\u001b[1;32m    128\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_targets)\n\u001b[0;32m--> 129\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    131\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/apps/pytorch/2.2.0/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/apps/pytorch/2.2.0/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nrep = 3\n",
    "\n",
    "for i in range(nrep):\n",
    "\n",
    "    train_list, val_list, test_list, sub_list = make_train_val_test_lists_rand(seqs, num_train, num_test)\n",
    "    train_lists[i] = train_list\n",
    "\n",
    "    #### Linear model\n",
    "\n",
    "    dropout_p = 0.\n",
    "    fc_out_norm = False\n",
    "    n_epochs = 100\n",
    "    learning_rate = .01\n",
    "\n",
    "    print(\"Fitting linear regression\")\n",
    "    X = seqs1h.float().to(device)\n",
    "    y = phenotypes.to(device)\n",
    "\n",
    "    X_train, y_train = X[train_list], y[train_list]\n",
    "    X_val, y_val = X[val_list], y[val_list]\n",
    "    X_test, y_test = X[test_list], y[test_list]\n",
    "\n",
    "    train_dataset = ProtDataset(X_train, y_train)\n",
    "    train_loader = data.DataLoader(train_dataset,\n",
    "                                   batch_size=1000,\n",
    "                                   shuffle=True,\n",
    "                                   drop_last=False)\n",
    "\n",
    "    val_dataset = ProtDataset(X_val, y_val)\n",
    "    val_loader = data.DataLoader(val_dataset,\n",
    "                                batch_size=1000,\n",
    "                                shuffle=False,\n",
    "                                drop_last=False)\n",
    "\n",
    "    test_dataset = ProtDataset(X_test, y_test)\n",
    "    test_loader = data.DataLoader(test_dataset,\n",
    "                                batch_size=1000,\n",
    "                                shuffle=False,\n",
    "                                drop_last=False)\n",
    "\n",
    "    model = LinearModel(L, AA_size, dropout_p, fc_out_norm).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    r2_test_log = []\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for batch_inputs, batch_targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_inputs)\n",
    "                loss = criterion(outputs, batch_targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "                model.eval()\n",
    "                pred, true = make_predictions(model, val_loader)\n",
    "                print(pearsonr(pred, true)[0]**2)\n",
    "                if pearsonr(pred, true)[0]**2 == \"nan\":\n",
    "                    break\n",
    "                r2_test_log.append(pearsonr(pred, true)[0]**2)\n",
    "\n",
    "    model.eval()\n",
    "    pred = model(X).cpu().detach().numpy().flatten()\n",
    "\n",
    "    preds['linear'][i] = pred\n",
    "\n",
    "    ### Transformer models\n",
    "\n",
    "    seqs_ex = seqs + AA_size*torch.tensor(range(L))\n",
    "    X = seqs_ex.to(device)\n",
    "    y = phenotypes.to(device)\n",
    "    X_train, y_train = X[train_list], y[train_list]\n",
    "    X_val, y_val = X[val_list], y[val_list]\n",
    "    X_test, y_test = X[test_list], y[test_list]\n",
    "\n",
    "    train_dataset = ProtDataset(X_train, y_train)\n",
    "    train_loader = data.DataLoader(train_dataset,\n",
    "                                   batch_size=train_batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   drop_last=False)\n",
    "    \n",
    "    val_dataset = ProtDataset(X_val, y_val)\n",
    "    val_loader = data.DataLoader(val_dataset,\n",
    "                                batch_size=len(X_val),\n",
    "                                shuffle=False,\n",
    "                                drop_last=False)\n",
    "\n",
    "    test_dataset = ProtDataset(X_test, y_test)\n",
    "    test_loader = data.DataLoader(test_dataset,\n",
    "                                batch_size=len(X_test),\n",
    "                                shuffle=False,\n",
    "                                drop_last=False)\n",
    "\n",
    "    input_dim = AA_size*L\n",
    "    output_dim = 1\n",
    "    learning_rate = 0.0002\n",
    "    num_heads = 4\n",
    "    hidden_dim_h = 48\n",
    "    dropout = .01\n",
    "    batch_size = len(X)\n",
    "\n",
    "\n",
    "    for num_layers in [1, 2]:        \n",
    "        if num_layers == 3:\n",
    "            n_epochs = 4000\n",
    "        elif num_layers == 2:\n",
    "            n_epochs = 2000\n",
    "        else: n_epochs = 1000\n",
    "        \n",
    "        print(f\"Build model with {num_layers} layers of attention\")\n",
    "        model = model_class(L, input_dim, hidden_dim_h*num_heads, num_layers, num_heads, dropout).to(device)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        r2_test_log = []\n",
    "        for epoch in range(n_epochs):\n",
    "                model.train()\n",
    "                total_loss = 0\n",
    "                for batch_inputs, batch_targets in train_loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model.pre_sig_forward(batch_inputs)\n",
    "                    loss = criterion(outputs, batch_targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                if epoch % 10 == 0:\n",
    "                    print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "                    model.eval()\n",
    "                    pred, true = make_predictions(model, val_loader)\n",
    "                    print(pearsonr(pred, true)[0]**2)\n",
    "                    if pearsonr(pred, true)[0]**2 == \"nan\":\n",
    "                        break\n",
    "                    r2_test_log.append(pearsonr(pred, true)[0]**2)\n",
    "\n",
    "        model.eval()\n",
    "        pred = model(X).flatten().cpu().detach().numpy()\n",
    "        preds[names[num_layers]][i] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5c3a6-ba7c-48c8-b6ee-fb7a4d93afc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.2.0",
   "language": "python",
   "name": "pytorch-2.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
