{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ee463d-203e-4672-9a1e-0a89dc8068a3",
   "metadata": {},
   "source": [
    "###### This notebook contains code for generating scripts for training the Epistatic Transformer model and hyperparameter search using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd54d982-c843-42aa-8bc7-957e8e3a7c72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../model')\n",
    "from utils import amino_acid_to_number, tokenize, Tee\n",
    "from functions import get_A2N_list, tokenize, make_train_val_test_lists_rand, prepare_data\n",
    "import pickle\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "source_path = \"../\"\n",
    "sys.path.append(source_path + 'model')\n",
    "from utils import amino_acid_to_number, tokenize, Tee\n",
    "from functions import get_A2N_list, tokenize, make_train_val_test_lists_rand, prepare_data\n",
    "from models import make_predictions, ProtDataset, Transformer_2k, LinearModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aedd0220-738a-4d3d-b912-53908746615d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_line(line, filename):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'a') as file:\n",
    "            file.write(line + '\\n')\n",
    "    else: \n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(line + '\\n')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35b83175-52ad-44cd-9239-799c75bff690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_command(filename, data_name, prefix, train_percent, seed, \n",
    "                 train_list=None, val_list=None, test_list=None,\n",
    "                iter2=200, iter4=200, iter8=200):\n",
    "    write_line(\"python3 run_script-CLI.py\\\\\", filename)\n",
    "    write_line(\"--device cuda:0 \\\\\", filename)\n",
    "    write_line(f\"--data_name {data_name} \\\\\", filename)\n",
    "    write_line(f\"--prefix {prefix} \\\\\", filename)\n",
    "    write_line(f\"--train_percent {train_percent}\\\\\", filename)\n",
    "    write_line(\"--fit_linear\\\\\", filename)\n",
    "    write_line(f\"--seed {seed}\\\\\", filename)\n",
    "    if train_list is not None:\n",
    "        write_line(\"--specify_train\\\\\", filename)\n",
    "        write_line(f\"--train_list {train_list}\\\\\", filename)\n",
    "    if val_list is not None:\n",
    "        write_line(\"--specify_val\\\\\", filename)\n",
    "        write_line(f\"--val_list {val_list}\\\\\", filename)\n",
    "    if test_list is not None:\n",
    "        write_line(\"--specify_test\\\\\", filename)\n",
    "        write_line(f\"--test_list {test_list}\\\\\", filename)\n",
    "        \n",
    "    write_line(f\"--iter2 {iter2}\\\\\", filename)\n",
    "    write_line(f\"--iter4 {iter4}\\\\\", filename)\n",
    "    write_line(f\"--iter8 {iter8}\", filename)    \n",
    "        \n",
    "    # with open(filename, 'r') as file:\n",
    "    #     content = file.read()\n",
    "    # with open(filename, 'w') as file:\n",
    "    #     file.write(content[:-2])\n",
    "    \n",
    "    write_line(\"\\n\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6bdc60d-4b9a-4dbd-ba6a-68344d16b6e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_path = \"../Data/Data_prepared/\"\n",
    "data_path = \"/blue/juannanzhou/ProteinLLE/Data/Data_prepared/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be134636-534c-4d06-9de8-91c470cef908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../Data/Data_prepared/train_lists/*': No such file or directory\n",
      "rm: cannot remove '../run_scripts/command*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm ../Data/Data_prepared/train_lists/*\n",
    "!rm ../run_scripts/command*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bfcc5f1-d521-4da1-a191-f41906ca2800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \"../run_scripts/\" + \"commands.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cef2f39-6524-416a-aa76-a05a51ecc94d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random All proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95a61b6d-172a-4101-9bd3-29251ca33784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \"../run_scripts/\" + \"random_train_commands.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0609fa2c-39cb-47c3-bcf4-61957f3fe05b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../run_scripts/random_train_commands.txt': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm {filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "385a65d5-d925-49d5-b9cd-d99bc7ee6ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../Data/Data_prepared/Protein_set.txt\", 'r') as file:\n",
    "    content = file.read()\n",
    "    \n",
    "protein_list = content.split('\\n')[: -1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0c27ffc-31dc-42a6-9483-c6dc06c6f6eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faure2023_1_lenient\n",
      "Faure2023_1_lenient\n",
      "Faure2023_1_lenient\n",
      "Faure2023_3_binding\n",
      "Faure2023_3_binding\n",
      "Faure2023_3_binding\n",
      "Faure2023_3_abundance\n",
      "Faure2023_3_abundance\n",
      "Faure2023_3_abundance\n",
      "Sinai2021\n",
      "Sinai2021\n",
      "Sinai2021\n",
      "Chen2023\n",
      "Chen2023\n",
      "Chen2023\n",
      "Somermeyer2022_cgreGFP\n",
      "Somermeyer2022_cgreGFP\n",
      "Somermeyer2022_cgreGFP\n",
      "Somermeyer2022_ppluGFP\n",
      "Somermeyer2022_ppluGFP\n",
      "Somermeyer2022_ppluGFP\n",
      "Somermeyer2022_amacGFP\n",
      "Somermeyer2022_amacGFP\n",
      "Somermeyer2022_amacGFP\n",
      "Pokusaeva_2019_S2\n",
      "Pokusaeva_2019_S2\n",
      "Pokusaeva_2019_S2\n",
      "Pokusaeva_2019_S5\n",
      "Pokusaeva_2019_S5\n",
      "Pokusaeva_2019_S5\n",
      "Pokusaeva_2019_S12\n",
      "Pokusaeva_2019_S12\n",
      "Pokusaeva_2019_S12\n"
     ]
    }
   ],
   "source": [
    "prefix = \"Random\"\n",
    "seed = 0\n",
    "for data_name in protein_list:\n",
    "    protein_name = data_name.split(\".\")[0]\n",
    "    for train_percent in [20, 50, 80]:\n",
    "        print(protein_name)\n",
    "        make_command(filename, protein_name, prefix, train_percent, seed, train_list=None, val_list=None, \n",
    "                    iter2=200, iter4=200, iter8=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303af96d-0e77-4324-81c3-254b4059b242",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63c8d5ce-1fe2-4739-9bc1-6522227b0a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_name = \"Somermeyer2022_4GFP\"\n",
    "datafile = pd.read_csv(\"../Data/Data_prepared/Somermeyer2022_4GFP.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f986e-c6c8-4f0b-ab73-1d13b627c3da",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Focal gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "988b92fd-4008-4de4-bb45-92f6c3204aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_name = \"Somermeyer2022_4GFP\"\n",
    "datafile = pd.read_csv(\"../Data/Data_prepared/Somermeyer2022_4GFP.csv\")\n",
    "\n",
    "# datafile = datafile[datafile.hd < 20]\n",
    "\n",
    "phenotypes, seqs, seqs1h = prepare_data(datafile)\n",
    "n, L, AA_size = seqs1h.shape\n",
    "\n",
    "seqs1hf = seqs1h.reshape(-1, AA_size*L)\n",
    "seqs1hf = seqs1hf.to(device).float()\n",
    "\n",
    "seqs_ex = seqs + AA_size*torch.tensor(range(L))\n",
    "X = seqs_ex.to(device)\n",
    "y = phenotypes.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01da15de-804c-4067-83a9-41af1b243d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amacGFP\n",
      "5325\n",
      "5325\n",
      "cgreGFP\n",
      "3925\n",
      "3925\n",
      "ppluGFP\n",
      "4835\n",
      "4835\n",
      "avGFP\n",
      "8104\n",
      "8103\n"
     ]
    }
   ],
   "source": [
    "# Train list for each gene, with small set of data from other genes\n",
    "# 50% of all data for focal gene\n",
    "nrep = 3\n",
    "train_file_names = []\n",
    "val_file_names = []\n",
    "gene_names = []\n",
    "for gene in datafile.gene.unique():\n",
    "    print(gene)\n",
    "    experiment = f\"focal_{gene}\"\n",
    "    sub = np.where(datafile.gene == gene)[0]\n",
    "    sub = list(sub)\n",
    "    comp_list = list(set(range(len(datafile))).difference(sub))\n",
    "    for i in range(nrep):\n",
    "        # train_list_focal = random.sample(sub, int(.5*len(sub)))\n",
    "        train_list_focal = random.sample(sub, int(.5*len(sub)))        \n",
    "        train_list_supp = random.sample(comp_list, int(.1 * len(train_list_focal)))    \n",
    "        train_list = train_list_supp + train_list_focal\n",
    "        comp_list_focal = set(sub).difference(train_list)\n",
    "        comp_list_focal = list(comp_list_focal)\n",
    "\n",
    "        diff = L - seqs1hf[comp_list_focal].matmul(seqs1hf[train_list_focal].T)\n",
    "        meandiff = diff.mean(1)\n",
    "        meandiff = meandiff.cpu().detach().numpy()\n",
    "\n",
    "        val_list = np.array(comp_list_focal)[meandiff > np.quantile(meandiff, .7)]\n",
    "        val_list = list(val_list)\n",
    "        print(len(val_list))\n",
    "        \n",
    "        train_file_name = data_path + \"train_lists/\" + f\"{data_name}_\" + experiment + \"_train_list_rep_\" + str(i) + \".pkl\"\n",
    "        val_file_name = data_path + \"train_lists/\" + f\"{data_name}_\" + experiment + \"_val_list_rep_\" + str(i) + \".pkl\"\n",
    "\n",
    "        train_file_names.append(train_file_name)\n",
    "        val_file_names.append(val_file_name)\n",
    "        gene_names.append(gene)\n",
    "\n",
    "        with open(train_file_name, 'wb') as file:\n",
    "            pickle.dump(train_list, file)\n",
    "        with open(val_file_name, 'wb') as file:\n",
    "            pickle.dump(val_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52798513-9d41-4d2e-8c3c-299f7318e95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_file_names)):\n",
    "    prefix = gene_names[i] + \"_focal\"\n",
    "    train_percent = 10000\n",
    "    seed = i\n",
    "    train_list = train_file_names[i]\n",
    "    val_list = val_file_names[i]\n",
    "    make_command(filename, data_name, prefix, train_percent, seed, train_list=train_list, val_list=val_list, \n",
    "                iter2=200, iter4=200, iter8=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18bc8180-8b52-40f7-92d8-d7574390de35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ppluGFP    4835\n",
       "Name: gene, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_name = \"/blue/juannanzhou/ProteinLLE/Data/Data_prepared/train_lists/Somermeyer2022_4GFP_focal_ppluGFP_train_list_rep_0.pkl\"\n",
    "with open(train_file_name, 'rb') as file:\n",
    "    train_list = pickle.load(file)\n",
    "\n",
    "val_file_name = \"/blue/juannanzhou/ProteinLLE/Data/Data_prepared/train_lists/Somermeyer2022_4GFP_focal_ppluGFP_val_list_rep_0.pkl\"\n",
    "with open(val_file_name, 'rb') as file:\n",
    "    val_list = pickle.load(file)\n",
    "\n",
    "datafile.iloc[train_list].gene.value_counts()\n",
    "\n",
    "datafile.iloc[val_list].gene.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130db98-86b0-464f-844f-24eaa31bb37d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### HD 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a7c8eaa-b5ec-4caf-8712-ee6ca07b2ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HD random training list\n",
    "train_file_names = []\n",
    "val_file_names = []\n",
    "experiment = \"HD2\"\n",
    "\n",
    "for i in range(2):\n",
    "    train_list = random.sample(list(np.where(datafile.hd <= 2)[0]), 40000)\n",
    "    val_list = random.sample(list(np.where(datafile.hd > 2)[0]), 10000)\n",
    "    \n",
    "    train_file_name = data_path + \"train_lists/\" + f\"{data_name}_\" + experiment + \"_train_list_rep_\" + str(i) + \".pkl\"\n",
    "    val_file_name = data_path + \"train_lists/\" + f\"{data_name}_\" + experiment + \"_val_list_rep_\" + str(i) + \".pkl\"\n",
    "    \n",
    "    train_file_names.append(train_file_name)\n",
    "    val_file_names.append(val_file_name)\n",
    "    \n",
    "    with open(train_file_name, 'wb') as file:\n",
    "        pickle.dump(train_list, file)\n",
    "    with open(val_file_name, 'wb') as file:\n",
    "        pickle.dump(val_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4135c18e-a14d-4f74-a6d5-88c324f4b48d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_percent = 10000\n",
    "seed = 0\n",
    "\n",
    "for i in range(len(train_file_names)):\n",
    "    prefix = experiment_names[i]\n",
    "    train_list = train_file_names[i]\n",
    "    val_list = val_file_names[i]\n",
    "    make_command(filename, data_name, prefix, train_percent, seed, train_list=train_list, val_list=val_list, \n",
    "                iter2=200, iter4=200, iter8=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.2.0",
   "language": "python",
   "name": "pytorch-2.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
